#!/usr/bin/env python3
"""
å®Œå…¨ç¬¦åˆå®˜æ–¹MCPè§„èŒƒçš„AIè§†é¢‘å¤„ç†æœåŠ¡å™¨
åŸºäºå®˜æ–¹æ–‡æ¡£ç¤ºä¾‹é‡æ–°å®ç°
"""

import asyncio
import json
import sys
import os
from pathlib import Path
from typing import Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import mcp.server.stdio
import mcp.types as types
from mcp.server.lowlevel import NotificationOptions, Server
from mcp.server.models import InitializationOptions

# åˆ›å»ºæœåŠ¡å™¨å®ä¾‹
server = Server("ai-video-master")

@server.list_tools()
async def handle_list_tools() -> list[types.Tool]:
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å·¥å…·"""
    return [
        types.Tool(
            name="reverse_text",
            description="åè½¬æ–‡æœ¬å­—ç¬¦ä¸² - ç”¨äºæµ‹è¯•MCPè¿æ¥",
            inputSchema={
                "type": "object",
                "properties": {
                    "text": {"type": "string", "description": "è¦åè½¬çš„æ–‡æœ¬"}
                },
                "required": ["text"]
            }
        ),
        types.Tool(
            name="video_to_slice",
            description="å°†è§†é¢‘æ™ºèƒ½åˆ‡ç‰‡ï¼ŒåŸºäºGoogle Cloud Video Intelligence APIè¿›è¡Œåœºæ™¯æ£€æµ‹",
            inputSchema={
                "type": "object",
                "properties": {
                    "input_dir": {"type": "string", "description": "è¾“å…¥è§†é¢‘ç›®å½•è·¯å¾„"},
                    "output_dir": {"type": "string", "description": "è¾“å‡ºåˆ‡ç‰‡ç›®å½•è·¯å¾„", "default": "./data/output"},
                    "concurrent": {"type": "integer", "description": "è§†é¢‘çº§å¹¶å‘æ•° (1-3)", "default": 3, "minimum": 1, "maximum": 3},
                    "ffmpeg_workers": {"type": "integer", "description": "FFmpegå¹¶è¡Œçº¿ç¨‹æ•° (2-8)", "default": 4, "minimum": 2, "maximum": 8}
                },
                "required": ["input_dir"]
            }
        ),
        types.Tool(
            name="video_to_srt",
            description="å°†è§†é¢‘è½¬æ¢ä¸ºSRTå­—å¹•æ–‡ä»¶ï¼Œä½¿ç”¨DashScopeè¯­éŸ³è¯†åˆ«APIï¼Œä¸“é—¨ä¼˜åŒ–å©´å¹¼å„¿å¥¶ç²‰è¯æ±‡",
            inputSchema={
                "type": "object",
                "properties": {
                    "input_dir": {"type": "string", "description": "è¾“å…¥è§†é¢‘ç›®å½•è·¯å¾„"},
                    "output_dir": {"type": "string", "description": "è¾“å‡ºSRTç›®å½•è·¯å¾„", "default": "./data/output"}
                },
                "required": ["input_dir"]
            }
        ),
        types.Tool(
            name="srt_to_product",
            description="åŸºäºSRTå­—å¹•å†…å®¹ç”Ÿæˆäº§å“ä»‹ç»è§†é¢‘åˆ‡ç‰‡ï¼Œä½¿ç”¨DeepSeek AIåˆ†æå©´å¹¼å„¿å¥¶ç²‰ç›¸å…³å†…å®¹",
            inputSchema={
                "type": "object",
                "properties": {
                    "srt_dir": {"type": "string", "description": "SRTå­—å¹•æ–‡ä»¶ç›®å½•è·¯å¾„"},
                    "output_dir": {"type": "string", "description": "è¾“å‡ºäº§å“è§†é¢‘ç›®å½•è·¯å¾„", "default": "./data/output"},
                    "input_video_dir": {"type": "string", "description": "å¯¹åº”çš„è¾“å…¥è§†é¢‘ç›®å½•è·¯å¾„", "default": "../video_to_srt/data/input"}
                },
                "required": ["srt_dir"]
            }
        ),
        types.Tool(
            name="slice_to_label",
            description="è§†é¢‘ç‰‡æ®µæ ‡ç­¾åˆ†æå·¥å…· - ğŸ­Originé©±åŠ¨æ¶æ„ï¼Œä»ğŸ¬Sliceç›®å½•åˆ†æåˆ‡ç‰‡æ–‡ä»¶",
            inputSchema={
                "type": "object",
                "properties": {
                    "slice_dir": {"type": "string", "description": "åˆ‡ç‰‡ç›®å½•è·¯å¾„", "default": "../ğŸ¬Slice"},
                    "video_name": {"type": "string", "description": "æŒ‡å®šè§†é¢‘åç§°ï¼Œä¸ºç©ºåˆ™å¤„ç†æ‰€æœ‰è§†é¢‘"},
                    "slice_type": {"type": "string", "description": "åˆ‡ç‰‡ç±»å‹", "enum": ["slices", "product", "all"], "default": "slices"},
                    "analysis_type": {"type": "string", "description": "åˆ†æç±»å‹", "enum": ["dual", "simple"], "default": "dual"}
                },
                "required": []
            }
        ),
        types.Tool(
            name="reclassify_main_labels",
            description="é‡æ–°è¿è¡Œä¸»æ ‡ç­¾æ™ºèƒ½åˆ†ç±» - ä½¿ç”¨DeepSeekåˆ†æå™¨é‡æ–°åˆ†ç±»é£ä¹¦æ•°æ®ä¸­çš„ä¸»æ ‡ç­¾",
            inputSchema={
                "type": "object",
                "properties": {
                    "target_model": {"type": "string", "description": "æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹", "enum": ["deepseek-chat", "claude-4.0", "auto"], "default": "deepseek-chat"},
                    "min_confidence": {"type": "number", "description": "æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼", "default": 0.5, "minimum": 0.0, "maximum": 1.0},
                    "batch_size": {"type": "integer", "description": "æ‰¹å¤„ç†å¤§å°", "default": 10, "minimum": 1, "maximum": 50},
                    "reason": {"type": "string", "description": "é‡æ–°åˆ†ç±»çš„åŸå› è¯´æ˜"}
                },
                "required": []
            }
        ),
        types.Tool(
            name="optimize_prompts",
            description="ğŸ”§ æ™ºèƒ½æç¤ºè¯ä¼˜åŒ–å·¥å…· - åŸºäºç”¨æˆ·åé¦ˆæ•°æ®ä¼˜åŒ–è§†è§‰åˆ†æå’Œä¸»æ ‡ç­¾åˆ†ç±»çš„æç¤ºè¯",
            inputSchema={
                "type": "object",
                "properties": {
                    "feedback_file": {"type": "string", "description": "åé¦ˆæ•°æ®æ–‡ä»¶è·¯å¾„", "default": "video_segment_feedback.json"},
                    "optimization_type": {"type": "string", "description": "ä¼˜åŒ–ç±»å‹", "enum": ["visual_labels", "main_tags", "both"], "default": "both"},
                    "reason": {"type": "string", "description": "ä¼˜åŒ–åŸå› è¯´æ˜", "default": "åŸºäºCursoræ™ºèƒ½åˆ†æçš„æç¤ºè¯ä¼˜åŒ–"},
                    "force_optimize": {"type": "boolean", "description": "å¼ºåˆ¶ä¼˜åŒ–ï¼ˆå³ä½¿é”™è¯¯ç‡è¾ƒä½ï¼‰", "default": False}
                },
                "required": []
            }
        )
    ]

@server.call_tool()
async def handle_call_tool(name: str, arguments: dict[str, Any]) -> list[types.TextContent]:
    """å¤„ç†å·¥å…·è°ƒç”¨"""
    
    if name == "reverse_text":
        text = arguments.get("text", "")
        result = text[::-1]
        return [types.TextContent(type="text", text=f"åè½¬ç»“æœ: {result}")]
    
    elif name == "video_to_slice":
        try:
            # åˆ‡æ¢åˆ°video_to_sliceç›®å½•
            original_cwd = os.getcwd()
            os.chdir(project_root / "video_to_slice")
            
            # å¯¼å…¥å¤„ç†å™¨
            sys.path.insert(0, str(project_root / "video_to_slice" / "src"))
            from parallel_batch_processor import ParallelBatchProcessor
            
            input_dir = arguments["input_dir"]
            output_dir = arguments.get("output_dir", "./data/output")
            concurrent = arguments.get("concurrent", 3)
            ffmpeg_workers = arguments.get("ffmpeg_workers", 4)
            
            processor = ParallelBatchProcessor(
                output_dir=output_dir,
                temp_dir="./data/temp",
                max_concurrent=min(max(concurrent, 1), 3),
                ffmpeg_workers=min(max(ffmpeg_workers, 2), 8)
            )
            
            result = processor.process_batch_sync(
                input_dir=input_dir,
                file_patterns=["*.mp4", "*.MP4", "*.avi", "*.AVI", "*.mov", "*.MOV", "*.mkv", "*.MKV"],
                features=["shot_detection"]
            )
            
            os.chdir(original_cwd)
            
            # æ–‡ä»¶å·²ç›´æ¥è¾“å‡ºåˆ°ğŸ­Originæ¶æ„
            result["note"] = "æ–‡ä»¶å·²ç›´æ¥è¾“å‡ºåˆ°ğŸ­Originæ¶æ„ (ğŸ¬Slice/{è§†é¢‘å}/slices/)"
            
            return [types.TextContent(type="text", text=json.dumps(result, indent=2, ensure_ascii=False))]
            
        except Exception as e:
            if 'original_cwd' in locals():
                os.chdir(original_cwd)
            return [types.TextContent(type="text", text=f"é”™è¯¯: {str(e)}")]
    
    elif name == "video_to_srt":
        try:
            original_cwd = os.getcwd()
            os.chdir(project_root / "video_to_srt")
            
            sys.path.insert(0, str(project_root / "video_to_srt" / "src"))
            from batch_video_to_srt import BatchVideoTranscriber
            from env_loader import get_dashscope_api_key, get_default_vocab_id
            
            input_dir = arguments["input_dir"]
            output_dir = arguments.get("output_dir", "./data/output")
            
            api_key = get_dashscope_api_key()
            if not api_key:
                raise ValueError("DashScope APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®")
            
            transcriber = BatchVideoTranscriber(api_key=api_key)
            
            result = transcriber.batch_process(
                input_dir=input_dir,
                output_dir=output_dir,
                supported_formats=[".mp4", ".mov", ".avi", ".mkv", ".webm"],
                preset_vocabulary_id=get_default_vocab_id()
            )
            
            os.chdir(original_cwd)
            
            result["note"] = "æ–‡ä»¶å·²ç›´æ¥è¾“å‡ºåˆ°ğŸ­Originæ¶æ„ (ğŸ“„SRT/{è§†é¢‘å}/{è§†é¢‘å}_full.srt)"
            
            return [types.TextContent(type="text", text=json.dumps(result, indent=2, ensure_ascii=False))]
            
        except Exception as e:
            if 'original_cwd' in locals():
                os.chdir(original_cwd)
            return [types.TextContent(type="text", text=f"é”™è¯¯: {str(e)}")]
    
    elif name == "srt_to_product":
        try:
            original_cwd = os.getcwd()
            os.chdir(project_root / "srt_to_product")
            
            sys.path.insert(0, str(project_root / "srt_to_product" / "src"))
            from batch_srt_to_product import BatchSRTToProductProcessor
            from env_loader import get_deepseek_api_key
            
            srt_dir = arguments["srt_dir"]
            output_dir = arguments.get("output_dir", "./data/output")
            input_video_dir = arguments.get("input_video_dir", "../video_to_srt/data/input")
            
            api_key = get_deepseek_api_key()
            if not api_key:
                raise ValueError("DeepSeek APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®")
            
            processor = BatchSRTToProductProcessor(
                input_video_dir=input_video_dir,
                api_key=api_key
            )
            
            result = processor.batch_process(
                srt_dir=srt_dir,
                output_dir=output_dir
            )
            
            os.chdir(original_cwd)
            
            result["note"] = "æ–‡ä»¶å·²ç›´æ¥è¾“å‡ºåˆ°ğŸ­Originæ¶æ„ (ğŸ¬Slice/{è§†é¢‘å}/product/ + ğŸ“„SRT/{è§†é¢‘å}/{è§†é¢‘å}_product.srt)"
            
            return [types.TextContent(type="text", text=json.dumps(result, indent=2, ensure_ascii=False))]
            
        except Exception as e:
            if 'original_cwd' in locals():
                os.chdir(original_cwd)
            return [types.TextContent(type="text", text=f"é”™è¯¯: {str(e)}")]
    
    elif name == "slice_to_label":
        try:
            original_cwd = os.getcwd()
            os.chdir(project_root / "slice_to_label")
            
            # ğŸ¤– æ£€æŸ¥æ¨¡å‹å‡çº§å†³ç­–
            upgrade_decision_file = project_root / "feishu_pool" / "model_upgrade_decision.json"
            use_gemini_upgrade = False
            
            if upgrade_decision_file.exists():
                try:
                    import json
                    with open(upgrade_decision_file, 'r', encoding='utf-8') as f:
                        decision_data = json.load(f)
                    use_gemini_upgrade = decision_data.get("upgrade_decision", False)
                    
                    if use_gemini_upgrade:
                        print(f"ğŸ”¥ æ£€æµ‹åˆ°æ¨¡å‹å‡çº§å†³ç­–ï¼Œå°†ä½¿ç”¨Geminié«˜ç²¾åº¦åˆ†æ")
                        print(f"ğŸ“Š å‡çº§åŸå› : {decision_data.get('upgrade_reason', 'unknown')}")
                    else:
                        print(f"âœ… ä½¿ç”¨æ ‡å‡†Qwenæ¨¡å‹è¿›è¡Œåˆ†æ")
                except Exception as e:
                    print(f"âš ï¸  è¯»å–æ¨¡å‹å‡çº§å†³ç­–æ–‡ä»¶å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤Qwenæ¨¡å‹")
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ä¾›åˆ†æå™¨ä½¿ç”¨
            import os
            os.environ["USE_GEMINI_UPGRADE"] = "true" if use_gemini_upgrade else "false"
            
            sys.path.insert(0, str(project_root / "slice_to_label"))
            from run_analysis import main as run_slice_analysis
            
            slice_dir = arguments.get("slice_dir", "../ğŸ¬Slice")
            video_name = arguments.get("video_name")
            slice_type = arguments.get("slice_type", "slices")
            analysis_type = arguments.get("analysis_type", "dual")
            
            # æ„å»ºå‚æ•°
            args = type('Args', (), {
                'slice_dir': slice_dir,
                'video_name': video_name,
                'slice_type': slice_type,
                'analysis_type': analysis_type
            })()
            
            result = await asyncio.to_thread(run_slice_analysis, args)
            
            os.chdir(original_cwd)
            
            return [types.TextContent(type="text", text=json.dumps(result, indent=2, ensure_ascii=False))]
            
        except Exception as e:
            if 'original_cwd' in locals():
                os.chdir(original_cwd)
            return [types.TextContent(type="text", text=f"é”™è¯¯: {str(e)}")]
    
    elif name == "reclassify_main_labels":
        try:
            original_cwd = os.getcwd()
            os.chdir(project_root / "feishu_pool")
            
            # ğŸ¤– æ£€æŸ¥ä¸»æ ‡ç­¾æ¨¡å‹å‡çº§å†³ç­–
            upgrade_decision_file = project_root / "feishu_pool" / "main_tag_model_upgrade_decision.json"
            use_enhanced_main_tag = False
            
            if upgrade_decision_file.exists():
                try:
                    import json
                    with open(upgrade_decision_file, 'r', encoding='utf-8') as f:
                        decision_data = json.load(f)
                    use_enhanced_main_tag = decision_data.get("upgrade_decision", False)
                    
                    if use_enhanced_main_tag:
                        print(f"ğŸ”¥ æ£€æµ‹åˆ°ä¸»æ ‡ç­¾æ¨¡å‹å‡çº§å†³ç­–ï¼Œå°†é€šè¿‡OpenRouterä½¿ç”¨Claudeè¿›è¡Œåˆ†ç±»")
                        print(f"ğŸ“Š å‡çº§åŸå› : {decision_data.get('upgrade_reason', 'unknown')}")
                    else:
                        print(f"âœ… ä½¿ç”¨æ ‡å‡†DeepSeekæ¨¡å‹è¿›è¡Œä¸»æ ‡ç­¾åˆ†ç±»")
                except Exception as e:
                    print(f"âš ï¸  è¯»å–ä¸»æ ‡ç­¾æ¨¡å‹å‡çº§å†³ç­–æ–‡ä»¶å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤DeepSeekæ¨¡å‹")
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ä¾›ä¸»æ ‡ç­¾åˆ†æå™¨ä½¿ç”¨
            import os
            os.environ["USE_ENHANCED_MAIN_TAG"] = "true" if use_enhanced_main_tag else "false"
            
            sys.path.insert(0, str(project_root / "feishu_pool"))
                            # ä¸»æ ‡ç­¾åˆ†ç±»åŠŸèƒ½å·²ç§»è‡³ label_to_classifier æ¨¡å—
                # from deepseek_tag_classifier import DeepSeekTagClassifier
            from optimized_data_pool import OptimizedDataPoolManager
            
            target_model = arguments.get("target_model", "deepseek-chat")
            min_confidence = arguments.get("min_confidence", 0.5)
            batch_size = arguments.get("batch_size", 10)
            reason = arguments.get("reason", "åŸºäºCursoråˆ†æçš„ä¸»æ ‡ç­¾é‡æ–°åˆ†ç±»")
            
            # åˆå§‹åŒ–æ•°æ®æ± ç®¡ç†å™¨
            pool_manager = OptimizedDataPoolManager()
            
            # æ£€æŸ¥è¿æ¥
            if not pool_manager.test_connection():
                raise ValueError("æ— æ³•è¿æ¥åˆ°é£ä¹¦æ•°æ®æ± ")
            
            # ä¸»æ ‡ç­¾åˆ†ç±»åŠŸèƒ½å·²ç§»è‡³ label_to_classifier æ¨¡å—
            result = {
                "status": "redirected",
                "message": "ä¸»æ ‡ç­¾åˆ†ç±»åŠŸèƒ½å·²ç§»è‡³ label_to_classifier æ¨¡å—",
                "recommendation": "è¯·ä½¿ç”¨ label_to_classifier/run.py è¿›è¡Œä¸»æ ‡ç­¾é‡æ–°åˆ†ç±»",
                "location": str(project_root / "label_to_classifier"),
                "command": "cd ../label_to_classifier && python run.py --force-reprocess"
            }
            
            # æ·»åŠ æœ¬æ¬¡æ“ä½œçš„å…ƒä¿¡æ¯
            result["operation_info"] = {
                "reason": reason,
                "target_model": target_model,
                "min_confidence": min_confidence,
                "batch_size": batch_size,
                "timestamp": asyncio.get_event_loop().time()
            }
            
            result["note"] = "ä¸»æ ‡ç­¾é‡æ–°åˆ†ç±»å®Œæˆï¼Œç»“æœå·²åŒæ­¥åˆ°é£ä¹¦æ•°æ®åº“"
            
            os.chdir(original_cwd)
            
            return [types.TextContent(type="text", text=json.dumps(result, indent=2, ensure_ascii=False))]
            
        except Exception as e:
            if 'original_cwd' in locals():
                os.chdir(original_cwd)
            return [types.TextContent(type="text", text=f"ä¸»æ ‡ç­¾é‡æ–°åˆ†ç±»é”™è¯¯: {str(e)}")]
    
    elif name == "optimize_prompts":
        try:
            original_cwd = os.getcwd()
            
            feedback_file = arguments.get("feedback_file", "video_segment_feedback.json")
            optimization_type = arguments.get("optimization_type", "both")
            reason = arguments.get("reason", "åŸºäºCursoræ™ºèƒ½åˆ†æçš„æç¤ºè¯ä¼˜åŒ–")
            force_optimize = arguments.get("force_optimize", False)
            
            # ç¡®ä¿åé¦ˆæ–‡ä»¶è·¯å¾„æ˜¯ç»å¯¹è·¯å¾„
            if not os.path.isabs(feedback_file):
                feedback_file = os.path.join(project_root, feedback_file)
            
            if not os.path.exists(feedback_file):
                return [types.TextContent(type="text", text=f"âŒ åé¦ˆæ–‡ä»¶ä¸å­˜åœ¨: {feedback_file}")]
            
            result = {
                "optimization_time": asyncio.get_event_loop().time(),
                "feedback_file": feedback_file,
                "optimization_type": optimization_type,
                "reason": reason,
                "force_optimize": force_optimize,
                "visual_labels_result": None,
                "main_tags_result": None,
                "summary": {}
            }
            
            # ğŸ¬ è§†è§‰åˆ†ææç¤ºè¯ä¼˜åŒ–
            if optimization_type in ["visual_labels", "both"]:
                try:
                    os.chdir(project_root / "slice_to_label")
                    sys.path.insert(0, str(project_root / "slice_to_label" / "config"))
                    
                    from prompt_templates import optimize_prompts_from_feedback
                    
                    print(f"ğŸ”§ å¼€å§‹ä¼˜åŒ–è§†è§‰åˆ†ææç¤ºè¯...")
                    visual_result = optimize_prompts_from_feedback(feedback_file, reason)
                    
                    result["visual_labels_result"] = visual_result
                    optimized_count = sum(1 for optimized in visual_result.values() if optimized)
                    
                    print(f"âœ… è§†è§‰åˆ†ææç¤ºè¯ä¼˜åŒ–å®Œæˆ: {optimized_count}/{len(visual_result)} ä¸ªæ¨¡æ¿å·²ä¼˜åŒ–")
                    
                except Exception as e:
                    result["visual_labels_result"] = {"error": str(e)}
                    print(f"âŒ è§†è§‰åˆ†ææç¤ºè¯ä¼˜åŒ–å¤±è´¥: {e}")
            
            # ğŸ·ï¸ ä¸»æ ‡ç­¾æç¤ºè¯ä¼˜åŒ–ï¼ˆç°åœ¨ä½¿ç”¨label_to_classifieræ¨¡å—ï¼‰
            if optimization_type in ["main_tags", "both"]:
                try:
                    os.chdir(project_root / "label_to_classifier" / "src")
                    sys.path.insert(0, str(project_root / "label_to_classifier" / "src"))
                    
                    from primary_ai_classifier import optimize_main_tag_prompts_from_feedback
                    
                    print(f"ğŸ¯ å¼€å§‹ä¼˜åŒ–ä¸»æ ‡ç­¾æç¤ºè¯...")
                    main_tag_result = optimize_main_tag_prompts_from_feedback(feedback_file, reason)
                    
                    result["main_tags_result"] = main_tag_result
                    
                    if main_tag_result:
                        print(f"âœ… ä¸»æ ‡ç­¾æç¤ºè¯ä¼˜åŒ–å®Œæˆ")
                    else:
                        print(f"â„¹ï¸  ä¸»æ ‡ç­¾æç¤ºè¯è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ä¼˜åŒ–")
                        
                except Exception as e:
                    result["main_tags_result"] = {"error": str(e)}
                    print(f"âŒ ä¸»æ ‡ç­¾æç¤ºè¯ä¼˜åŒ–å¤±è´¥: {e}")
            
            # ç”Ÿæˆæ€»ç»“
            visual_optimized = 0
            if result["visual_labels_result"] and isinstance(result["visual_labels_result"], dict):
                visual_optimized = sum(1 for v in result["visual_labels_result"].values() if v is True)
            
            main_tag_optimized = bool(result["main_tags_result"])
            
            result["summary"] = {
                "total_optimizations": visual_optimized + (1 if main_tag_optimized else 0),
                "visual_labels_optimized": visual_optimized,
                "main_tags_optimized": main_tag_optimized,
                "success": True
            }
            
            result["note"] = f"Cursoræ™ºèƒ½æç¤ºè¯ä¼˜åŒ–å®Œæˆ - è§†è§‰åˆ†æ: {visual_optimized}ä¸ªæ¨¡æ¿, ä¸»æ ‡ç­¾: {'å·²ä¼˜åŒ–' if main_tag_optimized else 'æ— éœ€ä¼˜åŒ–'}"
            
            os.chdir(original_cwd)
            
            return [types.TextContent(type="text", text=json.dumps(result, indent=2, ensure_ascii=False))]
            
        except Exception as e:
            if 'original_cwd' in locals():
                os.chdir(original_cwd)
            return [types.TextContent(type="text", text=f"æç¤ºè¯ä¼˜åŒ–é”™è¯¯: {str(e)}")]
    
    else:
        return [types.TextContent(type="text", text=f"æœªçŸ¥å·¥å…·: {name}")]

async def run():
    """è¿è¡ŒæœåŠ¡å™¨"""
    async with mcp.server.stdio.stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="ai-video-master",
                server_version="1.9.4",
                capabilities=server.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                ),
            ),
        )

if __name__ == "__main__":
    asyncio.run(run()) 