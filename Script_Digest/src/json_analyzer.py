#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘åˆ‡ç‰‡JSONåˆ†æå™¨
è´Ÿè´£æ‰«æç›®å½•ï¼Œè¯»å–å¹¶è§£ææ‰€æœ‰ ..._analysis.json æ–‡ä»¶ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚
"""

import os
import json
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional

logger = logging.getLogger(__name__)

class JsonAnalyzer:
    """
    åˆ†æå’Œç®¡ç†è§†é¢‘åˆ‡ç‰‡JSONæ–‡ä»¶çš„ç±»ã€‚
    """

    def __init__(self, json_directory: str):
        """
        åˆå§‹åŒ–JSONåˆ†æå™¨ã€‚

        Args:
            json_directory (str): å­˜æ”¾ ..._analysis.json æ–‡ä»¶çš„ç›®å½•è·¯å¾„ã€‚
        """
        self.json_dir = Path(json_directory)
        if not self.json_dir.is_dir():
            logger.error(f"âŒ æŒ‡å®šçš„JSONç›®å½•ä¸å­˜åœ¨æˆ–ä¸æ˜¯ä¸€ä¸ªç›®å½•: {json_directory}")
            raise FileNotFoundError(f"JSON directory not found: {json_directory}")
        
        self.video_slice_data: List[Dict[str, Any]] = []
        logger.info(f"âœ… JSONåˆ†æå™¨åˆå§‹åŒ–å®Œæˆï¼Œç›®æ ‡ç›®å½•: {self.json_dir}")

    def scan_and_parse_all(self) -> int:
        """
        æ‰«æç›®å½•ä¸‹çš„æ‰€æœ‰ `..._analysis.json` æ–‡ä»¶å¹¶è§£æå®ƒä»¬ã€‚

        Returns:
            int: æˆåŠŸè§£æçš„æ–‡ä»¶æ•°é‡ã€‚
        """
        logger.info(f"ğŸš€ å¼€å§‹æ‰«æç›®å½•: {self.json_dir}")
        json_files = list(self.json_dir.glob("*_analysis.json"))

        if not json_files:
            logger.warning(f"âš ï¸ åœ¨ç›®å½• {self.json_dir} ä¸­æœªæ‰¾åˆ° `..._analysis.json` æ–‡ä»¶ã€‚")
            return 0

        logger.info(f"ğŸ” å‘ç°äº† {len(json_files)} ä¸ªJSONæ–‡ä»¶ï¼Œå¼€å§‹è§£æ...")
        
        parsed_count = 0
        for file_path in json_files:
            parsed_data = self._parse_single_json(file_path)
            if parsed_data:
                self.video_slice_data.append(parsed_data)
                parsed_count += 1
        
        logger.info(f"âœ… å®Œæˆè§£æï¼ŒæˆåŠŸå¤„ç†äº† {parsed_count}/{len(json_files)} ä¸ªæ–‡ä»¶ã€‚")
        self.video_slice_data.sort(key=lambda x: x.get('confidence', 0), reverse=True)
        return parsed_count

    def _parse_single_json(self, file_path: Path) -> Optional[Dict[str, Any]]:
        """
        è§£æå•ä¸ªJSONæ–‡ä»¶ï¼Œå¹¶æå–å…³é”®ä¿¡æ¯ã€‚

        Args:
            file_path (Path): JSONæ–‡ä»¶çš„è·¯å¾„ã€‚

        Returns:
            Optional[Dict[str, Any]]: åŒ…å«å…³é”®ä¿¡æ¯çš„å­—å…¸ï¼Œå¦‚æœè§£æå¤±è´¥åˆ™è¿”å›Noneã€‚
        """
        try:
            with file_path.open('r', encoding='utf-8') as f:
                data = json.load(f)

            if not data.get("success", False):
                logger.warning(f"â­ï¸ è·³è¿‡æ–‡ä»¶ {file_path.name}ï¼Œå› ä¸º 'success' æ ‡è®°ä¸º falseã€‚")
                return None
            
            # æå–æˆ‘ä»¬å…³å¿ƒçš„å­—æ®µï¼Œæä¾›é»˜è®¤å€¼ä»¥é¿å…KeyError
            extracted = {
                "file_path": data.get("file_path", ""),
                "file_name": data.get("file_name", ""),
                "object": data.get("object", "æœªçŸ¥"),
                "scene": data.get("scene", "æœªçŸ¥"),
                "emotion": data.get("emotion", "æœªçŸ¥"),
                "main_tag": data.get("analysis", {}).get("predicted_category", "æœªçŸ¥"),
                "secondary_category": data.get("secondary_category", "æœªçŸ¥"),
                "reasoning": data.get("analysis", {}).get("reasoning", ""),
                "matched_keywords": data.get("analysis", {}).get("matched_keywords", []),
                "confidence": data.get("confidence", 0.0),
                "source_json_path": str(file_path.resolve()) # ä¿å­˜åŸå§‹jsonæ–‡ä»¶è·¯å¾„
            }
            return extracted
        except json.JSONDecodeError:
            logger.error(f"âŒ è§£æJSONæ–‡ä»¶å¤±è´¥ (æ ¼å¼é”™è¯¯): {file_path.name}")
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ–‡ä»¶ {file_path.name} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
        
        return None

    def get_all_slices(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰å·²è§£æçš„è§†é¢‘åˆ‡ç‰‡æ•°æ®ã€‚

        Returns:
            List[Dict[str, Any]]: è§†é¢‘åˆ‡ç‰‡æ•°æ®åˆ—è¡¨ã€‚
        """
        return self.video_slice_data

    def get_slice_by_filename(self, filename: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®è§†é¢‘æ–‡ä»¶åæŸ¥æ‰¾å¯¹åº”çš„åˆ‡ç‰‡æ•°æ®ã€‚

        Args:
            filename (str): è§†é¢‘æ–‡ä»¶å (ä¾‹å¦‚ "video_01.mp4")ã€‚

        Returns:
            Optional[Dict[str, Any]]: æ‰¾åˆ°çš„è§†é¢‘åˆ‡ç‰‡æ•°æ®ï¼Œå¦åˆ™ä¸ºNoneã€‚
        """
        for slice_data in self.video_slice_data:
            if slice_data['file_name'] == filename:
                return slice_data
        return None

if __name__ == "__main__":
    # --- æµ‹è¯•JSONåˆ†æå™¨ ---
    print("ğŸ§ª æµ‹è¯•è§†é¢‘åˆ‡ç‰‡JSONåˆ†æå™¨...")

    # å‡è®¾é¡¹ç›®æ ¹ç›®å½•æ˜¯ "Script_Digest" çš„ä¸Šä¸¤çº§ç›®å½•
    project_root = Path(__file__).parent.parent.resolve()
    # ä½¿ç”¨ç”¨æˆ·æä¾›çš„ç¤ºä¾‹JSONæ–‡ä»¶æ‰€åœ¨çš„ç›®å½•
    test_json_dir = project_root / "ğŸ­Origin"
    
    print(f"ğŸ“ æµ‹è¯•ç›®æ ‡ç›®å½•: {test_json_dir}")

    if not test_json_dir.exists():
        print(f"âŒ æµ‹è¯•ç›®å½•ä¸å­˜åœ¨ï¼Œæµ‹è¯•ä¸­æ­¢ã€‚")
        # åˆ›å»ºä¸€ä¸ªå‡çš„jsonæ–‡ä»¶ç”¨äºæµ‹è¯•
        print("ğŸ’¡ æ­£åœ¨åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„æµ‹è¯•JSONæ–‡ä»¶...")
        test_json_dir.mkdir(parents=True, exist_ok=True)
        temp_file = test_json_dir / "temp_test_analysis.json"
        temp_data = {
          "object": "å®å®è¶´åœ¨åœ°ä¸Š", "scene": "å®¤å†…", "emotion": "å¹³é™", "brand_elements": "æ— ",
          "success": True, "file_path": "/path/to/video.mp4", "file_name": "video.mp4",
          "confidence": 0.8, "analysis": {"predicted_category": "å®å®çŠ¶æ€", "reasoning": "å®å®å¾ˆå¯çˆ±", "matched_keywords": ["å®å®", "è¶´"]}
        }
        with temp_file.open('w', encoding='utf-8') as f:
            json.dump(temp_data, f)
    else:
        print("âœ… æµ‹è¯•ç›®å½•å·²æ‰¾åˆ°ã€‚")

    # 1. åˆå§‹åŒ–åˆ†æå™¨
    try:
        analyzer = JsonAnalyzer(str(test_json_dir))
        print("âœ… åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸã€‚")

        # 2. æ‰«æå¹¶è§£æ
        num_parsed = analyzer.scan_and_parse_all()

        # 3. æ‰“å°ç»“æœ
        if num_parsed > 0:
            print(f"\nğŸ‰ æˆåŠŸè§£æäº† {num_parsed} ä¸ªJSONæ–‡ä»¶ã€‚")
            all_slices = analyzer.get_all_slices()
            
            print("\n--- è§£ææ•°æ®ç¤ºä¾‹ (ç¬¬ä¸€ä¸ª) ---")
            # ä½¿ç”¨json.dumpsç¾åŒ–è¾“å‡º
            print(json.dumps(all_slices[0], indent=2, ensure_ascii=False))

            print(f"\n--- æ‘˜è¦ä¿¡æ¯ ---")
            print(f"  - æ–‡ä»¶å: {all_slices[0]['file_name']}")
            print(f"  - ç½®ä¿¡åº¦: {all_slices[0]['confidence']}")
            print(f"  - ä¸»è¦å¯¹è±¡: {all_slices[0]['object']}")
            print(f"  - ä¸»è¦æ ‡ç­¾: {all_slices[0]['main_tag']}")

        else:
            print("\nâŒ æœªèƒ½è§£æä»»ä½•JSONæ–‡ä»¶ã€‚è¯·æ£€æŸ¥ç›®å½•å’Œæ–‡ä»¶å†…å®¹ã€‚")

    except FileNotFoundError as e:
        print(f"\nâŒ åˆå§‹åŒ–å¤±è´¥: {e}")

    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if 'temp_file' in locals() and temp_file.exists():
        temp_file.unlink()
        print("\nğŸ—‘ï¸ å·²æ¸…ç†ä¸´æ—¶æµ‹è¯•æ–‡ä»¶ã€‚")

