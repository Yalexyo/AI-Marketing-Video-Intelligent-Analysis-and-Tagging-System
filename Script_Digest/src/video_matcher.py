#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘åŒ¹é…å™¨
è´Ÿè´£å°†è„šæœ¬æ®µè½ä¸è§†é¢‘åˆ‡ç‰‡è¿›è¡Œæ™ºèƒ½åŒ¹é…ï¼Œé›†æˆAIåˆ†æå’Œé¢„ç­›é€‰ä¼˜åŒ–ã€‚
"""

import os
import json
import logging
import shutil
from pathlib import Path
from typing import Dict, List, Any, Optional

# ç¡®ä¿å¯ä»¥ä»srcç›®å½•å¯¼å…¥å…¶ä»–æ¨¡å—
try:
    from config.dynamic_match_config import DynamicMatchConfig
    from deepseek_client import DeepSeekClient
except ImportError:
    # å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œéœ€è¦å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°sys.path
    import sys
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    sys.path.insert(0, project_root)
    from config.dynamic_match_config import DynamicMatchConfig
    from src.deepseek_client import DeepSeekClient

logger = logging.getLogger(__name__)

class VideoMatcher:
    """
    è§†é¢‘åŒ¹é…å™¨ï¼Œè´Ÿè´£å°†è„šæœ¬æ®µè½ä¸è§†é¢‘åˆ‡ç‰‡è¿›è¡Œæ™ºèƒ½åŒ¹é…ã€‚
    """

    def __init__(self, 
                 enable_pre_filter: bool = True, 
                 keyword_threshold: float = 0.15,
                 output_dir: Optional[str] = None,
                 enable_reference_copy: bool = True):
        """
        åˆå§‹åŒ–è§†é¢‘åŒ¹é…å™¨ã€‚

        Args:
            enable_pre_filter (bool): æ˜¯å¦å¯ç”¨å…³é”®è¯é¢„ç­›é€‰ä¼˜åŒ–
            keyword_threshold (float): å…³é”®è¯é‡å é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„è§†é¢‘å°†è¢«è¿‡æ»¤
            output_dir (Optional[str]): è¾“å‡ºç›®å½•è·¯å¾„ï¼Œç”¨äºé¢„ç­›é€‰æ–‡ä»¶å¤åˆ¶
            enable_reference_copy (bool): æ˜¯å¦å¯ç”¨é¢„ç­›é€‰æ–‡ä»¶å¤åˆ¶åˆ°ã€å‚è€ƒã€‘æ–‡ä»¶å¤¹
                """
        self.config = DynamicMatchConfig()
        self.ai_client = DeepSeekClient()
        self.match_results: List[Dict[str, Any]] = []
        
        # é¢„ç­›é€‰é…ç½®
        self.enable_pre_filter = enable_pre_filter
        self.keyword_threshold = keyword_threshold
        
        # æ–‡ä»¶å¤åˆ¶é…ç½®
        self.output_dir = Path(output_dir) if output_dir else None
        self.enable_reference_copy = enable_reference_copy
        
        logger.info(f"âœ… è§†é¢‘åŒ¹é…å™¨åˆå§‹åŒ–å®Œæˆ")
        if enable_pre_filter:
            logger.info(f"ğŸ” å·²å¯ç”¨å…³é”®è¯é¢„ç­›é€‰ (é˜ˆå€¼: {keyword_threshold:.2f})")
        if enable_reference_copy and output_dir:
            logger.info(f"ğŸ“ å·²å¯ç”¨é¢„ç­›é€‰æ–‡ä»¶å¤åˆ¶åˆ°ã€å‚è€ƒã€‘æ–‡ä»¶å¤¹")

    def match_script_to_videos(
        self,
        analyzed_script: List[Dict[str, Any]],
        video_slices: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        å°†è„šæœ¬æ®µè½ä¸è§†é¢‘åˆ‡ç‰‡è¿›è¡ŒåŒ¹é…ã€‚

        Args:
            analyzed_script (List[Dict[str, Any]]): å·²åˆ†æçš„è„šæœ¬æ®µè½åˆ—è¡¨
            video_slices (List[Dict[str, Any]]): è§†é¢‘åˆ‡ç‰‡æ•°æ®åˆ—è¡¨

        Returns:
            List[Dict[str, Any]]: åŒ¹é…ç»“æœåˆ—è¡¨
        """
        if not self.ai_client:
            logger.error("âŒ DeepSeekå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•è¿›è¡ŒåŒ¹é…ã€‚")
            return []
            
        if not analyzed_script or not video_slices:
            logger.warning("âš ï¸ è„šæœ¬æˆ–è§†é¢‘æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡ŒåŒ¹é…ã€‚")
            return []

        logger.info(f"ğŸš€ å¼€å§‹ä¸º {len(analyzed_script)} ä¸ªè„šæœ¬æ®µè½åŒ¹é… {len(video_slices)} ä¸ªè§†é¢‘åˆ‡ç‰‡...")
        if self.enable_pre_filter:
            logger.info(f"ğŸ” é¢„ç­›é€‰æ¨¡å¼ï¼šå°†å…ˆè¿›è¡Œå…³é”®è¯åŒ¹é…è¿‡æ»¤")
        
        self.match_results = []
        total_ai_calls = 0
        total_filtered = 0

        for i, segment in enumerate(analyzed_script, 1):
            logger.info(f"--- æ­£åœ¨å¤„ç†ç¬¬ {i}/{len(analyzed_script)} ä¸ªè„šæœ¬æ®µè½: ID={segment['id']} ---")
            
            # é¢„ç­›é€‰æ­¥éª¤
            if self.enable_pre_filter:
                filtered_videos = self._pre_filter_videos(segment, video_slices)
                filtered_count = len(video_slices) - len(filtered_videos)
                total_filtered += filtered_count
                logger.info(f"ğŸ” é¢„ç­›é€‰ï¼š{len(video_slices)} â†’ {len(filtered_videos)} ä¸ªè§†é¢‘ (è¿‡æ»¤æ‰ {filtered_count} ä¸ª)")
                
                # å¤åˆ¶é¢„ç­›é€‰é€šè¿‡çš„è§†é¢‘åˆ°ã€å‚è€ƒã€‘æ–‡ä»¶å¤¹
                self._copy_prefiltered_videos_to_reference(segment, filtered_videos)
                
                videos_to_process = filtered_videos
            else:
                videos_to_process = video_slices
            
            best_matches_for_segment = self._find_best_matches_for_segment(segment, videos_to_process)
            total_ai_calls += len(videos_to_process)
            
            # ä¿å­˜é€šè¿‡AIåŒ¹é…çš„è§†é¢‘ä¿¡æ¯åˆ°pass.json
            self._save_passed_videos_to_json(segment, best_matches_for_segment)
            
            if best_matches_for_segment:
                self.match_results.append({
                    "segment_id": segment['id'],
                    "segment_content": segment['content'],
                    "best_matches": best_matches_for_segment
                })
        
        if self.enable_pre_filter:
            efficiency_gain = (total_filtered / (len(analyzed_script) * len(video_slices))) * 100
            logger.info(f"ğŸ¯ é¢„ç­›é€‰æ•ˆæœï¼šæ€»å…±è¿‡æ»¤æ‰ {total_filtered} æ¬¡AIè°ƒç”¨ï¼Œæ•ˆç‡æå‡ {efficiency_gain:.1f}%")
            logger.info(f"ğŸ“Š å®é™…AIè°ƒç”¨æ¬¡æ•°: {total_ai_calls} (vs åŸæœ¬ {len(analyzed_script) * len(video_slices)})")
        
        logger.info(f"âœ… å®Œæˆæ‰€æœ‰åŒ¹é…ï¼Œå…±ä¸º {len(self.match_results)} ä¸ªæ®µè½æ‰¾åˆ°äº†åŒ¹é…ã€‚")
        return self.match_results

    def _pre_filter_videos(
        self, 
        segment: Dict[str, Any], 
        video_slices: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        åŸºäºå…³é”®è¯é‡å åº¦é¢„ç­›é€‰è§†é¢‘ï¼Œè¿‡æ»¤æ‰æ˜æ˜¾ä¸ç›¸å…³çš„è§†é¢‘ã€‚

        Args:
            segment (Dict[str, Any]): è„šæœ¬æ®µè½æ•°æ®
            video_slices (List[Dict[str, Any]]): æ‰€æœ‰è§†é¢‘åˆ‡ç‰‡

        Returns:
            List[Dict[str, Any]]: é€šè¿‡é¢„ç­›é€‰çš„è§†é¢‘åˆ—è¡¨
        """
        segment_keywords = set(segment.get('keywords', []))
        if not segment_keywords:
            logger.warning(f"âš ï¸ æ®µè½ {segment['id']} æ²¡æœ‰å…³é”®è¯ï¼Œè·³è¿‡é¢„ç­›é€‰")
            return video_slices
        
        # ğŸ¯ åŠ¨æ€è°ƒæ•´é˜ˆå€¼ï¼šä¿ƒé”€é€¼å•å†…å®¹ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼
        promotion_keywords = {'é€‰å¥¶', 'è¯•é”™', 'å†²äº†', 'ä¿ƒé”€', 'é€¼å•', 'å…³é”®', 'ä¸è¯•é”™'}
        current_threshold = self.keyword_threshold
        
        if segment_keywords & promotion_keywords:
            current_threshold = max(0.05, self.keyword_threshold - 0.1)  # é™ä½é˜ˆå€¼ä½†ä¸ä½äº0.05
            logger.info(f"ğŸ æ£€æµ‹åˆ°ä¿ƒé”€é€¼å•å†…å®¹ï¼Œè°ƒæ•´é¢„ç­›é€‰é˜ˆå€¼: {self.keyword_threshold:.2f} â†’ {current_threshold:.2f}")
        
        # è¯­ä¹‰ç›¸ä¼¼è¯æ˜ å°„
        semantic_mapping = {
            'å–‚å…»': ['å–‚å¥¶', 'å¥¶ç“¶', 'å“ºä¹³', 'æ¯ä¹³å–‚å…»', 'å–‚é£Ÿ', 'åƒå¥¶', 'å–å¥¶', 'å–‚å®å®', 'æ¸©æŸ”å–‚', 'çˆ¸çˆ¸æ¸©æŸ”å–‚'],
            'å®å®': ['å©´å„¿', 'å°å­©', 'å­©å­', 'å°æœ‹å‹', 'å¨ƒå¨ƒ', 'å®å®å–å¥¶', 'å®å®å–', 'å®å®åƒ'],
            'å¦ˆå¦ˆ': ['æ¯äº²', 'å¦ˆå’ª', 'å¥³äºº', 'å¥³æ€§', 'çˆ¸çˆ¸', 'çˆ¶äº²'],  # æ·»åŠ çˆ¶äº²ç›¸å…³
            'å¥¶ç²‰': ['é…æ–¹å¥¶', 'å©´å¹¼å„¿å¥¶ç²‰', 'ç‰›å¥¶ç²‰', 'å¯èµ‹', 'æƒ æ°', 'è•´æ·³'],
            'å¯èµ‹': ['å¯èµ‹å¥¶ç²‰', 'æƒ æ°å¯èµ‹', 'å¯èµ‹è•´æ·³'],
            'æƒ æ°': ['æƒ æ°å¥¶ç²‰', 'æƒ æ°å“ç‰Œ', 'æƒ æ°å¯èµ‹'],
            'ç”Ÿï¼': ['ç”Ÿ', 'å‡ºç”Ÿ', 'æ–°ç”Ÿ', 'è¯ç”Ÿ'],  # ä¸ºç‰¹æ®Šå…³é”®è¯æ·»åŠ æ˜ å°„
            'ç‹—éƒ½ä¸': ['ç‹—éƒ½', 'éƒ½ä¸', 'å¦å®š', 'æ‹’ç»'],  # ä¸ºç‰¹æ®Šå…³é”®è¯æ·»åŠ æ˜ å°„
            
            # ğŸ¯ æ–°å¢ï¼šä¿ƒé”€æœºåˆ¶å’Œé€¼å•è„šæœ¬ç›¸å…³å…³é”®è¯æ˜ å°„
            'é€‰å¥¶': ['é€‰æ‹©', 'å¥¶ç²‰', 'äº§å“å±•ç¤º', 'æ¨è', 'å»ºè®®', 'é€‰æ‹©å¥¶ç²‰', 'æŒ‘é€‰'],
            'è¯•é”™': ['å°è¯•', 'é”™è¯¯', 'é€‰æ‹©', 'å†³å®š', 'æµ‹è¯•'],
            'å†²äº†': ['å†²', 'è¡ŒåŠ¨', 'å†³å®š', 'è´­ä¹°', 'é€‰æ‹©', 'é©¬ä¸Š', 'ç«‹å³', 'èµ¶ç´§'],
            'ä¿ƒé”€': ['ä¿ƒé”€', 'ä¼˜æƒ ', 'æ´»åŠ¨', 'é™æ—¶', 'ç‰¹ä»·', 'æŠ˜æ‰£', 'è´­ä¹°'],
            'é€¼å•': ['æ¨è', 'å»ºè®®', 'é€‰æ‹©', 'å†³å®š', 'é©¬ä¸Š', 'ç«‹å³', 'ä¸è¦é”™è¿‡'],
            'å…³é”®': ['é‡è¦', 'å…³é”®', 'æ ¸å¿ƒ', 'ä¸»è¦', 'å¿…é¡»', 'ä¸€å®šè¦'],
            'ä¸è¯•é”™': ['æ­£ç¡®é€‰æ‹©', 'ä¸€æ¬¡é€‰å¯¹', 'å‡†ç¡®', 'å¯é ', 'å€¼å¾—ä¿¡èµ–'],
            
            # ğŸ ä¿ƒé”€æœºåˆ¶æ ‡ç­¾ç›¸å…³æ˜ å°„
            'æ¸©é¦¨': ['æ¸©é¦¨', 'å®¶åº­', 'äº²å­', 'äº’åŠ¨', 'å’Œè°', 'å¹¸ç¦'],
            'å±•ç¤º': ['å±•ç¤º', 'ä»‹ç»', 'æ¨è', 'è¯´æ˜', 'æ¼”ç¤º'],
            'æ¬¢ä¹': ['å¼€å¿ƒ', 'å¿«ä¹', 'æ„‰å¿«', 'å–œæ‚¦', 'æ¬¢ä¹', 'é«˜å…´'],
            'ä¿¡æ¯': ['ä¿¡æ¯', 'å†…å®¹', 'ä»‹ç»', 'è¯´æ˜', 'å±•ç¤º']
        }
        
        filtered_videos = []
        
        for video in video_slices:
            # ä»è§†é¢‘JSONä¸­æå–å…³é”®è¯å’Œæ–‡æœ¬å†…å®¹
            video_keywords = set()
            video_text = ""
            
            # ä»ä¸åŒå­—æ®µæå–å…³é”®è¯
            if 'matched_keywords' in video:
                video_keywords.update(video['matched_keywords'])
            
            if 'object' in video:
                video_keywords.add(video['object'])
                video_text += " " + str(video['object'])
            
            if 'emotion' in video:
                video_keywords.add(video['emotion'])
                
            if 'main_tag' in video:
                video_keywords.add(video['main_tag'])
                
            if 'reasoning' in video:
                video_text += " " + str(video['reasoning'])
            
            # è®¡ç®—å…³é”®è¯é‡å åº¦ï¼ˆç›´æ¥åŒ¹é…ï¼‰
            direct_overlap = len(segment_keywords & video_keywords)
            
            # è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åŒ¹é…
            semantic_overlap = 0
            for seg_keyword in segment_keywords:
                if seg_keyword in semantic_mapping:
                    similar_words = semantic_mapping[seg_keyword]
                    # æ£€æŸ¥è§†é¢‘å…³é”®è¯æˆ–æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«ç›¸ä¼¼è¯
                    for similar_word in similar_words:
                        if similar_word in video_keywords or similar_word in video_text:
                            semantic_overlap += 1
                            break
            
            # æ€»é‡å åº¦ = ç›´æ¥åŒ¹é… + è¯­ä¹‰åŒ¹é…
            total_overlap = direct_overlap + semantic_overlap
            overlap_ratio = total_overlap / len(segment_keywords)
            
            # ç‰¹æ®Šå…³é”®è¯åŠ æƒ (å“ç‰Œåã€ä¸“ä¸šæœ¯è¯­ç­‰)
            important_keywords = {'å¯èµ‹', 'æƒ æ°', 'HMO', 'å¥¶ç²‰', 'å®å®', 'å¦ˆå¦ˆ', 'å–‚å…»'}
            important_overlap = len(segment_keywords & video_keywords & important_keywords)
            if important_overlap > 0:
                overlap_ratio += important_overlap * 0.2  # é‡è¦å…³é”®è¯åŠ æƒ
            
            # ğŸ¯ æ–°å¢ï¼šä¿ƒé”€æœºåˆ¶ç‰¹æ®ŠåŒ¹é…è§„åˆ™
            promotion_keywords = {'é€‰å¥¶', 'è¯•é”™', 'å†²äº†', 'ä¿ƒé”€', 'é€¼å•', 'å…³é”®', 'ä¸è¯•é”™'}
            segment_has_promotion = bool(segment_keywords & promotion_keywords)
            video_is_promotion = 'ğŸ ä¿ƒé”€æœºåˆ¶' in video_text or 'ä¿ƒé”€æœºåˆ¶' in str(video.get('main_tag', ''))
            
            # å¦‚æœè„šæœ¬æ˜¯ä¿ƒé”€é€¼å•ç±»å‹ï¼Œä¸”è§†é¢‘æ˜¯ä¿ƒé”€æœºåˆ¶ï¼Œç»™äºˆç‰¹æ®ŠåŠ æƒ
            if segment_has_promotion and video_is_promotion:
                overlap_ratio += 0.3  # ä¿ƒé”€åŒ¹é…åŠ æƒ
                logger.debug(f"  ğŸ ä¿ƒé”€æœºåˆ¶ç‰¹æ®ŠåŒ¹é…: {video.get('file_name', 'Unknown')} (+0.3)")
            
            # ğŸ ä¿ƒé”€æœºåˆ¶è§†é¢‘çš„é¢å¤–è¯­ä¹‰åŒ¹é…
            if video_is_promotion:
                promotion_semantic_words = ['å±•ç¤º', 'æ¨è', 'ä»‹ç»', 'æ¸©é¦¨', 'å®¶åº­', 'æ¬¢ä¹', 'é€‰æ‹©', 'å†³å®š']
                for word in promotion_semantic_words:
                    if word in video_text:
                        overlap_ratio += 0.1  # æ¯ä¸ªä¿ƒé”€è¯­ä¹‰è¯+0.1
                        break
            
            # é€šè¿‡é˜ˆå€¼æ£€æŸ¥
            if overlap_ratio >= current_threshold:
                filtered_videos.append(video)
                logger.debug(f"  âœ… é€šè¿‡é¢„ç­›é€‰: {video.get('file_name', 'Unknown')} (é‡å åº¦: {overlap_ratio:.2f})")
            else:
                logger.debug(f"  âŒ è¢«è¿‡æ»¤: {video.get('file_name', 'Unknown')} (é‡å åº¦: {overlap_ratio:.2f})")
        
        return filtered_videos

    def _copy_prefiltered_videos_to_reference(
        self, 
        segment: Dict[str, Any], 
        filtered_videos: List[Dict[str, Any]]
    ) -> None:
        """
        å°†é¢„ç­›é€‰é€šè¿‡çš„è§†é¢‘å¤åˆ¶åˆ°å¯¹åº”æ®µè½çš„ã€å‚è€ƒã€‘æ–‡ä»¶å¤¹ä¸­ã€‚
        
        Args:
            segment (Dict[str, Any]): è„šæœ¬æ®µè½æ•°æ®
            filtered_videos (List[Dict[str, Any]]): é¢„ç­›é€‰é€šè¿‡çš„è§†é¢‘åˆ—è¡¨
        """
        if not self.enable_reference_copy or not self.output_dir or not filtered_videos:
            return
            
        try:
            # ç”Ÿæˆæ–‡ä»¶å¤¹åç§°
            segment_id = segment.get('id', 'unknown')
            segment_content = segment.get('content', '')
            folder_name = self._generate_folder_name(segment_id, segment_content)
            
            # åˆ›å»ºæ®µè½ç›®å½•å’Œå‚è€ƒå­ç›®å½•
            segment_dir = self.output_dir / folder_name
            reference_dir = segment_dir / "ã€å‚è€ƒã€‘"
            
            segment_dir.mkdir(parents=True, exist_ok=True)
            reference_dir.mkdir(exist_ok=True)
            
            # å¤åˆ¶é¢„ç­›é€‰è§†é¢‘åˆ°å‚è€ƒæ–‡ä»¶å¤¹
            copied_count = 0
            for video in filtered_videos:
                try:
                    # è·å–æºJSONæ–‡ä»¶è·¯å¾„ï¼Œä»ä¸­æ¨æ–­å®é™…è§†é¢‘æ–‡ä»¶
                    source_json_path = video.get('source_json_path', '')
                    if not source_json_path:
                        logger.debug(f"âš ï¸ é¢„ç­›é€‰å¤åˆ¶è·³è¿‡: æ— æºJSONè·¯å¾„")
                        continue
                    
                    # ä»JSONæ–‡ä»¶è·¯å¾„æ¨æ–­å¯¹åº”çš„å®é™…è§†é¢‘æ–‡ä»¶
                    json_path = Path(source_json_path)
                    actual_video_name = json_path.name.replace('_analysis.json', '.mp4')
                    source_video_path = json_path.parent / actual_video_name
                    
                    if not source_video_path.exists():
                        logger.debug(f"âš ï¸ é¢„ç­›é€‰å¤åˆ¶è·³è¿‡: æ‰¾ä¸åˆ°è§†é¢‘æ–‡ä»¶ {actual_video_name}")
                        continue
                    
                    # å¤åˆ¶åˆ°å‚è€ƒæ–‡ä»¶å¤¹
                    dest_path = reference_dir / actual_video_name
                    if not dest_path.exists():  # é¿å…é‡å¤å¤åˆ¶
                        shutil.copy2(source_video_path, dest_path)
                        copied_count += 1
                        logger.debug(f"ğŸ“ å¤åˆ¶åˆ°å‚è€ƒ: {actual_video_name}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ å¤åˆ¶è§†é¢‘æ–‡ä»¶å¤±è´¥ {video.get('file_name', 'unknown')}: {e}")
                    continue
            
            if copied_count > 0:
                logger.info(f"ğŸ“ å·²å¤åˆ¶ {copied_count} ä¸ªé¢„ç­›é€‰è§†é¢‘åˆ° {folder_name}/ã€å‚è€ƒã€‘/")
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºå‚è€ƒæ–‡ä»¶å¤¹å¤±è´¥: {e}")

    def _find_video_file(self, video_filename: str) -> Optional[Path]:
        """
        æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶çš„å®é™…è·¯å¾„ã€‚
        
        Args:
            video_filename (str): è§†é¢‘æ–‡ä»¶å
            
        Returns:
            Optional[Path]: è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å›None
        """
        if not video_filename:
            return None
            
        if not self.output_dir:
            return None
            
        input_dir = self.output_dir.parent / 'input'
        
        # æ–¹æ³•1: ç›´æ¥åŒ¹é…æ–‡ä»¶å
        video_path = input_dir / video_filename
        if video_path.exists():
            return video_path
        
        # æ–¹æ³•2: ç”±äºJSONä¸­çš„file_nameä¸å®é™…æ–‡ä»¶åä¸åŒ¹é…ï¼Œ
        # æˆ‘ä»¬éœ€è¦é€šè¿‡JSONæ–‡ä»¶æ‰¾åˆ°å¯¹åº”çš„å®é™…è§†é¢‘æ–‡ä»¶
        # æŸ¥æ‰¾åŒåçš„JSONæ–‡ä»¶ï¼Œç„¶åè·å–å¯¹åº”çš„å®é™…è§†é¢‘æ–‡ä»¶å
        json_filename = video_filename.replace('.mp4', '_analysis.json')
        json_path = input_dir / json_filename
        
        if json_path.exists():
            try:
                import json
                with open(json_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ä»JSONæ–‡ä»¶åæ¨æ–­å®é™…è§†é¢‘æ–‡ä»¶å
                # JSONæ–‡ä»¶åæ ¼å¼ï¼šæ¸©é¦¨æ—¥å¸¸_å®å®å–å¥¶ç“¶ä¸­çš„å¥¶_analysis.json
                # å¯¹åº”è§†é¢‘æ–‡ä»¶åï¼šæ¸©é¦¨æ—¥å¸¸_å®å®å–å¥¶ç“¶ä¸­çš„å¥¶.mp4
                actual_video_name = json_path.name.replace('_analysis.json', '.mp4')
                actual_video_path = input_dir / actual_video_name
                
                if actual_video_path.exists():
                    return actual_video_path
                    
            except Exception as e:
                logger.debug(f"è¯»å–JSONæ–‡ä»¶å¤±è´¥ {json_path}: {e}")
        
        # æ–¹æ³•3: å…¼å®¹æ—§è·¯å¾„ï¼šåœ¨ğŸ¬Sliceç›®å½•æŸ¥æ‰¾
        project_root = self.output_dir.parent.parent
        legacy_path = project_root / 'ğŸ¬Slice' / video_filename
        if legacy_path.exists():
            return legacy_path
                
        return None

    def _generate_folder_name(self, segment_id: str, content: str) -> str:
        """
        ç”Ÿæˆæ–‡ä»¶å¤¹åç§°ï¼ˆä¸file_organizer.pyä¸­çš„é€»è¾‘ä¿æŒä¸€è‡´ï¼‰ã€‚
        
        Args:
            segment_id (str): æ®µè½ID
            content (str): æ®µè½å†…å®¹
            
        Returns:
            str: æ–‡ä»¶å¤¹åç§°
        """
        # æå–æ•°å­—ID
        numeric_id = self._extract_numeric_id(segment_id)
        
        # æˆªå–å†…å®¹å‰ç¼€ï¼ˆæœ€å¤š5ä¸ªå­—ç¬¦ï¼Œé¿å…æ–‡ä»¶å¤¹åè¿‡é•¿ï¼‰
        content_prefix = content[:5] if content else "æœªçŸ¥å†…å®¹"
        
        return f"ã€{numeric_id}{content_prefix}...ã€‘"

    def _extract_numeric_id(self, segment_id: str) -> str:
        """
        ä»æ®µè½IDä¸­æå–æ•°å­—ï¼ˆä¸file_organizer.pyä¸­çš„é€»è¾‘ä¿æŒä¸€è‡´ï¼‰ã€‚
        
        Args:
            segment_id (str): æ®µè½IDï¼ˆå¦‚ "1ï¸âƒ£", "2", "â‘¢" ç­‰ï¼‰
            
        Returns:
            str: æå–çš„æ•°å­—å­—ç¬¦ä¸²
        """
        import re
        
        # å¤„ç†emojiæ•°å­— (1ï¸âƒ£ â†’ 1)
        emoji_to_digit = {
            '1ï¸âƒ£': '1', '2ï¸âƒ£': '2', '3ï¸âƒ£': '3', '4ï¸âƒ£': '4', '5ï¸âƒ£': '5',
            '6ï¸âƒ£': '6', '7ï¸âƒ£': '7', '8ï¸âƒ£': '8', '9ï¸âƒ£': '9', 'ğŸ”Ÿ': '10'
        }
        
        if segment_id in emoji_to_digit:
            return emoji_to_digit[segment_id]
        
        # æå–ä»»ä½•æ•°å­—å­—ç¬¦
        numbers = re.findall(r'\d+', segment_id)
        return numbers[0] if numbers else segment_id

    def _get_actual_video_name(self, video_slice: Dict[str, Any]) -> str:
        """
        ä»è§†é¢‘åˆ‡ç‰‡æ•°æ®ä¸­è·å–å®é™…çš„è§†é¢‘æ–‡ä»¶åã€‚
        
        Args:
            video_slice (Dict[str, Any]): è§†é¢‘åˆ‡ç‰‡æ•°æ®
            
        Returns:
            str: å®é™…çš„è§†é¢‘æ–‡ä»¶å
        """
        try:
            source_json_path = video_slice.get('source_json_path', '')
            if source_json_path:
                json_path = Path(source_json_path)
                actual_video_name = json_path.name.replace('_analysis.json', '.mp4')
                return actual_video_name
        except Exception as e:
            logger.debug(f"è·å–å®é™…è§†é¢‘æ–‡ä»¶åå¤±è´¥: {e}")
        
        # å¦‚æœå¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡ä»¶åä½œä¸ºå¤‡ç”¨
        return video_slice.get('file_name', 'unknown.mp4')

    def _find_best_matches_for_segment(
        self,
        segment: Dict[str, Any],
        video_slices: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ä¸ºå•ä¸ªè„šæœ¬æ®µè½æ‰¾åˆ°æœ€ä½³çš„è§†é¢‘åŒ¹é…ã€‚"""
        
        current_segment_matches = []
        for j, video_slice in enumerate(video_slices, 1):
            logger.debug(f"  - æ­£åœ¨åŒ¹é…è§†é¢‘ {j}/{len(video_slices)}: {video_slice['file_name']}")
            
            # 1. æ„é€ Prompt
            prompt = self._construct_prompt(segment, video_slice)
            
            # 2. è°ƒç”¨AIè·å–åˆ†æ
            ai_analysis = self.ai_client.get_match_analysis(prompt)
            
            if ai_analysis and "match_score" in ai_analysis:
                match_score = ai_analysis.get("match_score", 0.0)
                
                # 3. åˆ¤æ–­æ˜¯å¦æ»¡è¶³æœ€ä½åŒ¹é…é˜ˆå€¼
                min_threshold = self.config.QUALITY_STANDARDS['min_acceptable_threshold']
                if match_score >= min_threshold:
                    # è·å–å®é™…çš„è§†é¢‘æ–‡ä»¶åï¼ˆä»source_json_pathæ¨æ–­ï¼‰
                    actual_video_name = self._get_actual_video_name(video_slice)
                    
                    current_segment_matches.append({
                        "video_file_name": actual_video_name,  # ä½¿ç”¨å®é™…çš„è§†é¢‘æ–‡ä»¶å
                        "video_file_path": video_slice['file_path'],
                        "match_score": match_score,
                        "match_reason": ai_analysis.get("match_reason", ""),
                        "mismatch_issues": ai_analysis.get("mismatch_issues", [])
                    })
                    logger.info(f"    ğŸŒŸ æ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆåŒ¹é…: {video_slice['file_name']} (åˆ†æ•°: {match_score:.2f})")
        
        # 4. æ’åºå¹¶ç­›é€‰å‡ºæœ€ä½³åŒ¹é…
        sorted_matches = sorted(current_segment_matches, key=lambda x: x['match_score'], reverse=True)
        max_matches = self.config.QUALITY_STANDARDS['max_matches_per_segment']
        
        return sorted_matches[:max_matches]

    def _construct_prompt(self, segment: Dict[str, Any], video_slice: Dict[str, Any]) -> str:
        """æ„é€ å‘é€ç»™DeepSeekçš„åŒ¹é…åˆ†ææç¤ºã€‚"""
        
        # ä»è§†é¢‘JSONä¸­æå–å…³é”®ä¿¡æ¯
        video_object = video_slice.get('object', 'æœªçŸ¥')
        video_scene = video_slice.get('scene', 'æœªçŸ¥')
        video_emotion = video_slice.get('emotion', 'æœªçŸ¥')
        video_main_tag = video_slice.get('main_tag', 'æœªçŸ¥')
        video_keywords = video_slice.get('matched_keywords', [])
        video_reasoning = video_slice.get('analysis', {}).get('reasoning', 'æœªæä¾›')
        
        # ä½¿ç”¨é…ç½®ä¸­çš„æç¤ºæ¨¡æ¿
        prompt = self.config.DEEPSEEK_PROMPT.format(
            script_content=segment['content'],
            script_type=segment['type'],
            script_keywords=segment['keywords'],
            expected_emotions=segment['expected_emotions'],
            object=video_object,
            scene=video_scene,
            emotion=video_emotion,
            main_tag=video_main_tag,
            matched_keywords=video_keywords,
            reasoning=video_reasoning
        )
        
        return prompt

    def _save_passed_videos_to_json(self, segment: Dict[str, Any], best_matches: List[Dict[str, Any]]) -> None:
        """
        å°†é€šè¿‡AIåŒ¹é…çš„è§†é¢‘ä¿¡æ¯åˆ†çº§ä¿å­˜åˆ°pass.jsonæ–‡ä»¶ä¸­ã€‚
        
        Args:
            segment (Dict[str, Any]): è„šæœ¬æ®µè½ä¿¡æ¯
            best_matches (List[Dict[str, Any]]): é€šè¿‡åŒ¹é…çš„è§†é¢‘åˆ—è¡¨
        """
        if not self.output_dir or not best_matches:
            return
            
        try:
            # ç”Ÿæˆæ®µè½æ–‡ä»¶å¤¹åç§°
            folder_name = self._generate_folder_name(segment['id'], segment['content'])
            segment_dir = self.output_dir / folder_name
            
            # ç¡®ä¿æ®µè½ç›®å½•å­˜åœ¨
            segment_dir.mkdir(parents=True, exist_ok=True)
            
            # åˆ†çº§æ”¶å½•
            high_quality = []
            medium_quality = []
            acceptable = []
            hq = self.config.QUALITY_STANDARDS['high_quality_threshold']
            mq = self.config.QUALITY_STANDARDS['medium_quality_threshold']
            minq = self.config.QUALITY_STANDARDS['min_acceptable_threshold']
            for match in best_matches:
                score = match.get('match_score', 0)
                if score >= hq:
                    high_quality.append(match)
                elif score >= mq:
                    medium_quality.append(match)
                elif score >= minq:
                    acceptable.append(match)
            
            pass_data = {
                "segment_info": {
                    "id": segment['id'],
                    "content": segment['content'],
                    "type": segment.get('type', ''),
                    "keywords": segment.get('keywords', [])
                },
                "processing_time": self._get_current_timestamp(),
                "total_matches": len(best_matches),
                "min_score": min(match['match_score'] for match in best_matches) if best_matches else 0,
                "max_score": max(match['match_score'] for match in best_matches) if best_matches else 0,
                "high_quality": high_quality,
                "medium_quality": medium_quality,
                "acceptable": acceptable
            }
            
            # ä¿å­˜åˆ°pass.jsonæ–‡ä»¶
            pass_json_path = segment_dir / "pass.json"
            with open(pass_json_path, 'w', encoding='utf-8') as f:
                json.dump(pass_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ’¾ å·²åˆ†çº§ä¿å­˜ {len(best_matches)} ä¸ªåŒ¹é…ç»“æœåˆ° {folder_name}/pass.json")
            
            # ğŸ¯ æ–°å¢ï¼šå®Œæˆjsonä¿å­˜åç«‹å³ç§»åŠ¨æ–‡ä»¶å¹¶æ·»åŠ åˆ†æ•°å‰ç¼€
            self._move_best_matches_with_scores(segment, best_matches)
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜pass.jsonå¤±è´¥: {e}")

    def _move_best_matches_with_scores(self, segment: Dict[str, Any], best_matches: List[Dict[str, Any]]) -> None:
        """
        å®ŒæˆAIåŒ¹é…åç«‹å³å¤åˆ¶è§†é¢‘æ–‡ä»¶åˆ°æ®µè½æ ¹ç›®å½•ï¼Œå¹¶åœ¨æ–‡ä»¶åå‰åŠ ä¸Šåˆ†æ•°ã€‚
        ä»ã€å‚è€ƒã€‘æ–‡ä»¶å¤¹ä¸­åˆ é™¤å·²é€‰ä¸­çš„æ–‡ä»¶ï¼Œä¿ç•™å…¶ä»–æœªè¢«é€‰ä¸­çš„å€™é€‰è§†é¢‘ã€‚
        
        Args:
            segment (Dict[str, Any]): è„šæœ¬æ®µè½ä¿¡æ¯
            best_matches (List[Dict[str, Any]]): é€šè¿‡åŒ¹é…çš„è§†é¢‘åˆ—è¡¨
        """
        if not self.output_dir or not best_matches:
            return
            
        try:
            # ç”Ÿæˆæ®µè½æ–‡ä»¶å¤¹åç§°
            folder_name = self._generate_folder_name(segment['id'], segment['content'])
            segment_dir = self.output_dir / folder_name
            reference_dir = segment_dir / "ã€å‚è€ƒã€‘"
            
            copied_count = 0
            removed_from_reference = 0
            
            for match in best_matches:
                try:
                    video_file_name = match.get('video_file_name', '')
                    match_score = match.get('match_score', 0.0)
                    
                    if not video_file_name:
                        continue
                    
                    # æ£€æŸ¥ã€å‚è€ƒã€‘æ–‡ä»¶å¤¹ä¸­æ˜¯å¦æœ‰è¯¥æ–‡ä»¶
                    reference_video_path = reference_dir / video_file_name
                    
                    if reference_video_path.exists():
                        # ç”Ÿæˆå¸¦åˆ†æ•°çš„æ–°æ–‡ä»¶åï¼š0.85_åŸæ–‡ä»¶å.mp4
                        score_prefix = f"{match_score:.2f}_"
                        new_filename = score_prefix + video_file_name
                        
                        # å¤åˆ¶åˆ°æ®µè½æ ¹ç›®å½•å¹¶é‡å‘½å
                        destination_path = segment_dir / new_filename
                        
                        if not destination_path.exists():  # é¿å…é‡å¤å¤åˆ¶
                            shutil.copy2(str(reference_video_path), str(destination_path))
                            copied_count += 1
                            logger.info(f"â­ å·²å¤åˆ¶å¹¶é‡å‘½å: {video_file_name} â†’ {new_filename}")
                            
                            # ğŸ¯ å…³é”®ä¿®æ”¹ï¼šä»ã€å‚è€ƒã€‘æ–‡ä»¶å¤¹ä¸­åˆ é™¤å·²é€‰ä¸­çš„æ–‡ä»¶
                            reference_video_path.unlink()
                            removed_from_reference += 1
                            logger.debug(f"ğŸ—‘ï¸ ä»ã€å‚è€ƒã€‘åˆ é™¤å·²é€‰ä¸­æ–‡ä»¶: {video_file_name}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ å¤„ç†æ–‡ä»¶å¤±è´¥ {video_file_name}: {e}")
                    continue
            
            if copied_count > 0:
                logger.info(f"ğŸ“ å®Œæˆæ®µè½ {segment['id']} çš„æ–‡ä»¶å¤„ç†:")
                logger.info(f"   âœ… å¤åˆ¶ {copied_count} ä¸ªæœ€ä½³åŒ¹é…åˆ°æ®µè½æ ¹ç›®å½•ï¼ˆå¸¦åˆ†æ•°å‰ç¼€ï¼‰")
                logger.info(f"   ğŸ—‘ï¸ ä»ã€å‚è€ƒã€‘åˆ é™¤ {removed_from_reference} ä¸ªå·²é€‰ä¸­æ–‡ä»¶")
                
                # ç»Ÿè®¡å‰©ä½™çš„å€™é€‰è§†é¢‘æ•°é‡
                if reference_dir.exists():
                    remaining_count = len(list(reference_dir.iterdir()))
                    if remaining_count > 0:
                        logger.info(f"   ğŸ“‚ ã€å‚è€ƒã€‘æ–‡ä»¶å¤¹ä¿ç•™ {remaining_count} ä¸ªå…¶ä»–å€™é€‰è§†é¢‘ä¾›æ‰‹åŠ¨é€‰æ‹©")
                    else:
                        # å¦‚æœæ²¡æœ‰å‰©ä½™æ–‡ä»¶ï¼Œåˆ é™¤ç©ºæ–‡ä»¶å¤¹
                        reference_dir.rmdir()
                        logger.info(f"   ğŸ—‘ï¸ ã€å‚è€ƒã€‘æ–‡ä»¶å¤¹å·²æ¸…ç©ºå¹¶åˆ é™¤")
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†åŒ¹é…æ–‡ä»¶å¤±è´¥: {e}")

    def _get_current_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

if __name__ == "__main__":
    # --- æµ‹è¯•è§†é¢‘åŒ¹é…å™¨ ---
    print("ğŸ§ª æµ‹è¯•è§†é¢‘åŒ¹é…å™¨...")

    # æ¨¡æ‹Ÿæµ‹è¯•æ•°æ®
    mock_script = [
        {
            "id": "1ï¸âƒ£",
            "content": "ç‹—éƒ½ä¸ï¼Œç”Ÿï¼ç”Ÿçš„å°±æ˜¯çº¯å¥¶ç²‰å–‚å…»å…«æ–¤å…«ä¸¤çš„å¤§èƒ–å¨ƒï¼",
            "type": "æƒ…ç»ªè¡¨è¾¾",
            "keywords": ["å¥¶ç²‰", "å–‚å…»", "å¨ƒ"],
            "expected_emotions": ["æ¿€åŠ¨"]
        }
    ]
    
    mock_videos = [
        {
            "file_name": "test_video1.mp4",
            "file_path": "/test/path/video1.mp4",
            "object": "çˆ¸çˆ¸æ¸©æŸ”å–‚å®å®å–å¥¶",
            "scene": "å®¤å†…",
            "emotion": "æ¸©é¦¨",
            "main_tag": "ä¿ƒé”€æœºåˆ¶",
            "matched_keywords": ["å–‚å…»", "å®å®", "æ¸©é¦¨"],
            "analysis": {"reasoning": "æ¸©é¦¨çš„å–‚å…»åœºæ™¯"}
        },
        {
            "file_name": "test_video2.mp4", 
            "file_path": "/test/path/video2.mp4",
            "object": "å¥³äººå±•ç¤ºçç é¡¹é“¾",
            "scene": "å®¤å†…",
            "emotion": "æ—¶å°š",
            "main_tag": "æ—¶å°šå±•ç¤º",
            "matched_keywords": ["é¡¹é“¾", "æ—¶å°š"],
            "analysis": {"reasoning": "æ—¶å°šé…é¥°å±•ç¤º"}
        }
    ]
    
    try:
        # æµ‹è¯•é¢„ç­›é€‰åŠŸèƒ½
        matcher = VideoMatcher(enable_pre_filter=True, keyword_threshold=0.2)
        
        print("ğŸ” æµ‹è¯•é¢„ç­›é€‰åŠŸèƒ½...")
        filtered = matcher._pre_filter_videos(mock_script[0], mock_videos)
        print(f"é¢„ç­›é€‰ç»“æœ: {len(mock_videos)} â†’ {len(filtered)} ä¸ªè§†é¢‘")
        
        for video in filtered:
            print(f"  âœ… é€šè¿‡: {video['file_name']}")
        
        print("\nâœ… é¢„ç­›é€‰æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
