#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŠ¨æ€è„šæœ¬åŒ¹é…é…ç½®æ–‡ä»¶
æ”¯æŒè¿è¡Œæ—¶è¾“å…¥è„šæœ¬ï¼Œå¹¶æä¾›çµæ´»çš„åŒ¹é…è§„åˆ™å’Œå…³é”®è¯æ˜ å°„
"""

from typing import Dict, List, Any

class DynamicMatchConfig:
    """åŠ¨æ€åŒ¹é…é…ç½® - æ”¯æŒè¿è¡Œæ—¶è„šæœ¬è¾“å…¥"""

    def __init__(self):
        """åˆå§‹åŒ–åŠ¨æ€é…ç½®"""
        # ä¸å†ç¡¬ç¼–ç EXAMPLE_SCRIPT
        self.current_script_segments: Dict[str, str] = {}
        self.analyzed_segments: List[Dict[str, Any]] = []

        # JSONå­—æ®µåŒ¹é…æƒé‡é…ç½®
        self.MATCH_WEIGHTS: Dict[str, float] = {
            "object": 0.25,
            "emotion": 0.20,
            "scene": 0.20,
            "main_tag": 0.15,
            "matched_keywords": 0.10,
            "reasoning": 0.05,
            "secondary_category": 0.05,
        }

        # å…³é”®è¯æ˜ å°„è¡¨
        self._initialize_keyword_mappings()

        # DeepSeek AI åŒ¹é…æç¤ºæ¨¡æ¿
        self.DEEPSEEK_PROMPT = self._get_deepseek_prompt_template()

        # è´¨é‡æ§åˆ¶æ ‡å‡†
        self.QUALITY_STANDARDS: Dict[str, Any] = {
            "high_quality_threshold": 0.8,
            "medium_quality_threshold": 0.5,
            "min_acceptable_threshold": 0.2,  # é™ä½é˜ˆå€¼ï¼Œæ‰©å¤§æ”¶å½•
            "max_matches_per_segment": 100,     # æå‡æœ€å¤§æ”¶å½•æ•°é‡
        }

    def load_user_script(self, script_segments: Dict[str, str]):
        """åŠ è½½å¹¶è§£æç”¨æˆ·æä¾›çš„è„šæœ¬"""
        self.current_script_segments = script_segments
        self.analyzed_segments = self._analyze_script_segments(script_segments)

    def _analyze_script_segments(self, segments: Dict[str, str]) -> List[Dict[str, Any]]:
        """æ™ºèƒ½åˆ†æè„šæœ¬æ®µè½"""
        analyzed_list = []
        for segment_id, content in segments.items():
            segment_type = self._get_segment_type(content)
            keywords = self._extract_script_keywords(content)
            emotions = self._get_expected_emotions(content)
            
            analyzed_list.append({
                "id": segment_id,
                "content": content,
                "type": segment_type,
                "keywords": keywords,
                "expected_emotions": emotions,
            })
        return analyzed_list

    def _get_segment_type(self, content: str) -> str:
        """æ ¹æ®è„šæœ¬å†…å®¹åŠ¨æ€åˆ†ææ®µè½ç±»å‹"""
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œæœªæ¥å¯ä»¥ç”¨AIæ¥å¢å¼º
        type_scores = {segment_type: 0 for segment_type in self.SCRIPT_SEGMENT_KEYWORDS}
        
        for segment_type, keywords in self.SCRIPT_SEGMENT_KEYWORDS.items():
            for keyword in keywords:
                if keyword in content:
                    type_scores[segment_type] += 1
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„ç±»å‹
        if any(type_scores.values()):
            return max(type_scores, key=type_scores.get)
        
        return "é€šç”¨æ®µè½"

    def _extract_script_keywords(self, content: str) -> List[str]:
        """ä»è„šæœ¬å†…å®¹ä¸­æå–æ‰€æœ‰ç›¸å…³å…³é”®è¯"""
        keywords = set()
        all_mappings = [
            self.SCRIPT_SEGMENT_KEYWORDS,  # æ·»åŠ è„šæœ¬æ®µè½å…³é”®è¯æ˜ å°„
            self.EMOTION_MAPPING, 
            self.SCENE_MAPPING, 
            self.ACTION_MAPPING, 
            self.BRAND_MAPPING
        ]
        for mapping in all_mappings:
            for keyword_list in mapping.values():
                for keyword in keyword_list:
                    if keyword in content:
                        keywords.add(keyword)
        return list(keywords)

    def _get_expected_emotions(self, content: str) -> List[str]:
        """æ ¹æ®è„šæœ¬å†…å®¹æ¨æµ‹é¢„æœŸæƒ…ç»ª"""
        emotions = set()
        for emotion, keywords in self.EMOTION_MAPPING.items():
            for keyword in keywords:
                if keyword in content:
                    emotions.add(emotion)
        return list(emotions)

    def _initialize_keyword_mappings(self):
        """åˆå§‹åŒ–æ‰€æœ‰å…³é”®è¯æ˜ å°„è¡¨"""
        self.SCRIPT_SEGMENT_KEYWORDS = {
            "æƒ…ç»ªè¡¨è¾¾": ["ç‹—éƒ½ä¸", "ç”Ÿï¼", "å†²äº†", "è¯•é”™"],
            "äº§å“èƒŒä¹¦": ["ç™¾å¹´ç§‘ç ”", "å“ç‰Œ", "ä¸“ä¸šæ¸ é“", "æƒ æ°", "åˆ¶è¯èƒŒæ™¯"],
            "åŠ¨ä½œæè¿°": ["å¦ˆå¦ˆ", "æ‹¿å¥¶ç“¶", "æ‘‡å¤´", "å–‚å…»", "å®å®"],
            "ç§‘ç ”é…æ–¹": ["HMO", "é…æ–¹", "ç ”ç©¶", "ç§‘ç ”èƒŒæ™¯"],
            "å®å®çŠ¶æ€": ["å°è‚‰å®", "å¥½å¸¦", "äº’åŠ¨", "å¯çˆ±", "è¶´åœ°ä¸Š"],
            "å£æ’­æ¨è": ["å¯¹é•œå¤´", "å£æ’­", "æ¨è", "é€‰æ‹©", "å»ºè®®"],
        }
        self.EMOTION_MAPPING = {
            "å¼€å¿ƒ": ["å¼€å¿ƒ", "é«˜å…´", "å¿«ä¹", "æ¬¢ä¹", "ç¬‘"], "å“­é—¹": ["å“­", "å“­é—¹", "ä¸å®‰", "çƒ¦èº"],
            "æ— å¥ˆ": ["æ— å¥ˆ", "æ‘‡å¤´", "å¹æ°”"], "æ¸©é¦¨": ["æ¸©é¦¨", "æ¸©æš–", "å’Œè°", "äº²å¯†"],
            "ä¸“ä¸š": ["ä¸“ä¸š", "æƒå¨", "ç§‘ç ”"], "æ¿€åŠ¨": ["æ¿€åŠ¨", "å…´å¥‹", "çƒ­æƒ…", "å†²äº†"],
        }
        self.SCENE_MAPPING = { "å®¤å†…å®¶åº­": ["å®¤å†…", "å®¶é‡Œ", "å®¢å…", "å¨æˆ¿"], "äº§å“å±•ç¤º": ["å¥¶ç²‰ç½", "äº§å“", "åŒ…è£…"], "å£æ’­åœºæ™¯": ["å£æ’­", "è®²è§£", "å¯¹é•œå¤´"],}
        self.ACTION_MAPPING = { "æ‹¿ç€": ["æ‹¿ç€", "æ¡ç€"], "çœ‹ç€": ["çœ‹ç€", "æ³¨è§†"], "æ‘‡å¤´": ["æ‘‡å¤´", "æ‘†å¤´"], "å–‚å…»": ["å–‚å¥¶", "å–‚é£Ÿ"], "äº’åŠ¨": ["äº’åŠ¨", "ç©è€"], }
        self.BRAND_MAPPING = { "æƒ æ°": ["æƒ æ°"], "å¯èµ‹": ["å¯èµ‹"], "HMO": ["HMO"], }

    def _get_deepseek_prompt_template(self) -> str:
        """è·å–DeepSeek AIçš„æç¤ºæ¨¡æ¿"""
        return """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åŒ¹é…åˆ†æå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯è¿›è¡ŒåŒ¹é…åˆ†æï¼š

## è„šæœ¬æ®µè½ä¿¡æ¯ï¼š
- å†…å®¹ï¼š{script_content}
- ç±»å‹ï¼š{script_type}
- å…³é”®è¯ï¼š{script_keywords}
- é¢„æœŸæƒ…ç»ªï¼š{expected_emotions}

## è§†é¢‘åˆ‡ç‰‡JSONä¿¡æ¯ï¼š
- å¯¹è±¡æè¿°ï¼š{object}
- åœºæ™¯æè¿°ï¼š{scene}  
- æƒ…ç»ªçŠ¶æ€ï¼š{emotion}
- ä¸»æ ‡ç­¾ï¼š{main_tag}
- å…³é”®è¯ï¼š{matched_keywords}
- åˆ†ææ¨ç†ï¼š{reasoning}

## åŒ¹é…ä»»åŠ¡ï¼š
è¯·åˆ†æè§†é¢‘åˆ‡ç‰‡æ˜¯å¦é€‚åˆè¯¥è„šæœ¬æ®µè½ï¼Œå¹¶ä»¥JSONæ ¼å¼å›ç­”ï¼š
{{
    "match_score": 0.0-1.0,
    "match_reason": "åŒ¹é…ç†ç”±",
    "mismatch_issues": ["é—®é¢˜1", "é—®é¢˜2"]
}}
"""

if __name__ == '__main__':
    # --- æµ‹è¯•åŠ¨æ€é…ç½®ç³»ç»Ÿ ---
    print("ğŸ§ª æµ‹è¯•åŠ¨æ€åŒ¹é…é…ç½®ç³»ç»Ÿ...")
    
    # 1. æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥çš„è„šæœ¬
    user_script = {
        "S01": "èƒ½è‡ªå·±å–‚è‚¯å®šæ˜¯æ›´å¥½çš„ï¼Œä½†å‡¡ä½ å†³å®šäº†å¥¶ç²‰å–‚å…»ï¼Œå°±ä¸€å®šè¦é€‰æœ‰ç™¾å¹´ç§‘ç ”å®åŠ›ï¼Œä¸“ä¸šæ¸ é“ä¹Ÿè®¤å¯çš„å“ç‰Œã€‚",
        "S02": "å¦ˆå¦ˆæ‹¿ç€å¥¶ç“¶æ— å¥ˆæ‘‡å¤´ï¼Œå®å®é¥¿å¾—ä¸€ç›´å“­é—¹",
    }
    
    # 2. åˆ›å»ºå¹¶åŠ è½½é…ç½®
    dynamic_config = DynamicMatchConfig()
    dynamic_config.load_user_script(user_script)
    
    # 3. æ‰“å°åˆ†æç»“æœ
    print(f"\nâœ… æˆåŠŸåŠ è½½å¹¶è§£æäº† {len(dynamic_config.analyzed_segments)} ä¸ªè„šæœ¬æ®µè½ã€‚")
    for i, analyzed_seg in enumerate(dynamic_config.analyzed_segments, 1):
        print(f"\n--- æ®µè½ {i} ---")
        print(f"  ID: {analyzed_seg['id']}")
        print(f"  å†…å®¹: '{analyzed_seg['content'][:30]}...'")
        print(f"  -> è¯†åˆ«ç±»å‹: {analyzed_seg['type']}")
        print(f"  -> æå–å…³é”®è¯: {analyzed_seg['keywords']}")
        print(f"  -> é¢„æœŸæƒ…ç»ª: {analyzed_seg['expected_emotions']}")

    print("\nğŸ‰ åŠ¨æ€é…ç½®ç³»ç»Ÿå·¥ä½œæ­£å¸¸ï¼")
