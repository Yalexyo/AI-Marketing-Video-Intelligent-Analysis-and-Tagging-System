#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®˜æ–¹è§„èŒƒAIåˆ†æå™¨
ä¸¥æ ¼æŒ‰ç…§é˜¿é‡Œäº‘DashScopeå’ŒDeepSeekå®˜æ–¹APIè§„èŒƒå®ç°
"""

import os
import sys
import json
import logging
import requests
import base64
import time
try:
    import cv2  # type: ignore
    import numpy as np  # type: ignore
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {e}")
    print("ğŸ’¡ è¯·è¿è¡Œ: uv add opencv-python numpy")
    sys.exit(1)
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# å¯¼å…¥ç¯å¢ƒå˜é‡åŠ è½½å™¨å’Œæ™ºèƒ½å…³é”®å¸§æå–å™¨
from src.env_loader import load_environment
from src.smart_frame_extractor import SmartFrameExtractor

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class OfficialAIAnalyzer:
    """ä¸¥æ ¼ç¬¦åˆå®˜æ–¹è§„èŒƒçš„AIåˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        # è‡ªåŠ¨åŠ è½½.envæ–‡ä»¶
        env_loader = load_environment()
        
        self.dashscope_key = os.getenv("DASHSCOPE_API_KEY")
        self.deepseek_key = os.getenv("DEEPSEEK_API_KEY")
        
        if not self.dashscope_key:
            raise ValueError("âŒ æœªæ‰¾åˆ°DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        if not self.deepseek_key:
            raise ValueError("âŒ æœªæ‰¾åˆ°DEEPSEEK_API_KEYç¯å¢ƒå˜é‡")
            
        # å®˜æ–¹APIç«¯ç‚¹
        self.dashscope_url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation"
        self.deepseek_url = "https://api.deepseek.com/chat/completions"
        
        # é…ç½®å‚æ•°
        self.qwen_model = "qwen-vl-max-latest"
        self.deepseek_model = "deepseek-chat"
        self.fps = 2.0  # è§†é¢‘æŠ½å¸§é¢‘ç‡
        self.max_retries = 3
        self.timeout = 60
        
        # åˆå§‹åŒ–æ™ºèƒ½å…³é”®å¸§æå–å™¨
        self.frame_extractor = SmartFrameExtractor()
        
        logger.info("âœ… å®˜æ–¹è§„èŒƒAIåˆ†æå™¨åˆå§‹åŒ–å®Œæˆï¼ˆå·²é›†æˆæ™ºèƒ½å…³é”®å¸§æå–ï¼‰")
    
    def analyze_video_dual_stage(self, video_path: str) -> Dict[str, Any]:
        """
        åŒå±‚è¯†åˆ«æœºåˆ¶åˆ†æè§†é¢‘
        ä¸¥æ ¼æŒ‰ç…§é¡¹ç›®è®¾è®¡çš„åŒå±‚æ¶æ„å®ç°
        """
        try:
            file_info = Path(video_path)
            logger.info(f"ğŸ¯ å¼€å§‹åŒå±‚AIåˆ†æ: {file_info.name}")
            
            # æå–å…³é”®å¸§
            frames = self._extract_key_frames(video_path)
            if not frames:
                raise ValueError("æ— æ³•æå–è§†é¢‘å¸§")
            
            # ç¬¬ä¸€å±‚ï¼šAI-Bé€šç”¨è¯†åˆ«ï¼ˆç¦æ­¢å“ç‰Œè¯†åˆ«ï¼‰
            stage1_result = self._stage1_general_analysis(frames[0])
            
            # åˆ¤æ–­æ˜¯å¦è§¦å‘ç¬¬äºŒå±‚
            trigger_brand = self._should_trigger_brand_detection(stage1_result)
            
            if trigger_brand:
                logger.info("ğŸ” è§¦å‘ç¬¬äºŒå±‚å“ç‰Œæ£€æµ‹")
                # ç¬¬äºŒå±‚ï¼šAI-Aå“ç‰Œä¸“ç”¨æ£€æµ‹
                stage2_result = self._stage2_brand_detection(frames[0])
                brand_elements = stage2_result.get("brand_elements", "æ— ")
            else:
                logger.info("âšª æœªè§¦å‘å“ç‰Œæ£€æµ‹æ¡ä»¶")
                brand_elements = "æ— "
            
            # åˆå¹¶ç»“æœ
            final_result = {
                **stage1_result,
                "brand_elements": brand_elements,
                "analysis_method": "official_dual_stage",
                "stage1_triggered": True,
                "stage2_triggered": trigger_brand,
                "file_name": file_info.name,
                "file_size_mb": round(file_info.stat().st_size / (1024 * 1024), 2),
                "processed_at": datetime.now().isoformat(),
                "success": True
            }
            
            logger.info(f"âœ… åŒå±‚åˆ†æå®Œæˆ: {stage1_result.get('object', 'æœªçŸ¥')}")
            return final_result
            
        except Exception as e:
            logger.error(f"âŒ åŒå±‚åˆ†æå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "file_name": Path(video_path).name,
                "analysis_method": "official_dual_stage"
            }
    
    def _extract_key_frames(self, video_path: str) -> List[np.ndarray]:
        """ä½¿ç”¨æ™ºèƒ½å…³é”®å¸§æå–å™¨æå–è§†é¢‘å…³é”®å¸§"""
        try:
            # ä½¿ç”¨æ™ºèƒ½å…³é”®å¸§æå–å™¨
            key_frames_data = self.frame_extractor.extract_key_frames(video_path)
            
            if key_frames_data:
                # æå–å¸§æ•°æ®
                frames = [frame_data["frame"] for frame_data in key_frames_data]
                
                logger.info(f"ğŸ–¼ï¸ æ™ºèƒ½æå–äº† {len(frames)} ä¸ªå…³é”®å¸§")
                
                # æ‰“å°å¸§ä¿¡æ¯
                for i, frame_data in enumerate(key_frames_data):
                    logger.info(f"   å¸§{i+1}: {frame_data['timestamp']:.2f}s (æ–¹æ³•: {frame_data['extraction_method']})")
                
                return frames
            else:
                logger.error(f"âŒ æ™ºèƒ½å…³é”®å¸§æå–å¤±è´¥: è¿”å›ç©ºç»“æœ")
                return []
            
        except Exception as e:
            logger.error(f"âŒ å…³é”®å¸§æå–å™¨å¼‚å¸¸: {str(e)}")
            return []
    
    def _frame_to_base64(self, frame: np.ndarray) -> str:
        """å°†å¸§è½¬æ¢ä¸ºbase64ç¼–ç """
        try:
            # è°ƒæ•´å›¾ç‰‡å¤§å°ä»¥ç¬¦åˆAPIé™åˆ¶
            height, width = frame.shape[:2]
            if width > 1024 or height > 1024:
                scale = min(1024/width, 1024/height)
                new_width = int(width * scale)
                new_height = int(height * scale)
                frame = cv2.resize(frame, (new_width, new_height))
            
            # ç¼–ç ä¸ºJPEG
            _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
            
            # è½¬æ¢ä¸ºbase64
            base64_str = base64.b64encode(buffer).decode('utf-8')
            return f"data:image/jpeg;base64,{base64_str}"
            
        except Exception as e:
            logger.error(f"âŒ å¸§è½¬base64å¤±è´¥: {str(e)}")
            return ""
    
    def _stage1_general_analysis(self, frame: np.ndarray) -> Dict[str, Any]:
        """
        ç¬¬ä¸€å±‚ï¼šé€šç”¨è¯†åˆ«åˆ†æï¼ˆä¸¥æ ¼ç¦æ­¢å“ç‰Œè¯†åˆ«ï¼‰
        ä½¿ç”¨å®˜æ–¹Qwen-VL API
        """
        try:
            # è½¬æ¢å¸§ä¸ºbase64
            image_base64 = self._frame_to_base64(frame)
            if not image_base64:
                raise ValueError("å›¾ç‰‡è½¬æ¢å¤±è´¥")
            
            # æ„å»ºå®˜æ–¹æ ¼å¼çš„è¯·æ±‚
            prompt = """ä»”ç»†åˆ†æç”»é¢å†…å®¹ï¼Œæ— è®ºæ˜¯å¦æœ‰äººç‰©éƒ½è¦è¯¦ç»†æè¿°ã€‚

1. **interaction**: ç”¨"ä¸»è¯­+åŠ¨è¯+å®¾è¯­"æè¿°æ ¸å¿ƒäº‹ä»¶æˆ–ç‰©ä½“çŠ¶æ€
   - æœ‰äººç‰©æ—¶ï¼šå¦‚"å®å®æ‹’ç»å¥¶ç“¶", "å¦ˆå¦ˆå†²æ³¡å¥¶ç²‰"
   - æ— äººç‰©æ—¶ï¼šå¦‚"å¥¶ç²‰ç½å±•ç¤ºè¥å…»æ ‡ç­¾", "äº§å“æ‘†æ”¾æ¡Œé¢"

2. **scene**: æè¿°åœºæ™¯ç¯å¢ƒ (å®¤å†…/æˆ·å¤–ï¼Œå…·ä½“ä½ç½®)

3. **emotion**: åˆ†æç”»é¢ä¼ è¾¾çš„æƒ…ç»ªæˆ–æ°›å›´ï¼š
   - æœ‰äººç‰©æ—¶ï¼šé‡ç‚¹è§‚å¯Ÿé¢éƒ¨è¡¨æƒ…ã€è‚¢ä½“è¯­è¨€ï¼Œåˆ¤æ–­çœŸå®æƒ…ç»ªçŠ¶æ€
   - æ— äººç‰©æ—¶ï¼šåˆ†æç”»é¢è¥é€ çš„æ•´ä½“æ°›å›´ï¼ˆå¦‚ä¸“ä¸šã€æ¸©é¦¨ã€æ¸…æ–°ç­‰ï¼‰
   - é€‰æ‹©è¯æ±‡ï¼šå“­é—¹/ç—›è‹¦/æ‹’ç»/ä¸å¼€å¿ƒ/éš¾å—(è´Ÿé¢) | ä¸“æ³¨/å¹³é™/ä¸­æ€§çŠ¶æ€(ä¸­æ€§) | å¼€å¿ƒ/æ¸©é¦¨/æ„‰æ‚¦(æ­£é¢)

è¾“å‡ºæ ¼å¼ï¼š
interaction: [è¡Œä¸ºæè¿°æˆ–ç‰©ä½“çŠ¶æ€]
scene: [åœºæ™¯æè¿°]  
emotion: [å•ä¸ªè¯æ±‡]"""
            
            # æŒ‰å®˜æ–¹æ ¼å¼æ„å»ºè¯·æ±‚
            payload = {
                "model": self.qwen_model,
                "input": {
                    "messages": [
                        {
                            "role": "user",
                            "content": [
                                {"image": image_base64},
                                {"text": prompt}
                            ]
                        }
                    ]
                },
                "parameters": {
                    "max_tokens": 600,
                    "temperature": 0.05
                }
            }
            
            # å‘é€è¯·æ±‚
            response = self._make_dashscope_request(payload)
            result_text = response.get("output", {}).get("choices", [{}])[0].get("message", {}).get("content", "")
            
            # è§£æç»“æœ
            parsed_result = self._parse_stage1_result(result_text)
            
            logger.info(f"âœ… ç¬¬ä¸€å±‚åˆ†æå®Œæˆ: {parsed_result.get('object', 'æœªçŸ¥')}")
            return parsed_result
            
        except Exception as e:
            logger.error(f"âŒ ç¬¬ä¸€å±‚åˆ†æå¤±è´¥: {str(e)}")
            return {
                "object": "åˆ†æå¤±è´¥",
                "scene": "æœªçŸ¥",
                "emotion": "æœªçŸ¥",
                "confidence": 0.0,
                "stage1_error": str(e)
            }
    
    def _stage2_brand_detection(self, frame: np.ndarray) -> Dict[str, Any]:
        """
        ç¬¬äºŒå±‚ï¼šå“ç‰Œä¸“ç”¨æ£€æµ‹
        ä½¿ç”¨å®˜æ–¹Qwen-VL APIè¿›è¡Œå“ç‰Œè¯†åˆ«
        """
        try:
            # è½¬æ¢å¸§ä¸ºbase64
            image_base64 = self._frame_to_base64(frame)
            if not image_base64:
                raise ValueError("å›¾ç‰‡è½¬æ¢å¤±è´¥")
            
            # å“ç‰Œæ£€æµ‹ä¸“ç”¨prompt (ç²¾ç®€ç‰ˆ)
            brand_prompt = """è¯†åˆ«ç”»é¢ä¸­çš„å¥¶ç²‰å“ç‰Œæ ‡è¯†ã€‚

ç›®æ ‡å“ç‰Œï¼šå¯èµ‹, illuma, æƒ æ°, Wyeth, è•´æ·³, A2, ATWO, HMO

è¦æ±‚ï¼š
- åªè¯†åˆ«åˆ—è¡¨ä¸­çš„å“ç‰Œ
- å¿…é¡»æ¸…æ™°å¯è§
- å¦‚æ— å‘ç°è¾“å‡º"æ— "

è¾“å‡ºæ ¼å¼ï¼šå“ç‰Œåç§°æˆ–"æ— \""""
            
            # æŒ‰å®˜æ–¹æ ¼å¼æ„å»ºè¯·æ±‚
            payload = {
                "model": self.qwen_model,
                "input": {
                    "messages": [
                        {
                            "role": "user",
                            "content": [
                                {"image": image_base64},
                                {"text": brand_prompt}
                            ]
                        }
                    ]
                },
                "parameters": {
                    "max_tokens": 500,
                    "temperature": 0.05
                }
            }
            
            # å‘é€è¯·æ±‚
            response = self._make_dashscope_request(payload)
            result_text = response.get("output", {}).get("choices", [{}])[0].get("message", {}).get("content", "")
            
            # è§£æå“ç‰Œç»“æœ - å¤„ç†listç±»å‹çš„content
            if isinstance(result_text, list):
                if len(result_text) > 0 and isinstance(result_text[0], dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–textå­—æ®µ
                    brand_elements = result_text[0].get('text', str(result_text[0]))
                else:
                    brand_elements = str(result_text[0]) if result_text else "æ— "
            else:
                brand_elements = result_text
            
            brand_elements = brand_elements.strip() if brand_elements else "æ— "
            if not brand_elements or brand_elements.lower() in ["æ— ", "none", "æ— å“ç‰Œ"]:
                brand_elements = "æ— "
            
            logger.info(f"âœ… ç¬¬äºŒå±‚å“ç‰Œæ£€æµ‹å®Œæˆ: {brand_elements}")
            return {
                "brand_elements": brand_elements,
                "stage2_confidence": 0.9 if brand_elements != "æ— " else 0.0
            }
            
        except Exception as e:
            logger.error(f"âŒ ç¬¬äºŒå±‚å“ç‰Œæ£€æµ‹å¤±è´¥: {str(e)}")
            return {
                "brand_elements": "æ— ",
                "stage2_error": str(e)
            }
    
    def _make_dashscope_request(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """å‘é€DashScope APIè¯·æ±‚ï¼ˆå®˜æ–¹æ ¼å¼ï¼‰"""
        headers = {
            "Authorization": f"Bearer {self.dashscope_key}",
            "Content-Type": "application/json"
        }
        
        for attempt in range(self.max_retries):
            try:
                logger.info(f"ğŸ“¡ å‘é€DashScopeè¯·æ±‚ (å°è¯• {attempt + 1}/{self.max_retries})")
                
                response = requests.post(
                    self.dashscope_url,
                    headers=headers,
                    json=payload,
                    timeout=self.timeout
                )
                
                if response.status_code == 200:
                    result = response.json()
                    logger.info("âœ… DashScopeè¯·æ±‚æˆåŠŸ")
                    return result
                else:
                    logger.warning(f"âš ï¸ DashScopeè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                    if attempt < self.max_retries - 1:
                        time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    
            except Exception as e:
                logger.error(f"âŒ DashScopeè¯·æ±‚å¼‚å¸¸: {str(e)}")
                if attempt < self.max_retries - 1:
                    time.sleep(2 ** attempt)
        
        raise Exception("DashScope APIè¯·æ±‚å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def _should_trigger_brand_detection(self, stage1_result: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦è§¦å‘ç¬¬äºŒå±‚å“ç‰Œæ£€æµ‹"""
        trigger_keywords = [
            "å¥¶ç²‰", "å¥¶ç“¶", "äº§å“", "ç½", "åŒ…è£…", "å†²æ³¡", "å–‚å…»", "å–å¥¶", "é…æ–¹å¥¶"
        ]
        
        interaction = stage1_result.get("object", "").lower()
        scene = stage1_result.get("scene", "").lower()
        
        # æ£€æŸ¥äº¤äº’å’Œåœºæ™¯ä¸­æ˜¯å¦åŒ…å«è§¦å‘å…³é”®è¯
        text_to_check = f"{interaction} {scene}"
        return any(keyword in text_to_check for keyword in trigger_keywords)
    
    def _parse_stage1_result(self, result_text: Any) -> Dict[str, Any]:
        """è§£æç¬¬ä¸€å±‚åˆ†æç»“æœ"""
        try:
            # å¦‚æœresult_textæ˜¯listï¼Œæå–ç¬¬ä¸€ä¸ªå…ƒç´ 
            text_content = ""
            if isinstance(result_text, list):
                if len(result_text) > 0 and isinstance(result_text[0], dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–textå­—æ®µ
                    dict_item = result_text[0]
                    text_content = dict_item.get('text', str(dict_item))
                else:
                    text_content = str(result_text[0]) if result_text else ""
            else:
                text_content = str(result_text) if result_text else ""
            
            lines = text_content.strip().split('\n')
            result = {
                "object": "æœªçŸ¥äº¤äº’",
                "scene": "æœªçŸ¥åœºæ™¯", 
                "emotion": "æœªçŸ¥",
                "confidence": 0.8
            }
            
            for line in lines:
                line = line.strip()
                if line.startswith("interaction:"):
                    result["object"] = line.replace("interaction:", "").strip()
                elif line.startswith("scene:"):
                    result["scene"] = line.replace("scene:", "").strip()
                elif line.startswith("emotion:"):
                    result["emotion"] = line.replace("emotion:", "").strip()
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ è§£æç¬¬ä¸€å±‚ç»“æœå¤±è´¥: {str(e)}")
            logger.error(f"   åŸå§‹æ•°æ®ç±»å‹: {type(result_text)}")
            logger.error(f"   åŸå§‹æ•°æ®å†…å®¹: {result_text}")
            return {
                "object": "è§£æå¤±è´¥",
                "scene": "æœªçŸ¥",
                "emotion": "æœªçŸ¥",
                "confidence": 0.0
            }

def _save_individual_analysis(result: Dict[str, Any], input_dir: str) -> str:
    """ä¸ºæ¯ä¸ªè§†é¢‘ä¿å­˜å•ç‹¬çš„ç»“æ„åŒ–åˆ†ææ–‡ä»¶"""
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = Path("data/output")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # è·å–è¾“å…¥ç›®å½•åç§°ä½œä¸ºå­ç›®å½•
        input_path = Path(input_dir)
        dir_name = input_path.name
        structured_output_dir = output_dir / dir_name
        structured_output_dir.mkdir(exist_ok=True)
        
        # ç”Ÿæˆæ¸…ç†åçš„æ–‡ä»¶å
        file_name = result.get("file_name", "unknown.mp4")
        video_name = Path(file_name).stem
        clean_name = "".join(c for c in video_name if c.isalnum() or c in ('_', '-'))
        
        # æ„å»ºç»“æ„åŒ–ç»“æœ
        structured_result = {
            'file_info': {
                'filename': file_name,
                'file_path': result.get('file_path', ''),
                'file_size_mb': result.get('file_size_mb', 0),
                'directory': dir_name
            },
            'analysis_info': {
                'analysis_time': datetime.now().isoformat(),
                'analyzer_version': 'official_v1.0',
                'analysis_method': result.get('analysis_method', 'dual_stage'),
                'success': result.get('success', True)
            },
            'content_analysis': {
                'interaction': result.get('object', 'æœªçŸ¥'),
                'scene': result.get('scene', 'æœªçŸ¥'),
                'emotion': result.get('emotion', 'æœªçŸ¥'),
                'confidence': result.get('confidence', 0.8)
            },
            'brand_detection': {
                'brand_elements': result.get('brand_elements', 'æ— '),
                'brand_detected': result.get('brand_elements', 'æ— ') != 'æ— ',
                'stage2_triggered': result.get('stage2_triggered', False)
            },
            'technical_details': {
                'stage1_success': result.get('stage1_triggered', True),
                'stage2_success': result.get('stage2_triggered', False),
                'processing_time': result.get('processed_at', '')
            }
        }
        
        # ä¿å­˜å•ç‹¬çš„JSONæ–‡ä»¶
        output_file = structured_output_dir / f"{clean_name}_analysis.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(structured_result, f, ensure_ascii=False, indent=2)
        
        logger.debug(f"ğŸ’¾ å•ç‹¬åˆ†ææ–‡ä»¶å·²ä¿å­˜: {output_file}")
        return str(output_file)
        
    except Exception as e:
        logger.error(f"ä¿å­˜å•ç‹¬åˆ†ææ–‡ä»¶å¤±è´¥: {e}")
        return ""

def analyze_videos_with_official_api(input_dir: str, max_files: int = 10) -> Dict[str, Any]:
    """ä½¿ç”¨å®˜æ–¹APIåˆ†æè§†é¢‘æ–‡ä»¶ï¼Œå¹¶è¿‡æ»¤æ— æ•ˆæ–‡ä»¶"""
    try:
        analyzer = OfficialAIAnalyzer()
        
        # æ‰«æè§†é¢‘æ–‡ä»¶
        video_extensions = [".mp4", ".avi", ".mov", ".mkv", ".m4v"]
        video_files = []
        filtered_count = 0  # è¿‡æ»¤æ–‡ä»¶è®¡æ•°
        
        def _should_filter_video_file(file_path: Path) -> bool:
            """åˆ¤æ–­è§†é¢‘æ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«è¿‡æ»¤"""
            # ğŸ¯ ç”¨æˆ·åé¦ˆï¼šå¤šé•œå¤´è§†é¢‘ä¹Ÿåº”è¯¥è¢«åˆ†æï¼Œåªè¿‡æ»¤çœŸæ­£å¤±è´¥çš„æ–‡ä»¶
            # åªè¿‡æ»¤âŒå‰ç¼€çš„æ–‡ä»¶ï¼ˆåˆ†æå¤±è´¥ï¼‰ï¼Œâ™»ï¸æ–‡ä»¶å…è®¸æ­£å¸¸åˆ†æ
            if file_path.stem.startswith("âŒ"):
                return True
            return False
        
        for root, dirs, files in os.walk(input_dir):
            for file in files:
                if any(file.lower().endswith(ext) for ext in video_extensions):
                    file_path = Path(root) / file
                    # ğŸš¨ æ–°å¢ï¼šè¿‡æ»¤é€»è¾‘
                    if _should_filter_video_file(file_path):
                        filtered_count += 1
                        logger.debug(f"ğŸš« è¿‡æ»¤è§†é¢‘æ–‡ä»¶: {file_path.name} (è´¨é‡é—®é¢˜)")
                        continue
                    video_files.append(os.path.join(root, file))
        
        if filtered_count > 0:
            logger.info(f"ğŸš« å®˜æ–¹APIåˆ†æè¿‡æ»¤äº† {filtered_count} ä¸ªè´¨é‡é—®é¢˜è§†é¢‘æ–‡ä»¶")
        
        if max_files:
            video_files = video_files[:max_files]
        
        logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œå¼€å§‹å®˜æ–¹APIåˆ†æ")
        
        results = []
        failed_files = []
        
        for i, video_file in enumerate(video_files, 1):
            logger.info(f"ğŸ¬ å¤„ç†è¿›åº¦: {i}/{len(video_files)} - {Path(video_file).name}")
            
            result = analyzer.analyze_video_dual_stage(video_file)
            
            if result.get("success"):
                results.append(result)
                
                # ä¸ºæ¯ä¸ªè§†é¢‘ä¿å­˜å•ç‹¬çš„ç»“æ„åŒ–JSONæ–‡ä»¶
                _save_individual_analysis(result, input_dir)
            else:
                failed_files.append(result)
            
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™æµ
            if i < len(video_files):
                time.sleep(1)
        
        return {
            "total_analyzed": len(video_files),
            "successful_analyses": len(results),
            "failed_analyses": len(failed_files),
            "filtered_files": filtered_count,
            "results": results,
            "failed_files": failed_files
        }
        
    except Exception as e:
        logger.error(f"å®˜æ–¹APIåˆ†æå¤±è´¥: {e}")
        return {"error": str(e)}

if __name__ == "__main__":
    import argparse
    
    # è‡ªåŠ¨åŠ è½½.envæ–‡ä»¶
    print("ğŸ”§ æ­£åœ¨åŠ è½½ç¯å¢ƒé…ç½®...")
    env_loader = load_environment()
    
    # éªŒè¯é…ç½®
    if not env_loader.validate_config():
        print("âŒ ç¯å¢ƒé…ç½®ä¸å®Œæ•´")
        print("ğŸ’¡ è¯·æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ .env æ–‡ä»¶")
        sys.exit(1)
    
    parser = argparse.ArgumentParser(description="å®˜æ–¹è§„èŒƒAIè§†é¢‘åˆ†æå·¥å…·")
    parser.add_argument("--input", default="data/input", help="è¾“å…¥ç›®å½•")
    parser.add_argument("--max-files", type=int, default=5, help="æœ€å¤§æ–‡ä»¶æ•°")
    
    args = parser.parse_args()
    
    print("ğŸš€ å¯åŠ¨å®˜æ–¹è§„èŒƒAIåˆ†æ...")
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {args.input}")
    print(f"ğŸ“Š æœ€å¤§æ–‡ä»¶æ•°: {args.max_files}")
    print()
    
    # åˆ†æè§†é¢‘
    report = analyze_videos_with_official_api(args.input, args.max_files)
    
    if "error" not in report:
        # ä¿å­˜æŠ¥å‘Š - ä½¿ç”¨ç»“æ„åŒ–å‘½å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        input_dir_name = Path(args.input).name if hasattr(args, 'input') else 'mixed'
        output_file = f"data/output/official_analysis_{input_dir_name}_{timestamp}.json"
        os.makedirs("data/output", exist_ok=True)
        
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # æ˜¾ç¤ºç»“æœ
        summary = report["summary"]
        print(f"\nğŸ“Š å®˜æ–¹APIåˆ†æå®Œæˆ:")
        print(f"ğŸ“‹ æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
        print(f"âœ… æˆåŠŸæ–‡ä»¶: {summary['successful_files']}")
        print(f"âŒ å¤±è´¥æ–‡ä»¶: {summary['failed_files']}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {summary['success_rate']}")
        print(f"ğŸ”§ APIç‰ˆæœ¬: {summary['api_version']}")
        print(f"ğŸ“ æŠ¥å‘Šæ–‡ä»¶: {output_file}")
        
        # æ˜¾ç¤ºåˆ†æç»“æœç¤ºä¾‹
        if report["results"]:
            print(f"\nğŸ¯ åˆ†æç»“æœç¤ºä¾‹:")
            for i, result in enumerate(report["results"][:3], 1):
                print(f"\n{i}. {result['file_name']} ({result['file_size_mb']}MB)")
                print(f"   ğŸ“‹ äº¤äº’è¡Œä¸º: {result.get('object', 'æœªçŸ¥')}")
                print(f"   ğŸ  åœºæ™¯ç¯å¢ƒ: {result.get('scene', 'æœªçŸ¥')}")
                print(f"   ğŸ˜Š æƒ…ç»ªçŠ¶æ€: {result.get('emotion', 'æœªçŸ¥')}")
                print(f"   ğŸ·ï¸ å“ç‰Œå…ƒç´ : {result.get('brand_elements', 'æ— ')}")
                print(f"   ğŸ” ç¬¬ä¸€å±‚: âœ… | ç¬¬äºŒå±‚: {'âœ…' if result.get('stage2_triggered') else 'âšª'}")
    else:
        print(f"âŒ åˆ†æå¤±è´¥: {report['error']}")
