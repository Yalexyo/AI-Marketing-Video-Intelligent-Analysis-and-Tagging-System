#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½å…³é”®å¸§æå–å™¨
æ ¹æ®è§†é¢‘æ—¶é•¿ã€å†…å®¹å˜åŒ–å’Œåœºæ™¯åˆ‡æ¢æ™ºèƒ½æå–å…³é”®å¸§
"""

import cv2
import numpy as np
import logging
from typing import List, Tuple, Dict, Any
from pathlib import Path

logger = logging.getLogger(__name__)

class SmartFrameExtractor:
    """
    æ™ºèƒ½å…³é”®å¸§æå–å™¨
    æ ¹æ®è§†é¢‘ç‰¹å¾è‡ªé€‚åº”æå–æœ€å…·ä»£è¡¨æ€§çš„å…³é”®å¸§
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æå–å™¨"""
        # æ—¶é•¿åˆ†çº§ç­–ç•¥
        self.duration_strategies = {
            "ultra_short": {"max_duration": 2.0, "min_frames": 1, "max_frames": 2},
            "short": {"max_duration": 5.0, "min_frames": 2, "max_frames": 3}, 
            "medium": {"max_duration": 15.0, "min_frames": 3, "max_frames": 5},
            "long": {"max_duration": 60.0, "min_frames": 5, "max_frames": 8},
            "very_long": {"max_duration": float('inf'), "min_frames": 8, "max_frames": 12}
        }
        
        # å†…å®¹å˜åŒ–æ£€æµ‹é˜ˆå€¼
        self.content_change_threshold = 0.3
        self.histogram_bins = 32
        
    def extract_key_frames(self, video_path: str) -> List[Dict[str, Any]]:
        """
        æ™ºèƒ½æå–å…³é”®å¸§
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            å…³é”®å¸§åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«frameæ•°æ®å’Œå…ƒæ•°æ®
        """
        try:
            cap = cv2.VideoCapture(video_path)
            
            # è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = total_frames / fps if fps > 0 else 0
            
            logger.info(f"ğŸ¬ è§†é¢‘ä¿¡æ¯: {duration:.1f}ç§’, {fps:.1f}FPS, {total_frames}å¸§")
            
            # æ ¹æ®æ—¶é•¿ç¡®å®šæå–ç­–ç•¥
            strategy = self._get_duration_strategy(duration)
            logger.info(f"ğŸ“‹ æå–ç­–ç•¥: {strategy['strategy_name']} (ç›®æ ‡å¸§æ•°: {strategy['min_frames']}-{strategy['max_frames']})")
            
            # æ‰§è¡Œæ™ºèƒ½æå–
            key_frames = self._smart_extract(cap, fps, total_frames, duration, strategy)
            
            cap.release()
            
            logger.info(f"ğŸ–¼ï¸ æ™ºèƒ½æå–å®Œæˆ: {len(key_frames)} ä¸ªå…³é”®å¸§")
            return key_frames
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½å¸§æå–å¤±è´¥: {str(e)}")
            return []
    
    def _get_duration_strategy(self, duration: float) -> Dict[str, Any]:
        """æ ¹æ®è§†é¢‘æ—¶é•¿é€‰æ‹©æå–ç­–ç•¥"""
        for strategy_name, config in self.duration_strategies.items():
            if duration <= config["max_duration"]:
                return {
                    "strategy_name": strategy_name,
                    **config
                }
        
        # é»˜è®¤è¿”å›æœ€é•¿æ—¶é•¿ç­–ç•¥
        return {
            "strategy_name": "very_long",
            **self.duration_strategies["very_long"]
        }
    
    def _smart_extract(self, cap, fps: float, total_frames: int, duration: float, strategy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ™ºèƒ½æå–å…³é”®å¸§"""
        key_frames = []
        
        # æ–¹æ³•1: æ—¶é—´å‡åŒ€åˆ†å¸ƒ + å†…å®¹å˜åŒ–æ£€æµ‹
        if duration <= 5.0:
            # çŸ­è§†é¢‘ï¼šæ—¶é—´å‡åŒ€åˆ†å¸ƒ
            key_frames = self._extract_time_distributed(cap, fps, total_frames, strategy)
        elif duration <= 15.0:
            # ä¸­ç­‰è§†é¢‘ï¼šå†…å®¹å˜åŒ–æ£€æµ‹ + æ—¶é—´åˆ†å¸ƒ
            key_frames = self._extract_content_aware(cap, fps, total_frames, strategy)
        else:
            # é•¿è§†é¢‘ï¼šæ··åˆç­–ç•¥
            key_frames = self._extract_hybrid_strategy(cap, fps, total_frames, strategy)
        
        return key_frames
    
    def _extract_time_distributed(self, cap, fps: float, total_frames: int, strategy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ—¶é—´å‡åŒ€åˆ†å¸ƒæå–"""
        key_frames = []
        target_count = min(strategy["max_frames"], max(strategy["min_frames"], total_frames // 10))
        
        if target_count == 1:
            # åªå–ä¸­é—´å¸§
            frame_indices = [total_frames // 2]
        else:
            # å‡åŒ€åˆ†å¸ƒ
            step = total_frames // target_count
            frame_indices = [i * step for i in range(target_count)]
        
        for i, frame_idx in enumerate(frame_indices):
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            if ret:
                timestamp = frame_idx / fps
                key_frames.append({
                    "frame": frame,
                    "frame_index": frame_idx,
                    "timestamp": timestamp,
                    "extraction_method": "time_distributed",
                    "confidence": 0.9
                })
        
        return key_frames
    
    def _extract_content_aware(self, cap, fps: float, total_frames: int, strategy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åŸºäºå†…å®¹å˜åŒ–çš„æ™ºèƒ½æå–"""
        key_frames = []
        
        # é¦–å…ˆè·å–æ‰€æœ‰å¸§çš„ç›´æ–¹å›¾
        histograms = []
        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
        
        frame_step = max(1, total_frames // 50)  # æœ€å¤šé‡‡æ ·50ä¸ªç‚¹è¿›è¡Œå†…å®¹åˆ†æ
        
        for frame_idx in range(0, total_frames, frame_step):
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            if ret:
                hist = self._calculate_histogram(frame)
                histograms.append((frame_idx, hist))
        
        # æ£€æµ‹å†…å®¹å˜åŒ–ç‚¹
        change_points = self._detect_content_changes(histograms)
        
        # åœ¨å˜åŒ–ç‚¹é™„è¿‘æå–å…³é”®å¸§
        selected_indices = self._select_representative_frames(change_points, total_frames, strategy)
        
        # æå–é€‰å®šçš„å¸§
        for frame_idx in selected_indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            if ret:
                timestamp = frame_idx / fps
                key_frames.append({
                    "frame": frame,
                    "frame_index": frame_idx,
                    "timestamp": timestamp,
                    "extraction_method": "content_aware",
                    "confidence": 0.85
                })
        
        return key_frames
    
    def _extract_hybrid_strategy(self, cap, fps: float, total_frames: int, strategy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ··åˆç­–ç•¥ï¼šç»“åˆæ—¶é—´åˆ†å¸ƒå’Œå†…å®¹å˜åŒ–"""
        key_frames = []
        
        # 50% æ—¶é—´åˆ†å¸ƒ + 50% å†…å®¹å˜åŒ–
        time_count = strategy["max_frames"] // 2
        content_count = strategy["max_frames"] - time_count
        
        # æ—¶é—´åˆ†å¸ƒå¸§
        time_strategy = {"min_frames": time_count, "max_frames": time_count}
        time_frames = self._extract_time_distributed(cap, fps, total_frames, time_strategy)
        
        # å†…å®¹å˜åŒ–å¸§
        content_strategy = {"min_frames": content_count, "max_frames": content_count}
        content_frames = self._extract_content_aware(cap, fps, total_frames, content_strategy)
        
        # åˆå¹¶å¹¶å»é‡
        all_frames = time_frames + content_frames
        unique_frames = self._deduplicate_frames(all_frames)
        
        return unique_frames[:strategy["max_frames"]]
    
    def _calculate_histogram(self, frame: np.ndarray) -> np.ndarray:
        """è®¡ç®—å¸§çš„é¢œè‰²ç›´æ–¹å›¾"""
        # è½¬æ¢ä¸ºHSVè‰²å½©ç©ºé—´
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        
        # è®¡ç®—3Dç›´æ–¹å›¾
        hist = cv2.calcHist([hsv], [0, 1, 2], None, 
                           [self.histogram_bins, self.histogram_bins, self.histogram_bins],
                           [0, 180, 0, 256, 0, 256])
        
        # å½’ä¸€åŒ–
        hist = cv2.normalize(hist, hist).flatten()
        return hist
    
    def _detect_content_changes(self, histograms: List[Tuple[int, np.ndarray]]) -> List[int]:
        """æ£€æµ‹å†…å®¹å˜åŒ–ç‚¹"""
        change_points = [histograms[0][0]]  # æ€»æ˜¯åŒ…å«ç¬¬ä¸€å¸§
        
        for i in range(1, len(histograms)):
            prev_hist = histograms[i-1][1]
            curr_hist = histograms[i][1]
            
            # è®¡ç®—ç›´æ–¹å›¾ç›¸å…³æ€§
            correlation = cv2.compareHist(prev_hist, curr_hist, cv2.HISTCMP_CORREL)
            
            # å¦‚æœç›¸å…³æ€§ä½äºé˜ˆå€¼ï¼Œè®¤ä¸ºæ˜¯å†…å®¹å˜åŒ–ç‚¹
            if correlation < (1 - self.content_change_threshold):
                change_points.append(histograms[i][0])
        
        return change_points
    
    def _select_representative_frames(self, change_points: List[int], total_frames: int, strategy: Dict[str, Any]) -> List[int]:
        """ä»å˜åŒ–ç‚¹ä¸­é€‰æ‹©ä»£è¡¨æ€§å¸§"""
        if len(change_points) <= strategy["max_frames"]:
            return change_points
        
        # å¦‚æœå˜åŒ–ç‚¹å¤ªå¤šï¼Œå‡åŒ€é€‰æ‹©
        step = len(change_points) // strategy["max_frames"]
        selected = [change_points[i * step] for i in range(strategy["max_frames"])]
        
        return selected
    
    def _deduplicate_frames(self, frames: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å»é™¤é‡å¤å¸§"""
        seen_indices = set()
        unique_frames = []
        
        for frame_data in frames:
            frame_idx = frame_data["frame_index"]
            if frame_idx not in seen_indices:
                seen_indices.add(frame_idx)
                unique_frames.append(frame_data)
        
        # æŒ‰æ—¶é—´æˆ³æ’åº
        unique_frames.sort(key=lambda x: x["timestamp"])
        return unique_frames
    
    def get_extraction_summary(self, key_frames: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆæå–æ‘˜è¦"""
        if not key_frames:
            return {"error": "æ— å…³é”®å¸§"}
        
        methods = {}
        for frame_data in key_frames:
            method = frame_data.get("extraction_method", "unknown")
            methods[method] = methods.get(method, 0) + 1
        
        total_duration = key_frames[-1]["timestamp"] if key_frames else 0
        
        return {
            "total_frames": len(key_frames),
            "extraction_methods": methods,
            "time_span": f"0.0-{total_duration:.1f}ç§’",
            "coverage": "å®Œæ•´è¦†ç›–" if len(key_frames) >= 3 else "éƒ¨åˆ†è¦†ç›–",
            "avg_confidence": np.mean([f.get("confidence", 0.8) for f in key_frames])
        }

def extract_smart_frames(video_path: str) -> List[Dict[str, Any]]:
    """ä¾¿æ·å‡½æ•°ï¼šæ™ºèƒ½æå–å…³é”®å¸§"""
    extractor = SmartFrameExtractor()
    return extractor.extract_key_frames(video_path)

if __name__ == "__main__":
    # æµ‹è¯•æ™ºèƒ½å…³é”®å¸§æå–
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python smart_frame_extractor.py <video_path>")
        sys.exit(1)
    
    video_path = sys.argv[1]
    if not Path(video_path).exists():
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        sys.exit(1)
    
    print(f"ğŸ¯ å¼€å§‹æ™ºèƒ½å…³é”®å¸§æå–: {video_path}")
    
    extractor = SmartFrameExtractor()
    key_frames = extractor.extract_key_frames(video_path)
    
    if key_frames:
        summary = extractor.get_extraction_summary(key_frames)
        print(f"\nğŸ“Š æå–æ‘˜è¦:")
        print(f"   å…³é”®å¸§æ•°é‡: {summary['total_frames']}")
        print(f"   æ—¶é—´è·¨åº¦: {summary['time_span']}")
        print(f"   è¦†ç›–è´¨é‡: {summary['coverage']}")
        print(f"   å¹³å‡ç½®ä¿¡åº¦: {summary['avg_confidence']:.2f}")
        print(f"   æå–æ–¹æ³•: {summary['extraction_methods']}")
        
        print(f"\nğŸ–¼ï¸ å…³é”®å¸§è¯¦æƒ…:")
        for i, frame_data in enumerate(key_frames, 1):
            print(f"   {i}. æ—¶é—´æˆ³: {frame_data['timestamp']:.1f}s, "
                  f"æ–¹æ³•: {frame_data['extraction_method']}")
    else:
        print("âŒ æœªèƒ½æå–å…³é”®å¸§") 