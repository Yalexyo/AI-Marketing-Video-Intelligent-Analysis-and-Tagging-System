#!/usr/bin/env python3
"""
æ‰¹é‡SRTè½¬äº§å“ä»‹ç»è§†é¢‘å¤„ç†å™¨
åè°ƒæ•´ä¸ªå¤„ç†æµç¨‹ï¼šSRTè§£æ -> AIåˆ†æ -> è§†é¢‘ç”Ÿæˆ
"""

import json
import logging
import time
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from datetime import datetime

try:
    from .srt_parser import SRTParser
    from .deepseek_analyzer import DeepSeekAnalyzer
    from .video_generator import VideoGenerator
    from .env_loader import validate_config, get_config_summary
except ImportError:
    from srt_parser import SRTParser
    from deepseek_analyzer import DeepSeekAnalyzer
    from video_generator import VideoGenerator
    from env_loader import validate_config, get_config_summary

logger = logging.getLogger(__name__)

class BatchSRTToProductProcessor:
    """æ‰¹é‡SRTè½¬äº§å“ä»‹ç»è§†é¢‘å¤„ç†å™¨"""
    
    def __init__(self, input_video_dir: str, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
        
        Args:
            input_video_dir: åŸå§‹è§†é¢‘ç›®å½•è·¯å¾„
            api_key: DeepSeek APIå¯†é’¥
        """
        self.input_video_dir = Path(input_video_dir)
        
        # éªŒè¯é…ç½®
        if not validate_config():
            raise ValueError("é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥è®¾ç½®")
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.srt_parser = SRTParser()
        self.ai_analyzer = DeepSeekAnalyzer(api_key=api_key)
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("æ‰¹é‡å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # è®°å½•é…ç½®ä¿¡æ¯
        config_summary = get_config_summary()
        self.logger.info(f"é…ç½®æ‘˜è¦: {config_summary}")
    
    def process_batch(self, srt_dir: Path, output_dir: str, 
                     temp_dir: str = "data/temp") -> Tuple[Dict, Path]:
        """
        æ‰¹é‡å¤„ç†SRTæ–‡ä»¶
        
        Args:
            srt_dir: SRTæ–‡ä»¶ç›®å½•
            output_dir: è¾“å‡ºè§†é¢‘ç›®å½•
            temp_dir: ä¸´æ—¶ç›®å½•
            
        Returns:
            å¤„ç†ç»“æœæ‘˜è¦
        """
        start_time = time.time()
        
        self.temp_dir = Path(temp_dir)
        self.output_dir = Path(output_dir)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.temp_dir.mkdir(parents=True, exist_ok=True)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger.info("å¼€å§‹æ‰¹é‡å¤„ç†")
        self.logger.info(f"SRTç›®å½•: {srt_dir}")
        self.logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        self.logger.info(f"åŸå§‹è§†é¢‘ç›®å½•: {self.input_video_dir}")
        
        srt_files = self._scan_srt_files(srt_dir)
        self.logger.info(f"å‘ç°{len(srt_files)}ä¸ªSRTæ–‡ä»¶")
            
        all_processing_results = []
        all_video_results = []

        # åˆå§‹åŒ–è§†é¢‘ç”Ÿæˆå™¨
        video_generator = VideoGenerator(
            input_dir=str(self.input_video_dir),
            output_dir=str(self.output_dir)
        )
        self.logger.info("è§†é¢‘ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
            
        for i, srt_file in enumerate(srt_files):
            self.logger.info(f"å¤„ç†æ–‡ä»¶ {i+1}/{len(srt_files)}: {srt_file.name}")
                
            processing_result, video_results = self._process_file(
                srt_file, video_generator
            )
            all_processing_results.append(processing_result)
            all_video_results.extend(video_results)
            
        # ç”Ÿæˆå¹¶ä¿å­˜æŠ¥å‘Š
        report = self._generate_report(all_processing_results, all_video_results, start_time)
        report_path = self._save_report(report, self.output_dir)
            
        # ğŸš€ è‡ªåŠ¨æ•´ç†æ–‡ä»¶åˆ°ç»“æ„åŒ–ç›®å½•
        # self._auto_organize_outputs()
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        self._cleanup_temp_dir()
        
        return report, report_path

    def _process_file(self, srt_file: Path, video_generator: 'VideoGenerator') -> Tuple[Dict, List[Dict]]:
        """å¤„ç†å•ä¸ªSRTæ–‡ä»¶ï¼Œåˆ†æå¹¶ä¸ºæ¯ä¸ªä¸»é¢˜ç”Ÿæˆè§†é¢‘"""
        
        # ğŸš€ æ¸…ç†è¯¥è§†é¢‘çš„æ—§äº§å“ä»‹ç»æ–‡ä»¶ï¼Œé¿å…é‡å¤ç´¯ç§¯
        self._clean_old_product_videos(srt_file.stem)
        
        # 1. è§£æSRT
        segments = self.srt_parser.parse_srt_file(srt_file)
        if not segments:
            return {'filename': srt_file.name, 'success': False, 'error': 'SRTè§£æå¤±è´¥'}, []

        # 2. AIåˆ†ææ‰€æœ‰ä¸»é¢˜
        product_mentions = self.ai_analyzer.analyze_srt_content(segments, srt_file.name)
        if not product_mentions:
            return {'filename': srt_file.name, 'success': False, 'error': 'AIæœªè¯†åˆ«åˆ°äº§å“ä¸»é¢˜'}, []
        
        # ğŸ¯ åªä¿ç•™é«˜ç½®ä¿¡åº¦çš„æ ¸å¿ƒäº§å“ä¸»é¢˜ï¼Œè¿‡æ»¤ä½è´¨é‡å†…å®¹
        core_mentions = [m for m in product_mentions if m.confidence >= 0.8]
        if not core_mentions:
            self.logger.warning(f"æœªæ‰¾åˆ°é«˜ç½®ä¿¡åº¦ä¸»é¢˜ï¼Œä½¿ç”¨æ‰€æœ‰è¯†åˆ«çš„ä¸»é¢˜")
            core_mentions = product_mentions
        
        self.logger.info(f"AIåˆ†æå®Œæˆï¼Œè¯†åˆ«åˆ°{len(product_mentions)}ä¸ªä¸»é¢˜ï¼Œç­›é€‰å‡º{len(core_mentions)}ä¸ªæ ¸å¿ƒä¸»é¢˜")

        # 3. ä¸ºæ¯ä¸ªæ ¸å¿ƒä¸»é¢˜ç”Ÿæˆè§†é¢‘
        video_results = []
        for mention in core_mentions:
            self.logger.info(f"ä¸ºä¸»é¢˜ '{mention.topic}' ç”Ÿæˆè§†é¢‘...")
            
            # åˆ›å»ºä¸€ä¸ªç¬¦åˆæ—§ç‰ˆé€»è¾‘çš„ "segment_info"
            segment_info_for_video = {
                'start_time': mention.start_time,
                'end_time': mention.end_time,
                'topic': mention.topic,
                'sequence_ids': mention.sequence_ids,
                'summary': mention.summary,
                'keywords': mention.keywords,
                'logic_pattern': mention.logic_pattern,
                'confidence': mention.confidence,
                'scene_type': mention.scene_type,
                'duration': mention.duration
            }

            video_result = video_generator.generate_video_from_segment(
                srt_filename=srt_file.name,
                segment_info=segment_info_for_video,
                use_topic_as_filename=True # <--- æ–°å¢é€»è¾‘
            )
            video_results.append(video_result)

            if video_result['success']:
                self.logger.info(f"æˆåŠŸç”Ÿæˆè§†é¢‘: {video_result['output_path']}")
            else:
                self.logger.error(f"ä¸»é¢˜ '{mention.topic}' è§†é¢‘ç”Ÿæˆå¤±è´¥: {video_result['error']}")

        # 4. æ„å»ºå¤„ç†ç»“æœ
        processing_result = {
            'filename': srt_file.name,
            'success': True,
            'error': None,
            'segments_count': len(segments),
            'product_mentions': core_mentions,  # åªè¿”å›æ ¸å¿ƒä¸»é¢˜
            'analysis_summary': self.ai_analyzer.get_analysis_summary(core_mentions)
        }
        
        return processing_result, video_results

    def _clean_old_product_videos(self, video_stem: str):
        """æ¸…ç†æŒ‡å®šè§†é¢‘çš„æ—§äº§å“ä»‹ç»æ–‡ä»¶ï¼ˆè§†é¢‘+SRTï¼‰"""
        try:
            # æ¸…ç†è§†é¢‘æ–‡ä»¶
            mp4_pattern = f"{video_stem}_*.mp4"
            old_videos = list(self.output_dir.glob(mp4_pattern))
            
            # æ¸…ç†SRTæ–‡ä»¶
            srt_pattern = f"{video_stem}_*.srt"
            old_srts = list(self.output_dir.glob(srt_pattern))
            
            old_files = old_videos + old_srts
            
            if old_files:
                self.logger.info(f"æ¸…ç†{len(old_files)}ä¸ªæ—§çš„äº§å“æ–‡ä»¶...")
                for old_file in old_files:
                    old_file.unlink()
                    self.logger.debug(f"åˆ é™¤: {old_file.name}")
            
        except Exception as e:
            self.logger.warning(f"æ¸…ç†æ—§æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def _scan_srt_files(self, srt_dir: Path) -> List[Path]:
        """æ‰«æç›®å½•ä¸‹çš„SRTæ–‡ä»¶ï¼ˆé€’å½’æ‰«æå­ç›®å½•ï¼‰"""
        # ğŸ” é€’å½’æœç´¢æ‰€æœ‰SRTæ–‡ä»¶ï¼ŒåŒ…æ‹¬å­ç›®å½•
        srt_files = list(srt_dir.rglob('*.srt'))
        
        # ğŸš« è¿‡æ»¤æ‰å·²ç»æ˜¯äº§å“åˆ‡ç‰‡çš„SRTæ–‡ä»¶ï¼Œé¿å…é‡å¤å¤„ç†å’Œæ—¶é—´æˆ³é”™è¯¯
        filtered_files = []
        for srt_file in srt_files:
            # æ’é™¤åŒ…å«äº§å“ä¸»é¢˜åç§°çš„åˆ‡ç‰‡æ–‡ä»¶
            exclude_keywords = ['å¯èµ‹è•´æ·³', 'å¯èµ‹æ°´å¥¶', 'å¯èµ‹è“é’»', '_product', 'äº§å“ä»‹ç»', 'æ ¸å¿ƒé…æ–¹', 'ä¾¿æº']
            if any(keyword in srt_file.name for keyword in exclude_keywords):
                self.logger.info(f"è·³è¿‡äº§å“åˆ‡ç‰‡SRTæ–‡ä»¶: {srt_file.name}")
                continue
                
            # âœ… åªå¤„ç†å®Œæ•´SRTæ–‡ä»¶ï¼ˆæ ¹æ®æ¶æ„è®¾è®¡åŸåˆ™ï¼‰
            if '_full.srt' in srt_file.name:
                filtered_files.append(srt_file)
                self.logger.info(f"æ‰¾åˆ°å®Œæ•´SRTæ–‡ä»¶: {srt_file}")
            else:
                self.logger.debug(f"è·³è¿‡éå®Œæ•´SRTæ–‡ä»¶: {srt_file.name}")
        
        filtered_files.sort()  # æŒ‰æ–‡ä»¶åæ’åº
        return filtered_files
    
    def _generate_report(self, processing_results: List[Dict], 
                        video_results: List[Dict], start_time: float) -> Dict:
        """ç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
        end_time = time.time()
        processing_time = end_time - start_time
        
        # ç»Ÿè®¡SRTå¤„ç†ç»“æœ
        srt_total = len(processing_results)
        srt_success = sum(1 for r in processing_results if r['success'])
        srt_failed = srt_total - srt_success
        
        # ç»Ÿè®¡è§†é¢‘ç”Ÿæˆç»“æœ
        video_total = len(video_results)
        video_success = sum(1 for r in video_results if r['success'])
        video_failed = video_total - video_success
        
        # æ”¶é›†AIåˆ†æç»Ÿè®¡
        total_segments_analyzed = sum(
            len(r.get('product_mentions', [])) for r in processing_results if r['success']
        )
        
        best_confidences = [
            r['product_mentions'][0].confidence 
            for r in processing_results 
            if r['success'] and r['product_mentions']
        ]
        
        avg_confidence = sum(best_confidences) / len(best_confidences) if best_confidences else 0
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'processing_time': processing_time,
            'summary': {
                'srt_processing': {
                    'total': srt_total,
                    'success': srt_success,
                    'failed': srt_failed,
                    'success_rate': srt_success / srt_total if srt_total > 0 else 0
                },
                'video_generation': {
                    'total': video_total,
                    'success': video_success,
                    'failed': video_failed,
                    'success_rate': video_success / video_total if video_total > 0 else 0
                },
                'ai_analysis': {
                    'total_segments_analyzed': total_segments_analyzed,
                    'avg_confidence': avg_confidence,
                    'segments_with_products': len(best_confidences)
                }
            },
            'detailed_results': {
                'srt_processing': [{
                    'filename': r['filename'],
                    'success': r['success'],
                    'error': r['error'],
                    'segments_count': r['segments_count'],
                    'product_mentions': r['product_mentions'],
                    'analysis_summary': r['analysis_summary']
                } for r in processing_results],
                'video_generation': video_results
            },
            'config_used': get_config_summary()
        }
        
        return report
    
    def _save_report(self, report: Dict, output_dir: Path) -> Path:
        """ä¿å­˜å¤„ç†æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_filename = f"srt_to_product_report_{timestamp}.json"
        report_file = output_dir / report_filename
        
        try:
            # å°†ProductSegmentå¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸
            serializable_report = self._make_serializable(report)
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(serializable_report, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            return report_file
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
            return output_dir / "report_save_failed.txt"
    
    def _make_serializable(self, obj):
        """å°†å¯¹è±¡è½¬æ¢ä¸ºå¯JSONåºåˆ—åŒ–çš„æ ¼å¼"""
        if hasattr(obj, '__dict__'):
            # å¤„ç†è‡ªå®šä¹‰å¯¹è±¡ï¼ˆå¦‚ProductSegmentï¼‰
            return {
                'topic': getattr(obj, 'topic', 'æœªå®šä¹‰'),
                'sequence_ids': getattr(obj, 'sequence_ids', []),
                'summary': getattr(obj, 'summary', ''),
                'start_time': obj.start_time,
                'end_time': obj.end_time,
                'duration': obj.duration,
                'confidence': obj.confidence,
                'keywords': obj.keywords,
                'logic_pattern': getattr(obj, 'logic_pattern', 'å…¶ä»–'),
                'scene_type': getattr(obj, 'scene_type', 'æœªåˆ†ç±»')
            }
        elif isinstance(obj, dict):
            return {k: self._make_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_serializable(item) for item in obj]
        else:
            return obj
    
    def get_input_video_files(self) -> List[Path]:
        """è·å–è¾“å…¥è§†é¢‘ç›®å½•ä¸­çš„è§†é¢‘æ–‡ä»¶åˆ—è¡¨"""
        video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.wmv', '.flv']
        video_files = []
        
        for ext in video_extensions:
            video_files.extend(self.input_video_dir.glob(f'*{ext}'))
            video_files.extend(self.input_video_dir.glob(f'*{ext.upper()}'))
        
        return sorted(video_files)
    
    def validate_input_setup(self, srt_dir: Path) -> Dict:
        """éªŒè¯è¾“å…¥è®¾ç½®"""
        srt_dir = Path(srt_dir)
        
        # æ£€æŸ¥SRTç›®å½•
        if not srt_dir.exists():
            return {'valid': False, 'error': f'SRTç›®å½•ä¸å­˜åœ¨: {srt_dir}'}
        
        # æ£€æŸ¥åŸå§‹è§†é¢‘ç›®å½•
        if not self.input_video_dir.exists():
            return {'valid': False, 'error': f'åŸå§‹è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {self.input_video_dir}'}
        
        # æ‰«ææ–‡ä»¶
        srt_files = self._scan_srt_files(srt_dir)
        video_files = self.get_input_video_files()
        
        if not srt_files:
            return {'valid': False, 'error': 'SRTç›®å½•ä¸­æœªæ‰¾åˆ°.srtæ–‡ä»¶'}
        
        if not video_files:
            return {'valid': False, 'error': 'åŸå§‹è§†é¢‘ç›®å½•ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶'}
        
        # æ£€æŸ¥åŒ¹é…æƒ…å†µ
        matched_pairs = []
        unmatched_srt = []
        
        for srt_file in srt_files:
            base_name = srt_file.stem
            matched = False
            
            for video_file in video_files:
                if video_file.stem == base_name:
                    matched_pairs.append((srt_file.name, video_file.name))
                    matched = True
                    break
            
            if not matched:
                unmatched_srt.append(srt_file.name)
        
        return {
            'valid': True,
            'srt_files_count': len(srt_files),
            'video_files_count': len(video_files),
            'matched_pairs': matched_pairs,
            'unmatched_srt': unmatched_srt,
            'expected_outputs': len(matched_pairs)
        } 

    def _cleanup_temp_dir(self):
        """æ¸…ç†ä¸´æ—¶ç›®å½•"""
        # å®ç°æ¸…ç†ä¸´æ—¶ç›®å½•çš„é€»è¾‘
        pass

    def _cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        # å®ç°æ¸…ç†ä¸´æ—¶æ–‡ä»¶çš„é€»è¾‘
        pass

    # def _auto_organize_outputs(self):
    #     """è‡ªåŠ¨æ•´ç†è¾“å‡ºæ–‡ä»¶åˆ°ç»“æ„åŒ–ç›®å½•"""
    #     try:
    #         import sys
    #         # æ·»åŠ MCPæœåŠ¡å™¨è·¯å¾„ä»¥ä¾¿å¯¼å…¥auto_organizer
    #         mcp_path = Path(__file__).parent.parent.parent / "mcp_server"
    #         if str(mcp_path) not in sys.path:
    #             sys.path.append(str(mcp_path))
    #         from auto_organizer import AutoOrganizer
    #         # åˆ›å»ºæ•´ç†å™¨å®ä¾‹ï¼ˆåŸºäºé¡¹ç›®æ ¹ç›®å½•ï¼‰
    #         base_dir = Path(__file__).parent.parent.parent
    #         organizer = AutoOrganizer(str(base_dir))
    #         # æ‰§è¡Œè‡ªåŠ¨æ•´ç†
    #         result = organizer.auto_organize_after_tool('srt_to_product', str(self.output_dir))
    #         if result['success']:
    #             self.logger.info(f"âœ… è‡ªåŠ¨æ•´ç†å®Œæˆ: æ•´ç†äº†{result['organized_files']}ä¸ªæ–‡ä»¶")
    #             for file_info in organizer.organized_files:
    #                 self.logger.info(f"  ğŸ“ {file_info}")
    #         else:
    #             self.logger.warning(f"âš ï¸ è‡ªåŠ¨æ•´ç†å­˜åœ¨é—®é¢˜: {result['errors']}ä¸ªé”™è¯¯")
    #             for error in organizer.errors:
    #                 self.logger.warning(f"  âŒ {error}")
    #     except ImportError as e:
    #         self.logger.warning(f"âš ï¸ æ— æ³•å¯¼å…¥auto_organizerï¼Œè·³è¿‡è‡ªåŠ¨æ•´ç†: {e}")
    #     except Exception as e:
    #         self.logger.error(f"âŒ è‡ªåŠ¨æ•´ç†å¤±è´¥: {e}") 