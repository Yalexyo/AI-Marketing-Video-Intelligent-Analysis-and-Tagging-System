#!/usr/bin/env python3
"""
ğŸš€ å¿«é€Ÿè¿è¡Œè„šæœ¬ - ä¸»æ ‡ç­¾å¤„ç†å™¨
æä¾›ç®€åŒ–çš„æ¥å£å¿«é€Ÿæ‰§è¡Œä¸»æ ‡ç­¾åˆ†ç±»ä»»åŠ¡å’ŒåŠ¨æ€èšç±»
æ–°å¢: ğŸš€ å¢å¼ºèšç±»ç®¡ç†å™¨ - ç«¯åˆ°ç«¯å¤„ç†æ¶æ„ä¼˜åŒ–
"""

import sys
import os
from pathlib import Path
from typing import Optional, Dict, Any

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

# å¯¼å…¥ç»Ÿä¸€å¤„ç†å™¨
from src.unified_processing_manager import UnifiedProcessingManager
from src.slice_file_manager import SliceFileManager

def _should_filter_file_for_clustering(json_file: Path, json_data: Dict[str, Any]) -> bool:
    """
    åˆ¤æ–­æ–‡ä»¶æ˜¯å¦éœ€è¦è¿‡æ»¤ï¼ˆç”¨äºèšç±»åˆ†æï¼‰
    
    Args:
        json_file: JSONæ–‡ä»¶è·¯å¾„
        json_data: JSONæ•°æ®å†…å®¹
        
    Returns:
        bool: æ˜¯å¦éœ€è¦è¿‡æ»¤
    """
    # ğŸ¯ ç”¨æˆ·åé¦ˆï¼šå¤šé•œå¤´è§†é¢‘ä¹Ÿåº”è¯¥è¢«åˆ†æï¼Œåªè¿‡æ»¤çœŸæ­£å¤±è´¥çš„æ–‡ä»¶
    # åªè¿‡æ»¤âŒå‰ç¼€çš„æ–‡ä»¶ï¼ˆåˆ†æå¤±è´¥ï¼‰ï¼Œâ™»ï¸æ–‡ä»¶å…è®¸æ­£å¸¸åˆ†æ
    if json_file.stem.startswith("âŒ"):
        return True
    
    # æ£€æŸ¥quality_statusæ˜¯å¦ä¸ºfailed
    if json_data.get("quality_status") == "failed":
        return True
    
    # æ£€æŸ¥successå­—æ®µæ˜¯å¦ä¸ºfalse
    if json_data.get("success") == False:
        return True
    
    # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åŒ…å«âŒæ ‡è®°ï¼ˆâ™»ï¸æ ‡è®°å…è®¸é€šè¿‡ï¼‰
    file_path = json_data.get("file_path", "")
    if isinstance(file_path, str) and "âŒ" in file_path:
        return True
    
    return False

def run_ai_clustering_analysis_only():
    """ğŸ¤– åŒå±‚AIæ™ºèƒ½èšç±» - ä»…åˆ†ææ¨¡å¼ï¼ˆä¸å¤åˆ¶æ–‡ä»¶ï¼‰"""
    print("ğŸ¤– å¯åŠ¨åŒå±‚AIæ™ºèƒ½èšç±»åˆ†æå™¨ - ä»…åˆ†ææ¨¡å¼...")
    print("ğŸ§  åŒå±‚AIæ¶æ„ï¼šä¸»æ ‡ç­¾AI + å­ç±»åˆ«AI")
    print("ğŸ“Š åªå¢å¼ºJSONæ–‡ä»¶ï¼Œä¸å¤åˆ¶æ–‡ä»¶")
    try:
        from src.secondary_ai_classifier import SecondaryAIClassifier
        from src.slice_file_manager import SliceFileManager  # ğŸ”§ å¯¼å…¥SliceFileManager
        
        classifier = SecondaryAIClassifier()
        file_manager = SliceFileManager()  # ğŸ”§ åˆ›å»ºæ–‡ä»¶ç®¡ç†å™¨å®ä¾‹
        
        # ä»ğŸ¬Sliceç›®å½•åŠ è½½å·²åˆ†ç±»çš„æ•°æ®
        slice_files = []
        slice_dir = Path("../ğŸ¬Slice")
        
        for video_dir in slice_dir.iterdir():
            if video_dir.is_dir() and video_dir.name not in [".", "..", "ğŸ¬Slice"] and not video_dir.name.startswith("."):
                # æ”¯æŒçµæ´»çš„æ–‡ä»¶å¤¹ç»“æ„ï¼šæ—¢æ”¯æŒsliceså­ç›®å½•ï¼Œä¹Ÿæ”¯æŒç›´æ¥åœ¨ç›®å½•ä¸‹
                json_files_found = []
                
                # æ–¹æ³•1: æ£€æŸ¥sliceså­ç›®å½•
                slices_dir = video_dir / "slices"
                if slices_dir.exists():
                    json_files_found.extend(list(slices_dir.glob("*_analysis.json")))
                
                # æ–¹æ³•2: æ£€æŸ¥ç›´æ¥åœ¨ç›®å½•ä¸‹
                if not json_files_found:
                    json_files_found.extend(list(video_dir.glob("*_analysis.json")))
                
                slice_files.extend(json_files_found)
        
        if not slice_files:
            print("âŒ æœªæ‰¾åˆ°å·²åˆ†æçš„JSONæ–‡ä»¶")
            return None
        
        print(f"ğŸ“‹ å‘ç° {len(slice_files)} ä¸ªå·²åˆ†æçš„JSONæ–‡ä»¶")
        
        # æŒ‰ä¸»æ ‡ç­¾åˆ†ç»„å¤„ç†
        import json
        main_tag_groups = {}
        filtered_count = 0  # ğŸ†• æ–°å¢ï¼šè¿‡æ»¤æ–‡ä»¶è®¡æ•°
        
        for json_file in slice_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ğŸš¨ æ–°å¢ï¼šè´¨é‡è¿‡æ»¤é€»è¾‘
                if _should_filter_file_for_clustering(json_file, data):
                    filtered_count += 1
                    print(f"ğŸš« è¿‡æ»¤æ–‡ä»¶: {json_file.name} (è´¨é‡é—®é¢˜)")
                    continue
                
                main_tag = data.get("main_tag", "")
                if main_tag and "å…¶ä»–" not in main_tag:
                    if main_tag not in main_tag_groups:
                        main_tag_groups[main_tag] = []
                    
                    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ™ºèƒ½è·¯å¾„è§£ææ–¹æ³•
                    resolved_file_path = file_manager._resolve_valid_video_file_path(json_file, data)
                    
                    # æ„å»ºslice_dataæ ¼å¼
                    slice_data = {
                        "slice_name": json_file.stem.replace("_analysis", ""),
                        "labels": f"object: {data.get('object', '')}, scene: {data.get('scene', '')}, emotion: {data.get('emotion', '')}, brand_elements: {data.get('brand_elements', '')}",
                        "file_path": resolved_file_path,
                        "analysis_file": str(json_file),
                        "confidence": data.get("confidence", 0.0)
                    }
                    main_tag_groups[main_tag].append(slice_data)
            except Exception as e:
                print(f"âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {json_file}: {e}")
                continue
        
        if filtered_count > 0:
            print(f"ğŸš« å·²è¿‡æ»¤ {filtered_count} ä¸ªè´¨é‡é—®é¢˜æ–‡ä»¶")
        
        # å¯¹æ¯ä¸ªä¸»æ ‡ç­¾ç»„è¿›è¡ŒäºŒçº§AIåˆ†æ
        total_processed = 0
        total_enhanced = 0
        
        for main_tag, slice_list in main_tag_groups.items():
            print(f"\nğŸ¯ å¤„ç†ä¸»æ ‡ç­¾: {main_tag} ({len(slice_list)} ä¸ªæ–‡ä»¶)")
            
            # æ‰§è¡ŒäºŒçº§AIåˆ†ç±»
            enriched_results = classifier.batch_classify_secondary(
                slice_list, main_tag, min_confidence=0.5
            )
            
            # å°†ç»“æœå†™å›åŸJSONæ–‡ä»¶
            for enriched_slice in enriched_results:
                analysis_file = enriched_slice.get("analysis_file")
                if analysis_file and Path(analysis_file).exists():
                    try:
                        # è¯»å–åŸJSON
                        with open(analysis_file, 'r', encoding='utf-8') as f:
                            original_data = json.load(f)
                        
                        # æ·»åŠ äºŒçº§åˆ†æå­—æ®µ
                        if "secondary_category" in enriched_slice:
                            original_data.update({
                                "secondary_category": enriched_slice["secondary_category"],
                                "secondary_confidence": enriched_slice["secondary_confidence"],
                                "secondary_reasoning": enriched_slice.get("secondary_reasoning", ""),
                                "secondary_features": enriched_slice.get("secondary_features", []),
                                "secondary_processed_at": enriched_slice.get("secondary_processed_at", "")
                            })
                            
                            # å†™å›æ–‡ä»¶
                            with open(analysis_file, 'w', encoding='utf-8') as f:
                                json.dump(original_data, f, ensure_ascii=False, indent=2)
                            
                            total_enhanced += 1
                        
                        total_processed += 1
                        
                    except Exception as e:
                        print(f"âš ï¸ æ›´æ–°æ–‡ä»¶å¤±è´¥ {analysis_file}: {e}")
        
        print(f"\nâœ… äºŒçº§AIåˆ†æå®Œæˆ!")
        print(f"ğŸ“Š å¤„ç† {total_processed} ä¸ªæ–‡ä»¶ï¼ŒæˆåŠŸå¢å¼º {total_enhanced} ä¸ªJSONæ–‡ä»¶")
        print(f"ğŸ¯ å·²æ·»åŠ  secondary_category, secondary_confidence ç­‰å­—æ®µ")
        
        return {
            "total_processed": total_processed,
            "total_enhanced": total_enhanced,
            "main_tag_groups": list(main_tag_groups.keys())
        }
        
    except Exception as e:
        print(f"âŒ äºŒçº§AIåˆ†æå¤±è´¥: {e}")
        return None

def run_overview():
    """è¿è¡Œå¤„ç†æ¦‚è§ˆ - ä½¿ç”¨ç»Ÿä¸€ç®¡ç†å™¨"""
    print("ğŸ“Š è·å–å¤„ç†æ¦‚è§ˆ...")
    try:
        # ä½¿ç”¨æ–‡ä»¶ç®¡ç†å™¨è·å–æ¦‚è§ˆä¿¡æ¯
        file_manager = SliceFileManager()
        classified_data, unclassified_data = file_manager.collect_all_slice_data()
        
        # è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        stats = file_manager.get_processing_statistics()
        total_stats = stats.get("TOTAL", {})
        
        overview = {
            "total_videos": total_stats.get("total_videos", 0),
            "total_files": total_stats.get("total_files", 0),
            "classified_files": len(classified_data),
            "unclassified_files": len(unclassified_data),
            "processing_complete": True
        }
        
        print(f"ğŸ“Š æ¦‚è§ˆç»Ÿè®¡:")
        print(f"   ğŸ¬ æ€»è§†é¢‘æ•°: {overview['total_videos']}")
        print(f"   ğŸ“‹ æ€»æ–‡ä»¶æ•°: {overview['total_files']}")
        print(f"   ğŸ¯ å·²åˆ†ç±»: {overview['classified_files']}")
        print(f"   ğŸ§« æœªåˆ†ç±»: {overview['unclassified_files']}")
        
        return overview
    except Exception as e:
        print(f"âŒ è·å–æ¦‚è§ˆå¤±è´¥: {e}")
        return None

def run_single_video(video_name: str, force_reprocess: bool = False, no_backup: bool = False):
    """å¤„ç†å•ä¸ªè§†é¢‘ - ä½¿ç”¨ç»Ÿä¸€ç®¡ç†å™¨"""
    print(f"ğŸ¬ å¤„ç†è§†é¢‘: {video_name}")
    print("âš ï¸ å»ºè®®ä½¿ç”¨ç»Ÿä¸€æ™ºèƒ½åˆ†ç±»æ¨¡å¼ (run.py enhanced-cluster)")
    try:
        # ä½¿ç”¨ç»Ÿä¸€å¤„ç†ç®¡ç†å™¨è¿›è¡Œå•è§†é¢‘å¤„ç†
        manager = UnifiedProcessingManager()
        
        # æ„å»ºè¾“å‡ºç›®å½•
        from pathlib import Path
        from datetime import datetime
        output_dir = Path("../ğŸ“ç”Ÿæˆç»“æœ") / f"å•è§†é¢‘å¤„ç†_{video_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # æ‰§è¡Œç»Ÿä¸€æ™ºèƒ½åˆ†ç±»
        result = manager.perform_unified_classification_and_clustering(
            force_reprocess=force_reprocess,
            output_base_dir=output_dir
        )
        
        if result:
            print(f"âœ… è§†é¢‘ {video_name} å¤„ç†å®Œæˆ")
            print(f"ğŸ“ ç”Ÿæˆ {len(result.main_modules)} ä¸ªä¸»æ¨¡å—")
            print(f"ğŸ“Š AIåˆ†æç»Ÿè®¡: {result.ai_analysis_stats}")
            return {"success": True, "video_name": video_name, "result": result}
        else:
            return {"success": False, "video_name": video_name}
            
    except Exception as e:
        print(f"âŒ å¤„ç†è§†é¢‘å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}

def run_all_videos(force_reprocess: bool = False, no_backup: bool = False):
    """å¤„ç†æ‰€æœ‰è§†é¢‘ - ä½¿ç”¨ç»Ÿä¸€ç®¡ç†å™¨"""
    print("ğŸ¬ æ‰¹é‡å¤„ç†æ‰€æœ‰è§†é¢‘...")
    print("âš ï¸ å»ºè®®ä½¿ç”¨ç»Ÿä¸€æ™ºèƒ½åˆ†ç±»æ¨¡å¼ (run.py enhanced-cluster)")
    try:
        # ä½¿ç”¨ç»Ÿä¸€å¤„ç†ç®¡ç†å™¨
        manager = UnifiedProcessingManager()
        
        # æ‰§è¡Œç»Ÿä¸€æ™ºèƒ½åˆ†ç±»
        result = manager.perform_unified_classification_and_clustering(
            force_reprocess=force_reprocess
        )
        
        if result:
            print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ")
            print(f"ğŸ“ ç”Ÿæˆ {len(result.main_modules)} ä¸ªä¸»æ¨¡å—")
            print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡: {result.processing_stats}")
            print(f"ğŸ¤– AIåˆ†æç»Ÿè®¡: {result.ai_analysis_stats}")
            return {"success": True, "result": result}
        else:
            return {"success": False}
            
    except Exception as e:
        print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}

def run_clustering(output_base_dir: Optional[str] = None):
    """æ‰§è¡ŒåŠ¨æ€èšç±» - ä½¿ç”¨å¢å¼ºèšç±»ç®¡ç†å™¨"""
    print("ğŸ¯ æ‰§è¡ŒåŠ¨æ€èšç±»...")
    try:
        # ç›´æ¥ä½¿ç”¨ç»Ÿä¸€æ™ºèƒ½åˆ†ç±»ç®¡ç†å™¨
        return run_intelligent_classification(output_base_dir)
    except Exception as e:
        print(f"âŒ èšç±»å¤±è´¥: {e}")
        return None

def run_intelligent_classification(output_base_dir: Optional[str] = None, force_reprocess: bool = False):
    """ğŸ¯ ç»Ÿä¸€æ™ºèƒ½åˆ†ç±»æ¨¡å¼ - å†…å­˜æµå¼å¤„ç†ï¼ˆæ¶æ„ä¼˜åŒ–ç‰ˆv4.0ï¼‰"""
    print("ğŸ¯ å¯åŠ¨ç»Ÿä¸€æ™ºèƒ½åˆ†ç±»ç®¡ç†å™¨v4.0ï¼ˆæ¶æ„ä¼˜åŒ–ç‰ˆï¼‰...")
    print("ğŸ§  åŒå±‚AIæ¶æ„ï¼šä¸»æ ‡ç­¾AI + å­ç±»åˆ«AI")
    print("âš¡ æ¶æ„ä¼˜åŒ–ï¼šå†…å­˜æµå¼å¤„ç†ï¼Œå‡å°‘æ–‡ä»¶è¯»å†™")
    try:
        from src.unified_processing_manager import UnifiedProcessingManager
        manager = UnifiedProcessingManager()
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        if output_base_dir:
            output_dir = Path(output_base_dir)
        else:
            output_dir = None
        
        # æ‰§è¡Œç»Ÿä¸€æ™ºèƒ½åˆ†ç±»å’Œèšç±»ï¼ˆå†…å­˜æµå¼å¤„ç†ï¼‰
        result = manager.perform_unified_classification_and_clustering(
            force_reprocess=force_reprocess,
            output_base_dir=output_dir
        )
        
        print("âœ… ç»Ÿä¸€æ™ºèƒ½åˆ†ç±»å®Œæˆ!")
        print(f"ğŸ“ ç”Ÿæˆ {len(result.main_modules)} ä¸ªä¸»æ¨¡å—")
        print(f"ğŸ¯ å¤„ç† {sum(len(clusters) for clusters in result.main_modules.values())} ä¸ªèšç±»")
        print(f"ğŸ“Š æ€»è®¡ {sum(c.slice_count for clusters in result.main_modules.values() for c in clusters)} ä¸ªåˆ‡ç‰‡")
        print(f"ğŸ¤– AIåˆ†æç»Ÿè®¡: {result.ai_analysis_stats}")
        print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡: {result.processing_stats}")
        
        # æ˜¾ç¤ºè¯¦ç»†çš„AIåˆ†æç»“æœ
        for main_tag, clusters in result.main_modules.items():
            print(f"   ğŸ¯ {main_tag}: {len(clusters)} ä¸ªAIæ™ºèƒ½å­ç±»åˆ«")
            for cluster in clusters:
                if hasattr(cluster, 'avg_secondary_confidence'):
                    print(f"      â””â”€ {cluster.cluster_name}: {cluster.slice_count} ä¸ªåˆ‡ç‰‡ (AIç½®ä¿¡åº¦: {cluster.avg_secondary_confidence:.2f})")
                else:
                    print(f"      â””â”€ {cluster.cluster_name}: {cluster.slice_count} ä¸ªåˆ‡ç‰‡")
        
        return result
    except Exception as e:
        print(f"âŒ ç»Ÿä¸€æ™ºèƒ½åˆ†ç±»å¤±è´¥: {e}")
        return None

def run_process_and_cluster(force_reprocess: bool = False, no_backup: bool = False, 
                           enable_clustering: bool = True, output_base_dir: Optional[str] = None):
    """ä¸€é”®å¤„ç†ï¼šåˆ†ç±» + èšç±»"""
    print("ğŸš€ ä¸€é”®å¤„ç†ï¼šä¸»æ ‡ç­¾åˆ†ç±» + åŠ¨æ€èšç±»...")
    try:
        # ç¬¬ä¸€æ­¥ï¼šä¸»æ ‡ç­¾åˆ†ç±»
        print("ğŸ“ ç¬¬ä¸€æ­¥ï¼šæ‰§è¡Œä¸»æ ‡ç­¾åˆ†ç±»...")
        classification_result = run_all_videos(force_reprocess, no_backup)
        
        if not classification_result or not classification_result.get("success"):
            print("âŒ åˆ†ç±»æ­¥éª¤å¤±è´¥")
            return None
        
        print(f"âœ… åˆ†ç±»å®Œæˆ: {classification_result['total_stats']}")
        
        # ç¬¬äºŒæ­¥ï¼šèšç±»ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        clustering_result = None
        if enable_clustering:
            print("ğŸš€ ç¬¬äºŒæ­¥ï¼šæ‰§è¡ŒåŠ¨æ€èšç±»...")
            clustering_result = run_clustering(output_base_dir)
        
        return {
            "classification": classification_result,
            "clustering": clustering_result
        }
    except Exception as e:
        print(f"âŒ ä¸€é”®å¤„ç†å¤±è´¥: {e}")
        return None

def run_enhanced_process_and_cluster(force_reprocess: bool = False, no_backup: bool = False, 
                                   output_base_dir: Optional[str] = None):
    """ğŸš€ å¢å¼ºä¸€é”®å¤„ç†ï¼šåˆ†ç±» + å¢å¼ºç«¯åˆ°ç«¯èšç±»ï¼ˆæ¶æ„ä¼˜åŒ–ç‰ˆï¼‰"""
    print("ğŸš€ å¢å¼ºä¸€é”®å¤„ç†ï¼šä¸»æ ‡ç­¾åˆ†ç±» + å¢å¼ºç«¯åˆ°ç«¯èšç±»...")
    try:
        # ç¬¬ä¸€æ­¥ï¼šåˆ†ç±»å¤„ç†
        print("ğŸ“ ç¬¬ä¸€æ­¥ï¼šæ‰§è¡Œä¸»æ ‡ç­¾åˆ†ç±»...")
        classification_result = run_all_videos(force_reprocess, no_backup)
        
        if not classification_result or not classification_result.get("success"):
            print("âŒ åˆ†ç±»æ­¥éª¤å¤±è´¥")
            return None
        
        print(f"âœ… åˆ†ç±»å®Œæˆ: {classification_result['total_stats']}")
        
        # ç¬¬äºŒæ­¥ï¼šæ™ºèƒ½èšç±»
        print("ğŸš€ ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œç»Ÿä¸€æ™ºèƒ½åˆ†ç±»...")
        clustering_result = run_intelligent_classification(output_base_dir, force_reprocess)
        
        if not clustering_result:
            print("âŒ èšç±»æ­¥éª¤å¤±è´¥")
            return None
        
        print("ğŸ‰ å¢å¼ºä¸€é”®å¤„ç†å®Œæˆ!")
        return {
            "classification": classification_result,
            "clustering": clustering_result
        }
        
    except Exception as e:
        print(f"âŒ å¢å¼ºä¸€é”®å¤„ç†å¤±è´¥: {e}")
        return None

def interactive_mode():
    """äº¤äº’æ¨¡å¼"""
    print("ğŸ¯ ä¸»æ ‡ç­¾å¤„ç†å™¨ - äº¤äº’æ¨¡å¼")
    print("=" * 50)
    
    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. ğŸ“Š æŸ¥çœ‹å¤„ç†æ¦‚è§ˆ")
        print("2. ğŸ¬ å¤„ç†å•ä¸ªè§†é¢‘")
        print("3. ğŸ¬ å¤„ç†æ‰€æœ‰è§†é¢‘")
        print("4. ğŸ”„ å¼ºåˆ¶é‡æ–°å¤„ç†å•ä¸ªè§†é¢‘")
        print("5. ğŸ”„ å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰è§†é¢‘")
        print("6. ğŸ¯ æ‰§è¡ŒåŠ¨æ€èšç±»")
        print("7. ğŸš€ ä¸€é”®å¤„ç†ï¼ˆåˆ†ç±»+èšç±»ï¼‰")
        print("8. ğŸ”„ å¼ºåˆ¶ä¸€é”®å¤„ç†ï¼ˆåˆ†ç±»+èšç±»ï¼‰")
        print("9. ğŸ¯ æ‰§è¡Œç»Ÿä¸€æ™ºèƒ½åˆ†ç±»ï¼ˆæ¶æ„ä¼˜åŒ–ç‰ˆï¼‰")
        print("10. ğŸš€ å¢å¼ºä¸€é”®å¤„ç†ï¼ˆåˆ†ç±»+æ™ºèƒ½èšç±»ï¼‰")
        print("11. ğŸ“Š ä»…åˆ†ææ¨¡å¼ï¼ˆå¢å¼ºJSONï¼Œä¸å¤åˆ¶æ–‡ä»¶ï¼‰")
        print("0. ğŸšª é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (0-11): ").strip()
        
        if choice == "0":
            print("ğŸ‘‹ å†è§!")
            break
        elif choice == "1":
            run_overview()
        elif choice == "2":
            video_name = input("è¯·è¾“å…¥è§†é¢‘åç§° (å¦‚: è¿™æ˜¯æ¥ æ¥ çº¯å‡€ç‰ˆ): ").strip()
            if video_name:
                run_single_video(video_name)
            else:
                print("âŒ è§†é¢‘åç§°ä¸èƒ½ä¸ºç©º")
        elif choice == "3":
            run_all_videos()
        elif choice == "4":
            video_name = input("è¯·è¾“å…¥è§†é¢‘åç§° (å¦‚: è¿™æ˜¯æ¥ æ¥ çº¯å‡€ç‰ˆ): ").strip()
            if video_name:
                run_single_video(video_name, force_reprocess=True)
            else:
                print("âŒ è§†é¢‘åç§°ä¸èƒ½ä¸ºç©º")
        elif choice == "5":
            confirm = input("âš ï¸ ç¡®è®¤å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰è§†é¢‘? (y/N): ").strip().lower()
            if confirm == "y":
                run_all_videos(force_reprocess=True)
            else:
                print("âŒ æ“ä½œå·²å–æ¶ˆ")
        elif choice == "6":
            output_dir = input("è¯·è¾“å…¥è¾“å‡ºç›®å½• (ç•™ç©ºä½¿ç”¨é»˜è®¤): ").strip()
            run_clustering(output_dir if output_dir else None)
        elif choice == "7":
            output_dir = input("è¯·è¾“å…¥è¾“å‡ºç›®å½• (ç•™ç©ºä½¿ç”¨é»˜è®¤): ").strip()
            run_process_and_cluster(output_base_dir=output_dir if output_dir else None)
        elif choice == "8":
            confirm = input("âš ï¸ ç¡®è®¤å¼ºåˆ¶é‡æ–°å¤„ç†å¹¶èšç±»? (y/N): ").strip().lower()
            if confirm == "y":
                output_dir = input("è¯·è¾“å…¥è¾“å‡ºç›®å½• (ç•™ç©ºä½¿ç”¨é»˜è®¤): ").strip()
                run_process_and_cluster(
                    force_reprocess=True,
                    output_base_dir=output_dir if output_dir else None
                )
            else:
                print("âŒ æ“ä½œå·²å–æ¶ˆ")
        elif choice == "9":
            output_dir = input("è¯·è¾“å…¥è¾“å‡ºç›®å½• (ç•™ç©ºä½¿ç”¨é»˜è®¤): ").strip()
            force = input("æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†? (y/N): ").strip().lower() == "y"
            run_intelligent_classification(output_dir if output_dir else None, force)
        elif choice == "10":
            confirm = input("ğŸš€ ç¡®è®¤æ‰§è¡Œå¢å¼ºä¸€é”®å¤„ç†? (Y/n): ").strip().lower()
            if confirm != "n":
                output_dir = input("è¯·è¾“å…¥è¾“å‡ºç›®å½• (ç•™ç©ºä½¿ç”¨é»˜è®¤): ").strip()
                force = input("æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†? (y/N): ").strip().lower() == "y"
                run_enhanced_process_and_cluster(
                    force_reprocess=force,
                    output_base_dir=output_dir if output_dir else None
                )
            else:
                print("âŒ æ“ä½œå·²å–æ¶ˆ")
        elif choice == "11":
            run_ai_clustering_analysis_only()
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ä¸»æ ‡ç­¾å¤„ç†å™¨ + åŠ¨æ€èšç±»")
    print("=" * 50)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not Path("../ğŸ¬Slice").exists():
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° ğŸ¬Slice ç›®å½•")
        print("è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„é¡¹ç›®ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
        return
    
    # å¦‚æœæœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œç›´æ¥æ‰§è¡Œ
    if len(sys.argv) > 1:
        action = sys.argv[1].lower()
        
        # è§£æå‚æ•°
        force = False
        no_backup = False
        no_clustering = False
        output_dir = None
        
        for arg in sys.argv[2:]:
            if arg.lower() == "force":
                force = True
            elif arg.lower() == "no-backup":
                no_backup = True
            elif arg.lower() == "no-clustering":
                no_clustering = True
            elif arg.startswith("output="):
                output_dir = arg.split("=", 1)[1]
        
        if action == "overview":
            run_overview()
        elif action == "all":
            run_all_videos(force_reprocess=force, no_backup=no_backup)
        elif action == "cluster":
            run_clustering(output_dir)
        elif action == "enhanced-cluster" or action == "intelligent-classification":
            run_intelligent_classification(output_dir, force)
        elif action == "ai-cluster" or action == "ai-clustering":
            # ğŸ¯ ç»Ÿä¸€æ™ºèƒ½åˆ†ç±»æ¨¡å¼ - å†…å­˜æµå¼å¤„ç†ï¼ˆæ¶æ„ä¼˜åŒ–ç‰ˆv4.0ï¼‰
            print("ğŸ¯ å¯åŠ¨ç»Ÿä¸€æ™ºèƒ½åˆ†ç±»ç®¡ç†å™¨v4.0ï¼ˆæ¶æ„ä¼˜åŒ–ç‰ˆï¼‰...")
            print("ğŸ§  åŒå±‚AIæ¶æ„ï¼šä¸»æ ‡ç­¾AI + å­ç±»åˆ«AI")
            run_intelligent_classification(output_dir, force)
        elif action == "ai-cluster-analysis-only":
            # ğŸ¤– åŒå±‚AIæ™ºèƒ½èšç±» - ä»…åˆ†ææ¨¡å¼ï¼ˆä¸å¤åˆ¶æ–‡ä»¶ï¼‰
            run_ai_clustering_analysis_only()
        elif action == "all-cluster":
            run_process_and_cluster(
                force_reprocess=force, 
                no_backup=no_backup,
                enable_clustering=not no_clustering,
                output_base_dir=output_dir
            )
        elif action == "enhanced-all-cluster":
            run_enhanced_process_and_cluster(
                force_reprocess=force,
                no_backup=no_backup,
                output_base_dir=output_dir
            )
        else:
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„è§†é¢‘ç›®å½•å
            slice_dir = Path("../ğŸ¬Slice")
            potential_video_dir = slice_dir / action
            
            if potential_video_dir.exists() and potential_video_dir.is_dir() and (potential_video_dir / "slices").exists():
                # è¿™æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„è§†é¢‘ç›®å½•
                video_name = action
                run_single_video(video_name, force_reprocess=force, no_backup=no_backup)
            else:
                print("âŒ æ— æ•ˆå‚æ•°")
                print("ç”¨æ³•:")
                print("  python run.py overview                         # æŸ¥çœ‹æ¦‚è§ˆ")
                print("  python run.py all [force] [no-backup]          # å¤„ç†æ‰€æœ‰è§†é¢‘")
                print("  python run.py cluster [output=è·¯å¾„]             # æ‰§è¡Œèšç±»")
                print("  python run.py enhanced-cluster [output=è·¯å¾„]    # ğŸ¯ ç»Ÿä¸€æ™ºèƒ½åˆ†ç±»ï¼ˆæ¶æ„ä¼˜åŒ–ï¼‰")
                print("  python run.py ai-cluster [output=è·¯å¾„]          # ğŸ¯ ç»Ÿä¸€æ™ºèƒ½åˆ†ç±»ï¼ˆåŒä¸Šï¼‰")
                print("  python run.py ai-cluster-analysis-only        # ğŸ¤– åŒå±‚AIä»…åˆ†ææ¨¡å¼ï¼ˆä¸å¤åˆ¶æ–‡ä»¶ï¼‰")
                print("  python run.py all-cluster [force] [no-backup] [no-clustering] [output=è·¯å¾„]  # ä¸€é”®å¤„ç†")
                print("  python run.py enhanced-all-cluster [force] [no-backup] [output=è·¯å¾„]        # ğŸš€ å¢å¼ºä¸€é”®å¤„ç†")
                print("  python run.py <è§†é¢‘ç›®å½•å> [force] [no-backup]      # å¤„ç†å•ä¸ªè§†é¢‘")
                print("")
                print("ğŸ¯ æ¶æ„ä¼˜åŒ–åŠŸèƒ½:")
                print("  enhanced-cluster:       ç»Ÿä¸€æ™ºèƒ½åˆ†ç±»ï¼Œæ•´åˆæ–‡ä»¶å¤„ç†")
                print("  enhanced-all-cluster:   åˆ†ç±» + æ™ºèƒ½èšç±»ä¸€é”®å®Œæˆ")
                print("  ai-cluster:             ğŸ¯ ç»Ÿä¸€æ™ºèƒ½åˆ†ç±»ï¼Œä¸»æ ‡ç­¾AI + å­ç±»åˆ«AI")
                print("  ğŸ“ åŠ¨æ€èšç±»: åŸºäºä¸»æ ‡ç­¾åˆ†ç±»ç»“æœç”Ÿæˆ4å¤§æ¨¡å—æ–‡ä»¶å¤¹")
                print("  ğŸ¼ äº§å“ä»‹ç»: æ•´åˆè¥å…»ç§‘å­¦ï¼Œæ–°å¢A2æ ‡ç­¾è¯†åˆ«")
                print("  ğŸ¯ æ¶æ„ç®€åŒ–: å‡å°‘æ–‡ä»¶æ•°é‡ï¼Œç›´æ¥ç«¯åˆ°ç«¯å¤„ç†")
                print("  ğŸ¤– AIæ™ºèƒ½åŒ–: å®Œå…¨æ‘†è„±ç¡¬ç¼–ç å…³é”®è¯åŒ¹é…ï¼Œå…¨AIé©±åŠ¨")
    else:
        # è¿›å…¥äº¤äº’æ¨¡å¼
        interactive_mode()

if __name__ == "__main__":
    main() 