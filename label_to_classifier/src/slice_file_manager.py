#!/usr/bin/env python3
"""
üìÅ Áªü‰∏ÄÂàáÁâáÊñá‰ª∂ÁÆ°ÁêÜÂô® - Unified Slice File Manager
ÂêàÂπ∂json_processorÂíåenhanced_clustering_manager‰∏≠ÈáçÂ§çÁöÑÊñá‰ª∂Êìç‰ΩúÂäüËÉΩ
Êèê‰æõÁªü‰∏ÄÁöÑÊñá‰ª∂ËÆøÈóÆÊé•Âè£ÔºåÂáèÂ∞ë‰ª£Á†ÅÈáçÂ§ç

ËÆæËÆ°ÂéüÂàô:
- DRY: Don't Repeat Yourself - Ê∂àÈô§ÈáçÂ§ç‰ª£Á†Å
- Âçï‰∏ÄËÅåË¥£Ôºö‰∏ìÈó®Ë¥üË¥£Êñá‰ª∂Êìç‰Ωú
- Êé•Âè£Áªü‰∏ÄÔºö‰∏∫ÊâÄÊúâÊñá‰ª∂Êìç‰ΩúÊèê‰æõ‰∏ÄËá¥ÁöÑÊé•Âè£
"""

import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime

logger = logging.getLogger(__name__)

class SliceFileManager:
    """Áªü‰∏ÄÂàáÁâáÊñá‰ª∂ÁÆ°ÁêÜÂô® - Êèê‰æõ‰∏ÄÁ´ôÂºèÊñá‰ª∂Êìç‰ΩúÊúçÂä°"""
    
    def __init__(self, slice_base_dir: str = "../üé¨Slice"):
        """
        ÂàùÂßãÂåñÊñá‰ª∂ÁÆ°ÁêÜÂô®
        
        Args:
            slice_base_dir: ÂàáÁâáÂü∫Á°ÄÁõÆÂΩïË∑ØÂæÑ
        """
        self.slice_base_dir = Path(slice_base_dir)
        if not self.slice_base_dir.exists():
            raise ValueError(f"ÂàáÁâáÁõÆÂΩï‰∏çÂ≠òÂú®: {self.slice_base_dir}")
        
        self.logger = logging.getLogger(f"{self.__class__.__name__}")
        self.logger.info(f"‚úÖ Áªü‰∏ÄÂàáÁâáÊñá‰ª∂ÁÆ°ÁêÜÂô®ÂàùÂßãÂåñÂÆåÊàêÔºåÁõÆÂΩï: {self.slice_base_dir}")
    
    # ==================== ÁõÆÂΩïÊìç‰Ωú ====================
    
    def get_all_video_directories(self) -> List[str]:
        """
        Ëé∑ÂèñÊâÄÊúâËßÜÈ¢ëÁõÆÂΩïÂêçÁß∞ - ÊîØÊåÅÁÅµÊ¥ªÁöÑÊñá‰ª∂Â§πÁªìÊûÑ
        
        Returns:
            List[str]: ËßÜÈ¢ëÁõÆÂΩïÂêçÁß∞ÂàóË°®ÔºåÂ∑≤ÊéíÂ∫è
        """
        video_dirs = []
        
        for item in self.slice_base_dir.iterdir():
            # Ê£ÄÊü•ÊòØÂê¶‰∏∫ÁõÆÂΩïÔºàÊéíÈô§.DS_StoreÁ≠âÁ≥ªÁªüÊñá‰ª∂Ôºâ
            if (item.is_dir() and 
                item.name not in [".", "..", "üé¨Slice"] and 
                not item.name.startswith(".")):
                
                # Ê£ÄÊü•ÊòØÂê¶ÂåÖÂê´ÂàÜÊûêJSONÊñá‰ª∂ÔºàÊîØÊåÅÊúâslicesÂ≠êÁõÆÂΩïÊàñÁõ¥Êé•Âú®ÁõÆÂΩï‰∏ãÔºâ
                has_analysis_files = False
                
                # ÊñπÊ≥ï1: Ê£ÄÊü•slicesÂ≠êÁõÆÂΩï
                slices_dir = item / "slices"
                if slices_dir.exists():
                    if any(slices_dir.glob("*_analysis.json")):
                        has_analysis_files = True
                
                # ÊñπÊ≥ï2: Ê£ÄÊü•Áõ¥Êé•Âú®ÁõÆÂΩï‰∏ã
                if not has_analysis_files:
                    if any(item.glob("*_analysis.json")):
                        has_analysis_files = True
                
                if has_analysis_files:
                    video_dirs.append(item.name)
        
        video_dirs.sort()
        self.logger.info(f"üìÅ ÊâæÂà∞ {len(video_dirs)} ‰∏™ËßÜÈ¢ëÁõÆÂΩï: {video_dirs}")
        return video_dirs
    
    def get_video_slice_directory(self, video_name: str) -> Optional[Path]:
        """
        Ëé∑ÂèñÊåáÂÆöËßÜÈ¢ëÁöÑÂàáÁâáÁõÆÂΩïË∑ØÂæÑ
        
        Args:
            video_name: ËßÜÈ¢ëÂêçÁß∞
            
        Returns:
            Optional[Path]: ÂàáÁâáÁõÆÂΩïË∑ØÂæÑÔºå‰∏çÂ≠òÂú®ÂàôËøîÂõûNone
        """
        slice_dir = self.slice_base_dir / video_name / "slices"
        
        if not slice_dir.exists():
            self.logger.warning(f"‚ö†Ô∏è ËßÜÈ¢ëÂàáÁâáÁõÆÂΩï‰∏çÂ≠òÂú®: {slice_dir}")
            return None
        
        return slice_dir
    
    # ==================== JSONÊñá‰ª∂Êìç‰Ωú ====================
    
    def get_slice_json_files(self, video_name: str) -> List[Path]:
        """
        Ëé∑ÂèñÊåáÂÆöËßÜÈ¢ëÁöÑÊâÄÊúâÂàáÁâáJSONÊñá‰ª∂ - ÊîØÊåÅÁÅµÊ¥ªÁöÑÊñá‰ª∂Â§πÁªìÊûÑ
        
        Args:
            video_name: ËßÜÈ¢ëÂêçÁß∞
            
        Returns:
            List[Path]: JSONÊñá‰ª∂Ë∑ØÂæÑÂàóË°®ÔºåÂ∑≤ÊéíÂ∫è
        """
        video_dir = self.slice_base_dir / video_name
        
        if not video_dir.exists():
            self.logger.warning(f"‚ö†Ô∏è ËßÜÈ¢ëÁõÆÂΩï‰∏çÂ≠òÂú®: {video_dir}")
            return []
        
        json_files = []
        
        # ÊñπÊ≥ï1: Ê£ÄÊü•slicesÂ≠êÁõÆÂΩï
        slices_dir = video_dir / "slices"
        if slices_dir.exists():
            for file in slices_dir.iterdir():
                if file.is_file() and file.name.endswith("_analysis.json"):
                    json_files.append(file)
        
        # ÊñπÊ≥ï2: Ê£ÄÊü•Áõ¥Êé•Âú®ËßÜÈ¢ëÁõÆÂΩï‰∏ã
        if not json_files:  # Â¶ÇÊûúslicesÁõÆÂΩïÊ≤°ÊúâÊâæÂà∞Êñá‰ª∂ÔºåÊ£ÄÊü•Áõ¥Êé•ÁõÆÂΩï
            for file in video_dir.iterdir():
                if file.is_file() and file.name.endswith("_analysis.json"):
                    json_files.append(file)
        
        json_files.sort()
        self.logger.debug(f"üìÑ {video_name} ÊâæÂà∞ {len(json_files)} ‰∏™JSONÊñá‰ª∂")
        return json_files
    
    def get_all_slice_json_files(self) -> List[Path]:
        """
        Ëé∑ÂèñÊâÄÊúâËßÜÈ¢ëÁöÑÂàáÁâáJSONÊñá‰ª∂
        
        Returns:
            List[Path]: ÊâÄÊúâJSONÊñá‰ª∂Ë∑ØÂæÑÂàóË°®
        """
        all_json_files = []
        
        for video_name in self.get_all_video_directories():
            json_files = self.get_slice_json_files(video_name)
            all_json_files.extend(json_files)
        
        self.logger.info(f"üìÑ ÊÄªËÆ°ÊâæÂà∞ {len(all_json_files)} ‰∏™JSONÊñá‰ª∂")
        return all_json_files
    
    def read_json_file(self, json_file_path: Path) -> Optional[Dict[str, Any]]:
        """
        ËØªÂèñJSONÊñá‰ª∂ÂÜÖÂÆπ
        
        Args:
            json_file_path: JSONÊñá‰ª∂Ë∑ØÂæÑ
            
        Returns:
            Optional[Dict[str, Any]]: JSONÊï∞ÊçÆÔºåËØªÂèñÂ§±Ë¥•ËøîÂõûNone
        """
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return data
        except Exception as e:
            self.logger.error(f"‚ùå ËØªÂèñJSONÊñá‰ª∂Â§±Ë¥• {json_file_path}: {e}")
            return None
    
    def write_json_file(self, json_file_path: Path, data: Dict[str, Any]) -> bool:
        """
        ÂÜôÂÖ•JSONÊñá‰ª∂
        
        Args:
            json_file_path: JSONÊñá‰ª∂Ë∑ØÂæÑ
            data: Ë¶ÅÂÜôÂÖ•ÁöÑÊï∞ÊçÆ
            
        Returns:
            bool: ÂÜôÂÖ•ÊòØÂê¶ÊàêÂäü
        """
        try:
            with open(json_file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            self.logger.error(f"‚ùå ÂÜôÂÖ•JSONÊñá‰ª∂Â§±Ë¥• {json_file_path}: {e}")
            return False
    
    # ==================== Êï∞ÊçÆÊèêÂèñ‰∏éÂ§ÑÁêÜ ====================
    
    def extract_labels_for_classification(self, json_data: Dict[str, Any]) -> str:
        """
        ‰ªéJSONÊï∞ÊçÆ‰∏≠ÊèêÂèñÁî®‰∫éÂàÜÁ±ªÁöÑLabelsÂÜÖÂÆπ
        
        Args:
            json_data: JSONÊï∞ÊçÆÂ≠óÂÖ∏
            
        Returns:
            str: Ê†ºÂºèÂåñÁöÑlabelsÊñáÊú¨
        """
        labels_parts = []
        
        # ‰∏ªË¶ÅÂ≠óÊÆµ
        object_field = json_data.get("object", "")
        scene_field = json_data.get("scene", "")
        emotion_field = json_data.get("emotion", "")
        brand_elements = json_data.get("brand_elements", "")
        
        if object_field and object_field != "Êó†":
            labels_parts.append(f"ÂØπË±°: {object_field}")
        
        if scene_field and scene_field != "Êó†":
            labels_parts.append(f"Âú∫ÊôØ: {scene_field}")
        
        if emotion_field and emotion_field != "Êó†":
            labels_parts.append(f"ÊÉÖÁª™: {emotion_field}")
        
        if brand_elements and brand_elements != "Êó†":
            labels_parts.append(f"ÂìÅÁâåÂÖÉÁ¥†: {brand_elements}")
        
        # ÊãºÊé•ÊàêÂÆåÊï¥ÁöÑlabelsÊñáÊú¨
        labels_text = " | ".join(labels_parts)
        
        if not labels_text.strip():
            labels_text = f"ÂØπË±°: {object_field}, Âú∫ÊôØ: {scene_field}, ÊÉÖÁª™: {emotion_field}"
        
        return labels_text
    
    def check_if_already_processed(self, json_data: Dict[str, Any]) -> bool:
        """
        Ê£ÄÊü•JSONÊñá‰ª∂ÊòØÂê¶Â∑≤ÁªèÂ§ÑÁêÜËøáÔºàÂåÖÂê´main_tagÔºâ
        
        Args:
            json_data: JSONÊï∞ÊçÆÂ≠óÂÖ∏
            
        Returns:
            bool: ÊòØÂê¶Â∑≤Â§ÑÁêÜ
        """
        return "main_tag" in json_data and json_data.get("main_tag", "").strip() != ""
    
    def estimate_slice_duration(self, json_file: Path) -> float:
        """
        ‰º∞ÁÆóÂàáÁâáÊó∂Èïø
        
        Args:
            json_file: JSONÊñá‰ª∂Ë∑ØÂæÑ
            
        Returns:
            float: ‰º∞ÁÆóÁöÑÊó∂ÈïøÔºàÁßíÔºâ
        """
        try:
            # ‰ªéÊñá‰ª∂ÂêçÊèêÂèñÊó∂Èïø‰ø°ÊÅØ
            filename = json_file.stem
            
            # Êü•ÊâæÁ±ª‰ºº "_10.5s_" ÁöÑÊ®°Âºè
            import re
            duration_match = re.search(r'_(\d+\.?\d*)s_', filename)
            if duration_match:
                return float(duration_match.group(1))
            
            # ÈªòËÆ§‰º∞ÁÆóÔºöÊ†πÊçÆÊñá‰ª∂Â§ßÂ∞è
            file_size = json_file.stat().st_size
            estimated_duration = max(3.0, min(30.0, file_size / 1000))  # Âü∫‰∫éÊñá‰ª∂Â§ßÂ∞èÁöÑÁÆÄÂçï‰º∞ÁÆó
            
            return estimated_duration
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è ‰º∞ÁÆóÂàáÁâáÊó∂ÈïøÂ§±Ë¥• {json_file}: {e}")
            return 5.0  # ÈªòËÆ§Êó∂Èïø
    
    # ==================== ÊâπÈáèÊï∞ÊçÆÊî∂ÈõÜ ====================
    
    def _resolve_video_file_path(self, json_file: Path, json_data: Dict[str, Any]) -> str:
        """
        Êô∫ËÉΩËß£ÊûêËßÜÈ¢ëÊñá‰ª∂Ë∑ØÂæÑ - Â§ÑÁêÜ‚ôªÔ∏èÂâçÁºÄÂíåË∑ØÂæÑÂåπÈÖçÈóÆÈ¢ò
        
        Args:
            json_file: JSONÊñá‰ª∂Ë∑ØÂæÑ
            json_data: JSONÊï∞ÊçÆÂÜÖÂÆπ
            
        Returns:
            str: ÂÆûÈôÖÁöÑËßÜÈ¢ëÊñá‰ª∂Ë∑ØÂæÑ
        """
        try:
            # ÊñπÊ≥ï1Ôºö‰ºòÂÖà‰ΩøÁî®JSON‰∏≠ËÆ∞ÂΩïÁöÑfile_path
            if "file_path" in json_data:
                recorded_path = json_data["file_path"]
                if isinstance(recorded_path, str) and recorded_path:
                    # Ëß£ÊûêË∑ØÂæÑÔºåÊîØÊåÅÁõ∏ÂØπË∑ØÂæÑÂíåÁªùÂØπË∑ØÂæÑ
                    if recorded_path.startswith("../"):
                        # Áõ∏ÂØπË∑ØÂæÑÔºåÂü∫‰∫éÂΩìÂâçÂ∑•‰ΩúÁõÆÂΩïËß£Êûê
                        resolved_path = Path(recorded_path).resolve()
                    else:
                        # ÁªùÂØπË∑ØÂæÑÊàñÂΩìÂâçÁõÆÂΩïË∑ØÂæÑ
                        resolved_path = Path(recorded_path)
                    
                    # Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶Â≠òÂú®
                    if resolved_path.exists():
                        return str(resolved_path)
                    else:
                        self.logger.debug(f"JSONËÆ∞ÂΩïË∑ØÂæÑ‰∏çÂ≠òÂú®: {resolved_path}")
            
            # ÊñπÊ≥ï2Ôºö‰ΩøÁî®JSON‰∏≠ËÆ∞ÂΩïÁöÑfile_name
            if "file_name" in json_data:
                recorded_name = json_data["file_name"]
                if isinstance(recorded_name, str) and recorded_name:
                    candidate_path = json_file.parent / recorded_name
                    if candidate_path.exists():
                        return str(candidate_path)
                    else:
                        self.logger.debug(f"JSONËÆ∞ÂΩïÊñá‰ª∂Âêç‰∏çÂ≠òÂú®: {candidate_path}")
            
            # ÊñπÊ≥ï3ÔºöÊô∫ËÉΩÂåπÈÖç - Â∞ùËØïÂ§öÁßçÊñá‰ª∂ÂêçÊ®°Âºè
            base_name = json_file.stem.replace("_analysis", "")
            candidate_names = [
                f"{base_name}.mp4",           # Ê†áÂáÜÂêçÁß∞
                f"‚ôªÔ∏è{base_name}.mp4",         # Â∏¶‚ôªÔ∏èÂâçÁºÄ
                f"‚ùå{base_name}.mp4",         # Â∏¶‚ùåÂâçÁºÄ
            ]
            
            for candidate_name in candidate_names:
                candidate_path = json_file.parent / candidate_name
                if candidate_path.exists():
                    return str(candidate_path)
            
            # ÊñπÊ≥ï4ÔºöÊ®°Á≥äÂåπÈÖç - Âú®ÂêåÁõÆÂΩï‰∏ãÊêúÁ¥¢Áõ∏‰ººÊñá‰ª∂Âêç
            video_extensions = [".mp4", ".mov", ".avi", ".mkv"]
            for file_path in json_file.parent.iterdir():
                if file_path.is_file() and file_path.suffix.lower() in video_extensions:
                    # ÁßªÈô§ÁâπÊÆäÂâçÁºÄËøõË°åÊØîËæÉ
                    clean_name = file_path.stem.replace("‚ôªÔ∏è", "").replace("‚ùå", "")
                    if clean_name == base_name:
                        return str(file_path)
            
            # ÊñπÊ≥ï5ÔºöÂÖúÂ∫ïÊñπÊ°à - ËøîÂõûÊé®ÊµãÁöÑË∑ØÂæÑÔºàÂèØËÉΩ‰∏çÂ≠òÂú®Ôºâ
            fallback_path = json_file.parent / f"{base_name}.mp4"
            self.logger.warning(f"‚ö†Ô∏è Êó†Ê≥ïÊâæÂà∞ÂåπÈÖçÁöÑËßÜÈ¢ëÊñá‰ª∂Ôºå‰ΩøÁî®ÂÖúÂ∫ïË∑ØÂæÑ: {fallback_path}")
            return str(fallback_path)
            
        except Exception as e:
            self.logger.error(f"‚ùå Ëß£ÊûêËßÜÈ¢ëÊñá‰ª∂Ë∑ØÂæÑÂºÇÂ∏∏ {json_file}: {e}")
            # ËøîÂõûÂÖúÂ∫ïË∑ØÂæÑ
            return str(json_file.parent / f"{json_file.stem.replace('_analysis', '')}.mp4")

    def _should_filter_file(self, json_file: Path, json_data: Dict[str, Any]) -> bool:
        """
        Âà§Êñ≠Êñá‰ª∂ÊòØÂê¶ÈúÄË¶ÅËøáÊª§Ôºà‰æãÂ¶ÇÔºåÂ∏¶‚ùåÂâçÁºÄÔºåÊàñquality_status‰∏∫failedÔºâ
        
        Args:
            json_file: JSONÊñá‰ª∂Ë∑ØÂæÑ
            json_data: JSONÊï∞ÊçÆÂÜÖÂÆπ
            
        Returns:
            bool: ÊòØÂê¶ÈúÄË¶ÅËøáÊª§
        """
        # üéØ Áî®Êà∑ÂèçÈ¶àÔºöÂ§öÈïúÂ§¥ËßÜÈ¢ë‰πüÂ∫îËØ•Ë¢´ÂàÜÊûêÔºåÂè™ËøáÊª§ÁúüÊ≠£Â§±Ë¥•ÁöÑÊñá‰ª∂
        # Âè™ËøáÊª§‚ùåÂâçÁºÄÁöÑÊñá‰ª∂ÔºàÂàÜÊûêÂ§±Ë¥•ÔºâÔºå‚ôªÔ∏èÊñá‰ª∂ÂÖÅËÆ∏Ê≠£Â∏∏ÂàÜÊûê
        if json_file.stem.startswith("‚ùå"):
            return True
        
        # Ê£ÄÊü•quality_statusÊòØÂê¶‰∏∫failed
        if json_data.get("quality_status") == "failed":
            return True
        
        return False

    def _resolve_valid_video_file_path(self, json_file: Path, json_data: Dict[str, Any]) -> str:
        """
        Êô∫ËÉΩËß£ÊûêËßÜÈ¢ëÊñá‰ª∂Ë∑ØÂæÑ - ‰ªÖÂØπÊúâÊïàÊñá‰ª∂‰ΩøÁî®
        
        Args:
            json_file: JSONÊñá‰ª∂Ë∑ØÂæÑ
            json_data: JSONÊï∞ÊçÆÂÜÖÂÆπ
            
        Returns:
            str: ÂÆûÈôÖÁöÑËßÜÈ¢ëÊñá‰ª∂Ë∑ØÂæÑ
        """
        try:
            # ÊñπÊ≥ï1Ôºö‰ºòÂÖà‰ΩøÁî®JSON‰∏≠ËÆ∞ÂΩïÁöÑfile_path
            if "file_path" in json_data:
                recorded_path = json_data["file_path"]
                if isinstance(recorded_path, str) and recorded_path:
                    # Ëß£ÊûêË∑ØÂæÑÔºåÊîØÊåÅÁõ∏ÂØπË∑ØÂæÑÂíåÁªùÂØπË∑ØÂæÑ
                    if recorded_path.startswith("../"):
                        # Áõ∏ÂØπË∑ØÂæÑÔºåÂü∫‰∫éÂΩìÂâçÂ∑•‰ΩúÁõÆÂΩïËß£Êûê
                        resolved_path = Path(recorded_path).resolve()
                    else:
                        # ÁªùÂØπË∑ØÂæÑÊàñÂΩìÂâçÁõÆÂΩïË∑ØÂæÑ
                        resolved_path = Path(recorded_path)
                    
                    # Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶Â≠òÂú®
                    if resolved_path.exists():
                        return str(resolved_path)
                    else:
                        self.logger.debug(f"JSONËÆ∞ÂΩïË∑ØÂæÑ‰∏çÂ≠òÂú®: {resolved_path}")
            
            # ÊñπÊ≥ï2Ôºö‰ΩøÁî®JSON‰∏≠ËÆ∞ÂΩïÁöÑfile_name
            if "file_name" in json_data:
                recorded_name = json_data["file_name"]
                if isinstance(recorded_name, str) and recorded_name:
                    candidate_path = json_file.parent / recorded_name
                    if candidate_path.exists():
                        return str(candidate_path)
                    else:
                        self.logger.debug(f"JSONËÆ∞ÂΩïÊñá‰ª∂Âêç‰∏çÂ≠òÂú®: {candidate_path}")
            
            # ÊñπÊ≥ï3ÔºöÊô∫ËÉΩÂåπÈÖç - Â∞ùËØïÂ§öÁßçÊñá‰ª∂ÂêçÊ®°Âºè
            base_name = json_file.stem.replace("_analysis", "")
            candidate_names = [
                f"{base_name}.mp4",           # Ê†áÂáÜÂêçÁß∞
                f"‚ôªÔ∏è{base_name}.mp4",         # Â∏¶‚ôªÔ∏èÂâçÁºÄ
                f"‚ùå{base_name}.mp4",         # Â∏¶‚ùåÂâçÁºÄ
            ]
            
            for candidate_name in candidate_names:
                candidate_path = json_file.parent / candidate_name
                if candidate_path.exists():
                    return str(candidate_path)
            
            # ÊñπÊ≥ï4ÔºöÊ®°Á≥äÂåπÈÖç - Âú®ÂêåÁõÆÂΩï‰∏ãÊêúÁ¥¢Áõ∏‰ººÊñá‰ª∂Âêç
            video_extensions = [".mp4", ".mov", ".avi", ".mkv"]
            for file_path in json_file.parent.iterdir():
                if file_path.is_file() and file_path.suffix.lower() in video_extensions:
                    # ÁßªÈô§ÁâπÊÆäÂâçÁºÄËøõË°åÊØîËæÉ
                    clean_name = file_path.stem.replace("‚ôªÔ∏è", "").replace("‚ùå", "")
                    if clean_name == base_name:
                        return str(file_path)
            
            # ÊñπÊ≥ï5ÔºöÂÖúÂ∫ïÊñπÊ°à - ËøîÂõûÊé®ÊµãÁöÑË∑ØÂæÑÔºàÂèØËÉΩ‰∏çÂ≠òÂú®Ôºâ
            fallback_path = json_file.parent / f"{base_name}.mp4"
            self.logger.warning(f"‚ö†Ô∏è Êó†Ê≥ïÊâæÂà∞ÂåπÈÖçÁöÑËßÜÈ¢ëÊñá‰ª∂Ôºå‰ΩøÁî®ÂÖúÂ∫ïË∑ØÂæÑ: {fallback_path}")
            return str(fallback_path)
            
        except Exception as e:
            self.logger.error(f"‚ùå Ëß£ÊûêËßÜÈ¢ëÊñá‰ª∂Ë∑ØÂæÑÂºÇÂ∏∏ {json_file}: {e}")
            # ËøîÂõûÂÖúÂ∫ïË∑ØÂæÑ
            return str(json_file.parent / f"{json_file.stem.replace('_analysis', '')}.mp4")

    def collect_all_slice_data(self) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """
        Êî∂ÈõÜÊâÄÊúâÂàáÁâáÊï∞ÊçÆ - ÊîØÊåÅÁÅµÊ¥ªÁöÑÊñá‰ª∂Â§πÁªìÊûÑÔºåÂπ∂ËøáÊª§Êó†ÊïàÊñá‰ª∂
        
        Returns:
            Tuple[List[Dict], List[Dict]]: (Â∑≤ÂàÜÁ±ªÊï∞ÊçÆ, Êú™ÂàÜÁ±ªÊï∞ÊçÆ)
        """
        try:
            classified_data = []
            unclassified_data = []
            
            processing_stats = {
                "total_files": 0,
                "classified_files": 0,
                "unclassified_files": 0,
                "invalid_files": 0,
                "filtered_files": 0  # üÜï Êñ∞Â¢ûÔºöËøáÊª§ÁöÑÊñá‰ª∂Êï∞Èáè
            }
            
            # Êî∂ÈõÜÊâÄÊúâËßÜÈ¢ëÁõÆÂΩïÁöÑJSONÊñá‰ª∂
            for video_name in self.get_all_video_directories():
                self.logger.info(f"üìÅ Â§ÑÁêÜËßÜÈ¢ëÁõÆÂΩï: {video_name}")
                
                # Ëé∑ÂèñËØ•ËßÜÈ¢ëÁöÑÊâÄÊúâJSONÊñá‰ª∂
                json_files = self.get_slice_json_files(video_name)
                processing_stats["total_files"] += len(json_files)
                
                for json_file in json_files:
                    try:
                        # ËØªÂèñJSONÊï∞ÊçÆ
                        json_data = self.read_json_file(json_file)
                        if not json_data:
                            processing_stats["invalid_files"] += 1
                            continue
                        
                        # üö® Êñ∞Â¢ûÔºöË¥®ÈáèËøáÊª§ÈÄªËæë
                        if self._should_filter_file(json_file, json_data):
                            processing_stats["filtered_files"] += 1
                            self.logger.debug(f"üö´ ËøáÊª§Êñá‰ª∂: {json_file.name} (Ë¥®ÈáèÈóÆÈ¢ò)")
                            continue
                        
                        # ‰º∞ÁÆóÊó∂Èïø
                        duration = json_data.get("duration", 0)
                        if duration == 0:
                            duration = self.estimate_slice_duration(json_file)
                        
                        # ÊèêÂèñlabelsÂÜÖÂÆπ
                        labels_content = self.extract_labels_for_classification(json_data)
                        
                        # üîß ‰øÆÂ§çÔºö‰ªÖÂØπÊúâÊïàÊñá‰ª∂‰ΩøÁî®Êô∫ËÉΩË∑ØÂæÑËß£Êûê
                        resolved_file_path = self._resolve_valid_video_file_path(json_file, json_data)
                        
                        # ÊûÑÂª∫ÂàáÁâáÊï∞ÊçÆ
                        slice_data = {
                            "file_path": resolved_file_path,
                            "analysis_file": str(json_file),
                            "duration": duration,
                            "labels": labels_content,
                            "video_name": video_name,
                            "slice_name": json_file.stem.replace("_analysis", ""),
                            "raw_data": json_data  # ‰øùÂ≠òÂéüÂßãÊï∞ÊçÆ
                        }
                        
                        # Ê£ÄÊü•ÊòØÂê¶Â∑≤ÂàÜÁ±ª
                        if self.check_if_already_processed(json_data):
                            processing_stats["classified_files"] += 1
                            
                            # ÊèêÂèñ‰∏ªÊ†áÁ≠æÂíåÁõ∏ÂÖ≥‰ø°ÊÅØ
                            main_tag = json_data.get("main_tag", "")
                            confidence = json_data.get("main_tag_confidence", 0)
                            
                            slice_data.update({
                                "main_tag": main_tag,
                                "confidence": confidence
                            })
                            
                            classified_data.append(slice_data)
                        else:
                            processing_stats["unclassified_files"] += 1
                            
                            # ÂàÜÊûêÊú™ÂàÜÁ±ªÂéüÂõ†
                            unclassified_reason = self._analyze_unclassified_reason(json_data, labels_content)
                            slice_data.update({
                                "unclassified_reason": unclassified_reason
                            })
                            
                            unclassified_data.append(slice_data)
                        
                    except Exception as e:
                        self.logger.warning(f"‚ö†Ô∏è Â§ÑÁêÜÊñá‰ª∂ {json_file.name} Êó∂Âá∫Èîô: {e}")
                        processing_stats["invalid_files"] += 1
                        continue
            
            self.logger.info(f"üìä Êï∞ÊçÆÊî∂ÈõÜÂÆåÊàê: {len(classified_data)} ‰∏™Â∑≤ÂàÜÁ±ªÂàáÁâá, {len(unclassified_data)} ‰∏™Êú™ÂàÜÁ±ªÂàáÁâá")
            self.logger.info(f"üö´ Â∑≤ËøáÊª§ {processing_stats['filtered_files']} ‰∏™Ë¥®ÈáèÈóÆÈ¢òÊñá‰ª∂")
            self.logger.info(f"üìà Â§ÑÁêÜÁªüËÆ°: {processing_stats}")
            
            return classified_data, unclassified_data
        except Exception as e:
            self.logger.error(f"‚ùå Êî∂ÈõÜÊâÄÊúâÂàáÁâáÊï∞ÊçÆÊó∂ÂèëÁîüÈîôËØØ: {e}")
            return [], []
    
    def _analyze_unclassified_reason(self, json_data: Dict[str, Any], labels_content: str) -> str:
        """
        ÂàÜÊûêÊú™ÂàÜÁ±ªÁöÑÂéüÂõ†
        
        Args:
            json_data: JSONÊï∞ÊçÆ
            labels_content: labelsÂÜÖÂÆπ
            
        Returns:
            str: Êú™ÂàÜÁ±ªÂéüÂõ†ÊèèËø∞
        """
        if not labels_content or labels_content.strip() == "":
            return "ËßÜËßâÂàÜÊûêÊï∞ÊçÆ‰∏∫Á©∫ÊàñÊó†Êïà"
        
        if json_data.get("main_tag_status") == "unclassified":
            return json_data.get("unclassified_reason", "AIÂàÜÊûêÁΩÆ‰ø°Â∫¶‰∏çË∂≥")
        
        return "Êú™ËøõË°å‰∏ªÊ†áÁ≠æÂàÜÁ±ª"
    
    # ==================== ÁªüËÆ°‰ø°ÊÅØ ====================
    
    def get_processing_statistics(self, video_name: Optional[str] = None) -> Dict[str, Any]:
        """
        Ëé∑ÂèñÂ§ÑÁêÜÁªüËÆ°‰ø°ÊÅØ
        
        Args:
            video_name: ÊåáÂÆöËßÜÈ¢ëÂêçÁß∞ÔºåNoneË°®Á§∫ÁªüËÆ°ÊâÄÊúâËßÜÈ¢ë
            
        Returns:
            Dict[str, Any]: ÁªüËÆ°‰ø°ÊÅØ
        """
        if video_name:
            # Âçï‰∏™ËßÜÈ¢ëÁöÑÁªüËÆ°
            json_files = self.get_slice_json_files(video_name)
            
            stats = {
                "video_name": video_name,
                "total_files": len(json_files),
                "already_processed": 0,
                "needs_processing": 0,
                "invalid_files": 0
            }
            
            for json_file in json_files:
                data = self.read_json_file(json_file)
                if data is None:
                    stats["invalid_files"] += 1
                elif self.check_if_already_processed(data):
                    stats["already_processed"] += 1
                else:
                    stats["needs_processing"] += 1
            
            return stats
        else:
            # ÊâÄÊúâËßÜÈ¢ëÁöÑÁªüËÆ°
            video_dirs = self.get_all_video_directories()
            all_stats = {}
            
            total_summary = {
                "total_videos": len(video_dirs),
                "total_files": 0,
                "already_processed": 0,
                "needs_processing": 0,
                "invalid_files": 0
            }
            
            for video_name in video_dirs:
                stats = self.get_processing_statistics(video_name)
                all_stats[video_name] = stats
                
                # Á¥ØËÆ°Âà∞ÊÄªËÆ°
                for key in ["total_files", "already_processed", "needs_processing", "invalid_files"]:
                    total_summary[key] += stats[key]
            
            all_stats["TOTAL"] = total_summary
            return all_stats
    
    # ==================== Â∑•ÂÖ∑ÊñπÊ≥ï ====================
    
    def get_timestamp(self) -> str:
        """Ëé∑ÂèñÂΩìÂâçÊó∂Èó¥Êà≥"""
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    def backup_json_file(self, json_file_path: Path) -> bool:
        """
        Â§á‰ªΩJSONÊñá‰ª∂
        
        Args:
            json_file_path: Ë¶ÅÂ§á‰ªΩÁöÑJSONÊñá‰ª∂Ë∑ØÂæÑ
            
        Returns:
            bool: Â§á‰ªΩÊòØÂê¶ÊàêÂäü
        """
        try:
            backup_path = json_file_path.with_suffix(".json.backup")
            
            # Â¶ÇÊûúÂ§á‰ªΩÂ∑≤Â≠òÂú®ÔºåË∑≥Ëøá
            if backup_path.exists():
                return True
            
            import shutil
            shutil.copy2(json_file_path, backup_path)
            self.logger.debug(f"üîÑ Â§á‰ªΩÊñá‰ª∂: {backup_path.name}")
            return True
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Â§á‰ªΩÊñá‰ª∂Â§±Ë¥• {json_file_path}: {e}")
            return False
    
    def update_json_with_main_tag(self, json_file_path: Path, main_tag: str, 
                                 confidence: float, analysis: Dict[str, Any]) -> bool:
        """
        Êõ¥Êñ∞JSONÊñá‰ª∂ÔºåÊ∑ªÂä†main_tagÂ≠óÊÆµ
        
        Args:
            json_file_path: JSONÊñá‰ª∂Ë∑ØÂæÑ
            main_tag: ‰∏ªÊ†áÁ≠æ
            confidence: ÁΩÆ‰ø°Â∫¶
            analysis: ÂàÜÊûêÁªìÊûú
            
        Returns:
            bool: Êõ¥Êñ∞ÊòØÂê¶ÊàêÂäü
        """
        try:
            # ËØªÂèñÂéüÂßãÊï∞ÊçÆ
            data = self.read_json_file(json_file_path)
            if data is None:
                return False
            
            # Ê∑ªÂä†main_tagÁõ∏ÂÖ≥Â≠óÊÆµ
            data["main_tag"] = main_tag
            data["main_tag_confidence"] = confidence
            data["main_tag_reasoning"] = analysis.get("reasoning", "")
            data["main_tag_keywords"] = analysis.get("matched_keywords", [])
            data["main_tag_processed_at"] = self.get_timestamp()
            
            # ÂÜôÂõûÊñá‰ª∂
            success = self.write_json_file(json_file_path, data)
            
            if success:
                self.logger.info(f"‚úÖ Êõ¥Êñ∞ÊàêÂäü: {json_file_path.name} -> {main_tag}")
            else:
                self.logger.error(f"‚ùå Êõ¥Êñ∞Â§±Ë¥•: {json_file_path.name}")
            
            return success
            
        except Exception as e:
            self.logger.error(f"‚ùå Êõ¥Êñ∞JSONÊñá‰ª∂ÂºÇÂ∏∏ {json_file_path}: {e}")
            return False 