#!/usr/bin/env python3
"""
ğŸ“„ JSONæ–‡ä»¶å¤„ç†å™¨
ä¸“é—¨å¤„ç†ğŸ¬Sliceç›®å½•ä¸‹çš„åˆ‡ç‰‡JSONæ–‡ä»¶ï¼Œæ·»åŠ main_tagå­—æ®µ
"""

import json
import os
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any

logger = logging.getLogger(__name__)


class SliceJsonProcessor:
    """åˆ‡ç‰‡JSONæ–‡ä»¶å¤„ç†å™¨"""
    
    def __init__(self, slice_base_dir: str = "../ğŸ¬Slice"):
        """åˆå§‹åŒ–JSONå¤„ç†å™¨"""
        self.slice_base_dir = Path(slice_base_dir)
        if not self.slice_base_dir.exists():
            raise ValueError(f"åˆ‡ç‰‡ç›®å½•ä¸å­˜åœ¨: {self.slice_base_dir}")
        
        logger.info(f"âœ… JSONå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œåˆ‡ç‰‡ç›®å½•: {self.slice_base_dir}")
    
    def get_all_video_directories(self) -> List[str]:
        """è·å–æ‰€æœ‰è§†é¢‘ç›®å½•åç§°"""
        video_dirs = []
        
        for item in self.slice_base_dir.iterdir():
            # æ£€æŸ¥æ˜¯å¦ä¸ºç›®å½•ä¸”åŒ…å«sliceså­ç›®å½•ï¼ˆæ’é™¤.DS_Storeç­‰ç³»ç»Ÿæ–‡ä»¶ï¼‰
            if (item.is_dir() and 
                item.name not in [".", "..", "ğŸ¬Slice"] and 
                not item.name.startswith(".") and
                (item / "slices").exists()):
                video_dirs.append(item.name)
        
        video_dirs.sort()
        logger.info(f"ğŸ“ æ‰¾åˆ° {len(video_dirs)} ä¸ªè§†é¢‘ç›®å½•: {video_dirs}")
        return video_dirs
    
    def get_slice_json_files(self, video_name: str) -> List[Path]:
        """è·å–æŒ‡å®šè§†é¢‘çš„æ‰€æœ‰åˆ‡ç‰‡JSONæ–‡ä»¶"""
        video_dir = self.slice_base_dir / video_name / "slices"
        
        if not video_dir.exists():
            logger.warning(f"âš ï¸ è§†é¢‘åˆ‡ç‰‡ç›®å½•ä¸å­˜åœ¨: {video_dir}")
            return []
        
        json_files = []
        for file in video_dir.iterdir():
            if file.is_file() and file.name.endswith("_analysis.json"):
                json_files.append(file)
        
        json_files.sort()
        logger.info(f"ğŸ“„ {video_name} æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶")
        return json_files
    
    def read_json_file(self, json_file_path: Path) -> Optional[Dict[str, Any]]:
        """è¯»å–JSONæ–‡ä»¶å†…å®¹"""
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return data
        except Exception as e:
            logger.error(f"âŒ è¯»å–JSONæ–‡ä»¶å¤±è´¥ {json_file_path}: {e}")
            return None
    
    def write_json_file(self, json_file_path: Path, data: Dict[str, Any]) -> bool:
        """å†™å…¥JSONæ–‡ä»¶"""
        try:
            with open(json_file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            logger.error(f"âŒ å†™å…¥JSONæ–‡ä»¶å¤±è´¥ {json_file_path}: {e}")
            return False
    
    def extract_labels_for_classification(self, json_data: Dict[str, Any]) -> str:
        """ä»JSONæ•°æ®ä¸­æå–ç”¨äºåˆ†ç±»çš„Labelså†…å®¹"""
        # æå–å…³é”®å­—æ®µç»„æˆåˆ†ææ–‡æœ¬
        labels_parts = []
        
        # ä¸»è¦å­—æ®µ
        object_field = json_data.get("object", "")
        scene_field = json_data.get("scene", "")
        emotion_field = json_data.get("emotion", "")
        brand_elements = json_data.get("brand_elements", "")
        
        if object_field and object_field != "æ— ":
            labels_parts.append(f"å¯¹è±¡: {object_field}")
        
        if scene_field and scene_field != "æ— ":
            labels_parts.append(f"åœºæ™¯: {scene_field}")
        
        if emotion_field and emotion_field != "æ— ":
            labels_parts.append(f"æƒ…ç»ª: {emotion_field}")
        
        if brand_elements and brand_elements != "æ— ":
            labels_parts.append(f"å“ç‰Œå…ƒç´ : {brand_elements}")
        
        # æ‹¼æ¥æˆå®Œæ•´çš„labelsæ–‡æœ¬
        labels_text = " | ".join(labels_parts)
        
        if not labels_text.strip():
            labels_text = f"å¯¹è±¡: {object_field}, åœºæ™¯: {scene_field}, æƒ…ç»ª: {emotion_field}"
        
        return labels_text
    
    def update_json_with_main_tag(self, json_file_path: Path, main_tag: str, confidence: float, analysis: Dict[str, Any]) -> bool:
        """æ›´æ–°JSONæ–‡ä»¶ï¼Œæ·»åŠ main_tagå­—æ®µ"""
        try:
            # è¯»å–åŸå§‹æ•°æ®
            data = self.read_json_file(json_file_path)
            if data is None:
                return False
            
            # æ·»åŠ main_tagç›¸å…³å­—æ®µ
            data["main_tag"] = main_tag
            data["main_tag_confidence"] = confidence
            data["main_tag_reasoning"] = analysis.get("reasoning", "")
            data["main_tag_keywords"] = analysis.get("matched_keywords", [])
            data["main_tag_processed_at"] = self._get_timestamp()
            
            # å†™å›æ–‡ä»¶
            success = self.write_json_file(json_file_path, data)
            
            if success:
                logger.info(f"âœ… æ›´æ–°æˆåŠŸ: {json_file_path.name} -> {main_tag}")
            else:
                logger.error(f"âŒ æ›´æ–°å¤±è´¥: {json_file_path.name}")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°JSONæ–‡ä»¶å¼‚å¸¸ {json_file_path}: {e}")
            return False
    
    def check_if_already_processed(self, json_data: Dict[str, Any]) -> bool:
        """æ£€æŸ¥JSONæ–‡ä»¶æ˜¯å¦å·²ç»å¤„ç†è¿‡"""
        return "main_tag" in json_data and json_data.get("main_tag", "").strip() != ""
    
    def get_processing_statistics(self, video_name: str) -> Dict[str, int]:
        """è·å–æŒ‡å®šè§†é¢‘çš„å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        json_files = self.get_slice_json_files(video_name)
        
        stats = {
            "total_files": len(json_files),
            "already_processed": 0,
            "needs_processing": 0,
            "invalid_files": 0
        }
        
        for json_file in json_files:
            data = self.read_json_file(json_file)
            if data is None:
                stats["invalid_files"] += 1
            elif self.check_if_already_processed(data):
                stats["already_processed"] += 1
            else:
                stats["needs_processing"] += 1
        
        return stats
    
    def get_all_processing_statistics(self) -> Dict[str, Dict[str, int]]:
        """è·å–æ‰€æœ‰è§†é¢‘çš„å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        video_dirs = self.get_all_video_directories()
        all_stats = {}
        
        total_summary = {
            "total_files": 0,
            "already_processed": 0,
            "needs_processing": 0,
            "invalid_files": 0
        }
        
        for video_name in video_dirs:
            stats = self.get_processing_statistics(video_name)
            all_stats[video_name] = stats
            
            # ç´¯è®¡åˆ°æ€»è®¡
            for key in total_summary:
                total_summary[key] += stats[key]
        
        all_stats["TOTAL"] = total_summary
        return all_stats
    
    def _get_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    def backup_json_file(self, json_file_path: Path) -> bool:
        """å¤‡ä»½JSONæ–‡ä»¶"""
        try:
            backup_path = json_file_path.with_suffix(".json.backup")
            
            # å¦‚æœå¤‡ä»½å·²å­˜åœ¨ï¼Œè·³è¿‡
            if backup_path.exists():
                return True
            
            import shutil
            shutil.copy2(json_file_path, backup_path)
            logger.debug(f"ğŸ”„ å¤‡ä»½æ–‡ä»¶: {backup_path.name}")
            return True
            
        except Exception as e:
            logger.warning(f"âš ï¸ å¤‡ä»½æ–‡ä»¶å¤±è´¥ {json_file_path}: {e}")
            return False 