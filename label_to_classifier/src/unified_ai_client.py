#!/usr/bin/env python3
"""
ğŸ¤– ç»Ÿä¸€AIå®¢æˆ·ç«¯
æä¾›ç»Ÿä¸€çš„AI APIè°ƒç”¨æ¥å£ï¼Œæ”¯æŒå¤šæ¨¡å‹è‡ªåŠ¨åˆ‡æ¢ã€é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
å®ç° DeepSeek -> Claude -> æŠ¥é”™ çš„é€»è¾‘
"""

import json
import logging
import time
import requests
from typing import Dict, List, Optional, Any, Union
try:
    from .unified_ai_config_manager import (
        UnifiedAIConfigManager, ModelConfig, ModelSelectionStrategy, 
        TaskType, ModelType, get_ai_config_manager
    )
except ImportError:
    # æ”¯æŒç›´æ¥è¿è¡Œæµ‹è¯•
    from unified_ai_config_manager import (
        UnifiedAIConfigManager, ModelConfig, ModelSelectionStrategy, 
        TaskType, ModelType, get_ai_config_manager
    )

logger = logging.getLogger(__name__)

class AICallResult:
    """AIè°ƒç”¨ç»“æœå°è£…"""
    
    def __init__(self, success: bool, data: Any = None, error: str = None, 
                 model_used: str = None, attempts: int = 0):
        self.success = success
        self.data = data
        self.error = error
        self.model_used = model_used
        self.attempts = attempts
        self.timestamp = time.time()
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "success": self.success,
            "data": self.data,
            "error": self.error,
            "model_used": self.model_used,
            "attempts": self.attempts,
            "timestamp": self.timestamp
        }

class UnifiedAIClient:
    """ç»Ÿä¸€AIå®¢æˆ·ç«¯"""
    
    def __init__(self, task_type: TaskType):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        self.task_type = task_type
        self.config_manager = get_ai_config_manager()
        self.logger = logging.getLogger(f"{__name__}.{task_type.value}")
        
        # è·å–ä»»åŠ¡é…ç½®
        self.model_configs, self.strategy = self.config_manager.get_model_selection_for_task(task_type)
        
        self.logger.info(f"ğŸ¤– ç»Ÿä¸€AIå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ - ä»»åŠ¡: {task_type.value}")
        self.logger.info(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {[config.model_type.value for config in self.model_configs]}")
        self.logger.info(f"ğŸ¯ ç­–ç•¥: ä¸¥æ ¼æ¨¡å¼={self.strategy.strict_mode}, å›é€€={self.strategy.fallback_enabled}")
    
    def call_ai(self, prompt: str, user_message: str, **kwargs) -> AICallResult:
        """
        ç»Ÿä¸€AIè°ƒç”¨æ¥å£
        
        Args:
            prompt: ç³»ç»Ÿæç¤ºè¯
            user_message: ç”¨æˆ·æ¶ˆæ¯
            **kwargs: é¢å¤–å‚æ•°
        
        Returns:
            AICallResult: è°ƒç”¨ç»“æœ
        """
        total_attempts = 0
        last_error = None
        
        # æŒ‰ä¼˜å…ˆçº§å°è¯•æ¯ä¸ªæ¨¡å‹
        for model_config in self.model_configs:
            model_attempts = 0
            
            while model_attempts < self.strategy.max_retries:
                total_attempts += 1
                model_attempts += 1
                
                try:
                    self.logger.info(f"ğŸ¤– å°è¯•è°ƒç”¨ {model_config.model_type.value} (ç¬¬{model_attempts}æ¬¡)")
                    
                    result = self._call_single_model(model_config, prompt, user_message, **kwargs)
                    
                    if result.success:
                        self.logger.info(f"âœ… {model_config.model_type.value} è°ƒç”¨æˆåŠŸ")
                        result.attempts = total_attempts
                        return result
                    else:
                        last_error = result.error
                        self.logger.warning(f"âš ï¸ {model_config.model_type.value} è°ƒç”¨å¤±è´¥: {result.error}")
                        
                        # å¦‚æœä¸æ˜¯ä¸¥æ ¼æ¨¡å¼ï¼Œå•ä¸ªæ¨¡å‹æˆåŠŸå³å¯
                        if not self.strategy.strict_mode:
                            break
                
                except Exception as e:
                    last_error = str(e)
                    self.logger.error(f"âŒ {model_config.model_type.value} è°ƒç”¨å¼‚å¸¸: {e}")
                
                # é‡è¯•é—´éš”
                if model_attempts < self.strategy.max_retries:
                    time.sleep(1)
            
            self.logger.warning(f"âš ï¸ {model_config.model_type.value} ç»è¿‡ {self.strategy.max_retries} æ¬¡å°è¯•åå¤±è´¥")
        
        # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥äº†
        error_message = f"âŒ æ‰€æœ‰æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œæœ€åé”™è¯¯: {last_error}"
        self.logger.error(error_message)
        
        return AICallResult(
            success=False,
            error=error_message,
            attempts=total_attempts
        )
    
    def _call_single_model(self, config: ModelConfig, prompt: str, user_message: str, **kwargs) -> AICallResult:
        """è°ƒç”¨å•ä¸ªæ¨¡å‹"""
        try:
            if config.model_type == ModelType.DEEPSEEK:
                return self._call_deepseek(config, prompt, user_message, **kwargs)
            elif config.model_type == ModelType.CLAUDE:
                return self._call_claude_via_openrouter(config, prompt, user_message, **kwargs)
            else:
                return AICallResult(
                    success=False,
                    error=f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {config.model_type.value}",
                    model_used=config.model_type.value
                )
        
        except Exception as e:
            return AICallResult(
                success=False,
                error=f"æ¨¡å‹è°ƒç”¨å¼‚å¸¸: {str(e)}",
                model_used=config.model_type.value
            )
    
    def _call_deepseek(self, config: ModelConfig, prompt: str, user_message: str, **kwargs) -> AICallResult:
        """è°ƒç”¨DeepSeekæ¨¡å‹"""
        headers = {
            "Authorization": f"Bearer {config.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": config.model_name,
            "messages": [
                {"role": "system", "content": prompt},
                {"role": "user", "content": user_message}
            ],
            "temperature": kwargs.get("temperature", config.temperature),
            "max_tokens": kwargs.get("max_tokens", config.max_tokens),
            "stream": False
        }
        
        response = requests.post(
            config.api_url,
            headers=headers,
            json=payload,
            timeout=config.timeout
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            
            return AICallResult(
                success=True,
                data=content,
                model_used=config.model_type.value
            )
        else:
            return AICallResult(
                success=False,
                error=f"DeepSeek APIé”™è¯¯: {response.status_code} - {response.text}",
                model_used=config.model_type.value
            )
    
    def _call_claude_via_openrouter(self, config: ModelConfig, prompt: str, user_message: str, **kwargs) -> AICallResult:
        """é€šè¿‡OpenRouterè°ƒç”¨Claudeæ¨¡å‹"""
        headers = {
            "Authorization": f"Bearer {config.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/ai-video-analysis",
            "X-Title": "AI Video Analysis Tool"
        }
        
        payload = {
            "model": config.model_name,
            "messages": [
                {"role": "system", "content": prompt},
                {"role": "user", "content": user_message}
            ],
            "temperature": kwargs.get("temperature", config.temperature),
            "max_tokens": kwargs.get("max_tokens", config.max_tokens)
        }
        
        response = requests.post(
            config.api_url,
            headers=headers,
            json=payload,
            timeout=config.timeout
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            
            return AICallResult(
                success=True,
                data=content,
                model_used=config.model_type.value
            )
        else:
            return AICallResult(
                success=False,
                error=f"Claude APIé”™è¯¯: {response.status_code} - {response.text}",
                model_used=config.model_type.value
            )
    

    
    def get_available_models(self) -> List[str]:
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        return [config.model_type.value for config in self.model_configs]
    
    def get_current_strategy(self) -> Dict[str, Any]:
        """è·å–å½“å‰ç­–ç•¥ä¿¡æ¯"""
        return {
            "task_type": self.task_type.value,
            "available_models": self.get_available_models(),
            "strict_mode": self.strategy.strict_mode,
            "fallback_enabled": self.strategy.fallback_enabled,
            "max_retries": self.strategy.max_retries
        }

# ä¾¿æ·å‡½æ•°
def create_ai_client(task_type: TaskType) -> UnifiedAIClient:
    """åˆ›å»ºAIå®¢æˆ·ç«¯çš„ä¾¿æ·å‡½æ•°"""
    return UnifiedAIClient(task_type)

def call_ai_for_task(task_type: TaskType, prompt: str, user_message: str, **kwargs) -> AICallResult:
    """ä¸ºæŒ‡å®šä»»åŠ¡è°ƒç”¨AIçš„ä¾¿æ·å‡½æ•°"""
    client = create_ai_client(task_type)
    return client.call_ai(prompt, user_message, **kwargs)

if __name__ == "__main__":
    # æµ‹è¯•ç»Ÿä¸€AIå®¢æˆ·ç«¯ - ä¸“æ³¨äºæ–‡æœ¬åˆ†ç±»ä»»åŠ¡
    print("ğŸ§ª æµ‹è¯•ç»Ÿä¸€AIå®¢æˆ·ç«¯ï¼ˆæ–‡æœ¬åˆ†ç±»ä¸“ç”¨ï¼‰")
    print("=" * 60)
    
    try:
        # æµ‹è¯•ä¸»æ ‡ç­¾åˆ†ç±»
        main_tag_client = UnifiedAIClient(TaskType.MAIN_TAG_CLASSIFICATION)
        print(f"ğŸ“‹ ä¸»æ ‡ç­¾åˆ†ç±»å®¢æˆ·ç«¯é…ç½®: {main_tag_client.get_current_strategy()}")
        
        # æµ‹è¯•äºŒçº§æ ‡ç­¾åˆ†ç±»
        secondary_tag_client = UnifiedAIClient(TaskType.SECONDARY_TAG_CLASSIFICATION)
        print(f"ğŸ“‹ äºŒçº§æ ‡ç­¾åˆ†ç±»å®¢æˆ·ç«¯é…ç½®: {secondary_tag_client.get_current_strategy()}")
        
        print(f"\nğŸ¯ é…ç½®ç‰¹ç‚¹:")
        print(f"   - ä¸»æ ‡ç­¾åˆ†ç±»: æ”¯æŒå›é€€ï¼Œå•ä¸ªæ¨¡å‹æˆåŠŸå³å¯")
        print(f"   - äºŒçº§æ ‡ç­¾åˆ†ç±»: ä¸¥æ ¼æ¨¡å¼ï¼ŒDeepSeek->Claude->æŠ¥é”™")
        print(f"   - ä»…æ”¯æŒæ–‡æœ¬åˆ†ç±»ï¼Œä¸åŒ…å«è§†è§‰æ¨¡å‹")
        
        # æ¨¡æ‹Ÿç®€å•çš„AIè°ƒç”¨æµ‹è¯•
        test_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å©´å¹¼å„¿å¥¶ç²‰è§†é¢‘åˆ†æä¸“å®¶ã€‚"
        test_message = "è¯·å¯¹ä»¥ä¸‹æ ‡ç­¾è¿›è¡Œåˆ†ç±»æµ‹è¯•ï¼šè¥å…»é…æ–¹ã€A2è›‹ç™½ã€ä¾¿æºè£…"
        
        print(f"\nğŸ§ª æ‰§è¡ŒAIè°ƒç”¨æµ‹è¯•...")
        result = main_tag_client.call_ai(test_prompt, test_message)
        
        if result.success:
            print(f"âœ… æµ‹è¯•æˆåŠŸ - ä½¿ç”¨æ¨¡å‹: {result.model_used}")
            print(f"ğŸ“„ å“åº”å†…å®¹: {result.data[:100]}...")
        else:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {result.error}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}") 