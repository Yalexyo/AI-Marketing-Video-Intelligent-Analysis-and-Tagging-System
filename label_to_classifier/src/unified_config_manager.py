#!/usr/bin/env python3
"""
âš™ï¸ ç»Ÿä¸€é…ç½®ç®¡ç†å™¨
æ•´åˆæ‰€æœ‰æ¨¡å—çš„é…ç½®ç®¡ç†ï¼Œæä¾›ç»Ÿä¸€çš„é…ç½®æ¥å£
æ¶æ„ä¼˜åŒ–ç‰ˆï¼šå‡å°‘é…ç½®æ–‡ä»¶å†—ä½™ï¼Œç»Ÿä¸€ç¯å¢ƒå˜é‡ç®¡ç†
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional
from dataclasses import dataclass

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


@dataclass
class AIModelConfig:
    """AIæ¨¡å‹é…ç½®"""
    primary_model: str
    secondary_model: str
    api_key: str
    base_url: Optional[str] = None
    timeout: int = 30
    max_retries: int = 2


@dataclass
class ProcessingConfig:
    """å¤„ç†é…ç½®"""
    slice_base_dir: str = "../ğŸ¬Slice"
    output_base_dir: str = "../ğŸ“ç”Ÿæˆç»“æœ"
    backup_enabled: bool = True
    min_confidence_threshold: float = 0.4
    batch_size: int = 10
    concurrent_workers: int = 3


@dataclass
class UnifiedConfig:
    """ç»Ÿä¸€é…ç½®"""
    processing: ProcessingConfig
    deepseek: AIModelConfig
    claude: AIModelConfig
    gemini: AIModelConfig
    debug_mode: bool = False
    log_level: str = "INFO"


class UnifiedConfigManager:
    """âš™ï¸ ç»Ÿä¸€é…ç½®ç®¡ç†å™¨ - æ•´åˆæ‰€æœ‰æ¨¡å—é…ç½®"""
    
    def __init__(self, config_file: Optional[str] = None):
        """åˆå§‹åŒ–ç»Ÿä¸€é…ç½®ç®¡ç†å™¨"""
        self.config_file = config_file or "config/unified_config.json"
        self.config_dir = Path("config")
        self.config_dir.mkdir(exist_ok=True)
        
        # åŠ è½½é…ç½®
        self.config = self._load_unified_config()
        
        # è®¾ç½®æ—¥å¿—çº§åˆ«
        logging.getLogger().setLevel(getattr(logging, self.config.log_level))
        
        logger.info("âœ… ç»Ÿä¸€é…ç½®ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“ é…ç½®æ–‡ä»¶: {self.config_file}")
        logger.info(f"ğŸ”§ è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if self.config.debug_mode else 'å…³é—­'}")
    
    def _load_unified_config(self) -> UnifiedConfig:
        """åŠ è½½ç»Ÿä¸€é…ç½®"""
        try:
            # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡åŠ è½½
            config = self._load_from_environment()
            
            # å¦‚æœé…ç½®æ–‡ä»¶å­˜åœ¨ï¼Œåˆå¹¶é…ç½®æ–‡ä»¶çš„è®¾ç½®
            config_path = Path(self.config_file)
            if config_path.exists():
                file_config = self._load_from_file(config_path)
                config = self._merge_configs(config, file_config)
            
            # éªŒè¯é…ç½®
            self._validate_config(config)
            
            return config
            
        except Exception as e:
            logger.error(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
            return self._get_default_config()
    
    def _load_from_environment(self) -> UnifiedConfig:
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        # å¤„ç†é…ç½®
        processing_config = ProcessingConfig(
            slice_base_dir=os.getenv("SLICE_BASE_DIR", "../ğŸ¬Slice"),
            output_base_dir=os.getenv("OUTPUT_BASE_DIR", "../ğŸ“ç”Ÿæˆç»“æœ"),
            backup_enabled=os.getenv("BACKUP_ENABLED", "true").lower() == "true",
            min_confidence_threshold=float(os.getenv("MIN_CONFIDENCE_THRESHOLD", "0.4")),
            batch_size=int(os.getenv("BATCH_SIZE", "10")),
            concurrent_workers=int(os.getenv("CONCURRENT_WORKERS", "3"))
        )
        
        # DeepSeeké…ç½®
        deepseek_config = AIModelConfig(
            primary_model=os.getenv("DEEPSEEK_PRIMARY_MODEL", "deepseek-chat"),
            secondary_model=os.getenv("DEEPSEEK_SECONDARY_MODEL", "deepseek-chat"),
            api_key=os.getenv("DEEPSEEK_API_KEY", ""),
            base_url=os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com"),
            timeout=int(os.getenv("DEEPSEEK_TIMEOUT", "30")),
            max_retries=int(os.getenv("DEEPSEEK_MAX_RETRIES", "2"))
        )
        
        # Claudeé…ç½®
        claude_config = AIModelConfig(
            primary_model=os.getenv("CLAUDE_PRIMARY_MODEL", "anthropic/claude-4-sonnet-20250522"),
            secondary_model=os.getenv("CLAUDE_SECONDARY_MODEL", "anthropic/claude-4-sonnet-20250522"),
            api_key=os.getenv("OPENROUTER_API_KEY", ""),
            base_url=os.getenv("OPENROUTER_BASE_URL", "https://openrouter.ai/api/v1"),
            timeout=int(os.getenv("CLAUDE_TIMEOUT", "30")),
            max_retries=int(os.getenv("CLAUDE_MAX_RETRIES", "2"))
        )
        
        # Geminié…ç½®
        gemini_config = AIModelConfig(
            primary_model=os.getenv("GEMINI_PRIMARY_MODEL", "gemini-2.5-pro"),
            secondary_model=os.getenv("GEMINI_SECONDARY_MODEL", "gemini-2.5-pro"),
            api_key=os.getenv("GEMINI_API_KEY", ""),
            base_url=os.getenv("GEMINI_BASE_URL"),
            timeout=int(os.getenv("GEMINI_TIMEOUT", "30")),
            max_retries=int(os.getenv("GEMINI_MAX_RETRIES", "2"))
        )
        
        return UnifiedConfig(
            processing=processing_config,
            deepseek=deepseek_config,
            claude=claude_config,
            gemini=gemini_config,
            debug_mode=os.getenv("DEBUG_MODE", "false").lower() == "true",
            log_level=os.getenv("LOG_LEVEL", "INFO")
        )
    
    def _load_from_file(self, config_path: Path) -> Dict[str, Any]:
        """ä»é…ç½®æ–‡ä»¶åŠ è½½é…ç½®"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            return {}
    
    def _merge_configs(self, env_config: UnifiedConfig, file_config: Dict[str, Any]) -> UnifiedConfig:
        """åˆå¹¶ç¯å¢ƒå˜é‡é…ç½®å’Œæ–‡ä»¶é…ç½®"""
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„é…ç½®åˆå¹¶é€»è¾‘
        # ç›®å‰ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®
        return env_config
    
    def _validate_config(self, config: UnifiedConfig):
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        # éªŒè¯APIå¯†é’¥
        if not config.deepseek.api_key:
            logger.warning("âš ï¸ DeepSeek APIå¯†é’¥æœªé…ç½®")
        
        if not config.claude.api_key:
            logger.warning("âš ï¸ Claude APIå¯†é’¥æœªé…ç½®")
        
        if not config.gemini.api_key:
            logger.warning("âš ï¸ Gemini APIå¯†é’¥æœªé…ç½®")
        
        # éªŒè¯è·¯å¾„
        slice_dir = Path(config.processing.slice_base_dir)
        if not slice_dir.exists():
            logger.warning(f"âš ï¸ åˆ‡ç‰‡ç›®å½•ä¸å­˜åœ¨: {slice_dir}")
        
        # éªŒè¯æ•°å€¼èŒƒå›´
        if config.processing.min_confidence_threshold < 0 or config.processing.min_confidence_threshold > 1:
            logger.warning(f"âš ï¸ ç½®ä¿¡åº¦é˜ˆå€¼è¶…å‡ºèŒƒå›´: {config.processing.min_confidence_threshold}")
    
    def _get_default_config(self) -> UnifiedConfig:
        """è·å–é»˜è®¤é…ç½®"""
        logger.info("ğŸ”§ ä½¿ç”¨é»˜è®¤é…ç½®")
        
        return UnifiedConfig(
            processing=ProcessingConfig(),
            deepseek=AIModelConfig(
                primary_model="deepseek-chat",
                secondary_model="deepseek-chat",
                api_key=""
            ),
            claude=AIModelConfig(
                primary_model="anthropic/claude-4-sonnet-20250522",
                secondary_model="anthropic/claude-4-sonnet-20250522",
                api_key=""
            ),
            gemini=AIModelConfig(
                primary_model="gemini-2.5-pro",
                secondary_model="gemini-2.5-pro",
                api_key=""
            )
        )
    
    def get_config(self) -> UnifiedConfig:
        """è·å–ç»Ÿä¸€é…ç½®"""
        return self.config
    
    def get_ai_config(self, model_type: str) -> AIModelConfig:
        """è·å–æŒ‡å®šAIæ¨¡å‹é…ç½®"""
        if model_type.lower() == "deepseek":
            return self.config.deepseek
        elif model_type.lower() == "claude":
            return self.config.claude
        elif model_type.lower() == "gemini":
            return self.config.gemini
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
    
    def get_processing_config(self) -> ProcessingConfig:
        """è·å–å¤„ç†é…ç½®"""
        return self.config.processing
    
    def update_config(self, updates: Dict[str, Any]):
        """æ›´æ–°é…ç½®"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°é…ç½®çš„åŠ¨æ€æ›´æ–°
            logger.info("ğŸ”§ é…ç½®æ›´æ–°è¯·æ±‚")
            # å®é™…å®ç°ä¼šæ›´å¤æ‚ï¼Œéœ€è¦æ ¹æ®æ›´æ–°å†…å®¹ä¿®æ”¹å¯¹åº”çš„é…ç½®å¯¹è±¡
            pass
        except Exception as e:
            logger.error(f"âŒ é…ç½®æ›´æ–°å¤±è´¥: {e}")
    
    def save_config_to_file(self, file_path: Optional[str] = None):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        try:
            output_path = Path(file_path or self.config_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            config_dict = {
                "processing": {
                    "slice_base_dir": self.config.processing.slice_base_dir,
                    "output_base_dir": self.config.processing.output_base_dir,
                    "backup_enabled": self.config.processing.backup_enabled,
                    "min_confidence_threshold": self.config.processing.min_confidence_threshold,
                    "batch_size": self.config.processing.batch_size,
                    "concurrent_workers": self.config.processing.concurrent_workers
                },
                "deepseek": {
                    "primary_model": self.config.deepseek.primary_model,
                    "secondary_model": self.config.deepseek.secondary_model,
                    "base_url": self.config.deepseek.base_url,
                    "timeout": self.config.deepseek.timeout,
                    "max_retries": self.config.deepseek.max_retries
                },
                "claude": {
                    "primary_model": self.config.claude.primary_model,
                    "secondary_model": self.config.claude.secondary_model,
                    "base_url": self.config.claude.base_url,
                    "timeout": self.config.claude.timeout,
                    "max_retries": self.config.claude.max_retries
                },
                "gemini": {
                    "primary_model": self.config.gemini.primary_model,
                    "secondary_model": self.config.gemini.secondary_model,
                    "base_url": self.config.gemini.base_url,
                    "timeout": self.config.gemini.timeout,
                    "max_retries": self.config.gemini.max_retries
                },
                "debug_mode": self.config.debug_mode,
                "log_level": self.config.log_level,
                "note": "APIå¯†é’¥é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼Œä¸ä¿å­˜åˆ°æ–‡ä»¶ä¸­"
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(config_dict, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: {output_path}")
            
        except Exception as e:
            logger.error(f"âŒ é…ç½®ä¿å­˜å¤±è´¥: {e}")
    
    def get_config_summary(self) -> Dict[str, Any]:
        """è·å–é…ç½®æ‘˜è¦"""
        return {
            "processing": {
                "slice_base_dir": self.config.processing.slice_base_dir,
                "output_base_dir": self.config.processing.output_base_dir,
                "backup_enabled": self.config.processing.backup_enabled,
                "min_confidence_threshold": self.config.processing.min_confidence_threshold,
                "batch_size": self.config.processing.batch_size,
                "concurrent_workers": self.config.processing.concurrent_workers
            },
            "ai_models": {
                "deepseek": {
                    "primary_model": self.config.deepseek.primary_model,
                    "api_key_configured": bool(self.config.deepseek.api_key)
                },
                "claude": {
                    "primary_model": self.config.claude.primary_model,
                    "api_key_configured": bool(self.config.claude.api_key)
                },
                "gemini": {
                    "primary_model": self.config.gemini.primary_model,
                    "api_key_configured": bool(self.config.gemini.api_key)
                }
            },
            "debug_mode": self.config.debug_mode,
            "log_level": self.config.log_level
        }
    
    def print_config_status(self):
        """æ‰“å°é…ç½®çŠ¶æ€"""
        print("âš™ï¸ ç»Ÿä¸€é…ç½®çŠ¶æ€:")
        print("=" * 50)
        
        summary = self.get_config_summary()
        
        print("ğŸ“ å¤„ç†é…ç½®:")
        for key, value in summary["processing"].items():
            print(f"   {key}: {value}")
        
        print("\nğŸ¤– AIæ¨¡å‹é…ç½®:")
        for model, config in summary["ai_models"].items():
            api_status = "âœ… å·²é…ç½®" if config["api_key_configured"] else "âŒ æœªé…ç½®"
            print(f"   {model}: {config['primary_model']} ({api_status})")
        
        print(f"\nğŸ”§ ç³»ç»Ÿé…ç½®:")
        print(f"   è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if summary['debug_mode'] else 'å…³é—­'}")
        print(f"   æ—¥å¿—çº§åˆ«: {summary['log_level']}")


# å…¨å±€é…ç½®ç®¡ç†å™¨å®ä¾‹
_global_config_manager: Optional[UnifiedConfigManager] = None


def get_unified_config_manager() -> UnifiedConfigManager:
    """è·å–å…¨å±€ç»Ÿä¸€é…ç½®ç®¡ç†å™¨å®ä¾‹"""
    global _global_config_manager
    if _global_config_manager is None:
        _global_config_manager = UnifiedConfigManager()
    return _global_config_manager


def get_ai_config(model_type: str) -> AIModelConfig:
    """è·å–AIæ¨¡å‹é…ç½®çš„ä¾¿æ·å‡½æ•°"""
    return get_unified_config_manager().get_ai_config(model_type)


def get_processing_config() -> ProcessingConfig:
    """è·å–å¤„ç†é…ç½®çš„ä¾¿æ·å‡½æ•°"""
    return get_unified_config_manager().get_processing_config() 