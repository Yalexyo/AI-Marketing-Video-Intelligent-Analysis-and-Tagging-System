#!/usr/bin/env python3
"""
è¯­ä¹‰ç‰‡æ®µåˆå¹¶å™¨ - åŸºäºè§†è§‰å’Œè¯­ä¹‰ç›¸ä¼¼æ€§åˆå¹¶è§†é¢‘ç‰‡æ®µ
ä½¿ç”¨CLIPæ¨¡å‹è¿›è¡Œå¤šæ¨¡æ€åˆ†æï¼Œå®ç°æ™ºèƒ½ç‰‡æ®µæ•´åˆ

ä¸»è¦åŠŸèƒ½:
1. è§†è§‰ç›¸ä¼¼æ€§åˆ†æ
2. è¯­ä¹‰å†…å®¹ç†è§£
3. ç›¸é‚»ç‰‡æ®µåˆå¹¶ç­–ç•¥
4. æ—¶é—´è¿è´¯æ€§ä¿è¯
"""

import os
import cv2
import numpy as np
import logging
import subprocess
import shutil
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import json
from datetime import datetime

logger = logging.getLogger(__name__)

try:
    import torch
    from transformers import CLIPProcessor, CLIPModel
    from PIL import Image
    CLIP_AVAILABLE = True
except ImportError:
    CLIP_AVAILABLE = False
    logger.warning("CLIPæ¨¡å‹ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install torch transformers pillow")


class SemanticSegmentMerger:
    """è¯­ä¹‰ç‰‡æ®µåˆå¹¶å™¨"""
    
    def __init__(self, 
                 similarity_threshold: float = 0.92,
                 max_merge_duration: float = 25.0,
                 min_segment_duration: float = 2.0):
        """
        åˆå§‹åŒ–è¯­ä¹‰ç‰‡æ®µåˆå¹¶å™¨
        
        Args:
            similarity_threshold: è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼ (0-1)
            max_merge_duration: å•ä¸ªåˆå¹¶ç‰‡æ®µæœ€å¤§æ—¶é•¿(ç§’)
            min_segment_duration: æœ€å°ç‰‡æ®µæ—¶é•¿(ç§’)
        """
        self.similarity_threshold = similarity_threshold
        self.max_merge_duration = max_merge_duration
        self.min_segment_duration = min_segment_duration
        
        # åˆå§‹åŒ–CLIPæ¨¡å‹
        self.clip_model = None
        self.clip_processor = None
        self._init_clip_model()
        
        logger.info(f"è¯­ä¹‰ç‰‡æ®µåˆå¹¶å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ç›¸ä¼¼åº¦é˜ˆå€¼: {similarity_threshold}")
        logger.info(f"æœ€å¤§åˆå¹¶æ—¶é•¿: {max_merge_duration}ç§’")
        logger.info(f"æœ€å°ç‰‡æ®µæ—¶é•¿: {min_segment_duration}ç§’")
    
    def _init_clip_model(self):
        """åˆå§‹åŒ–CLIPæ¨¡å‹"""
        if not CLIP_AVAILABLE:
            logger.warning("CLIPæ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨åŸºç¡€ç›¸ä¼¼æ€§åˆ†æ")
            print(f"âš ï¸ CLIPä¾èµ–æœªå®‰è£…ï¼Œå°†ä½¿ç”¨åŸºç¡€åˆ†ææ¨¡å¼")
            return
        
        try:
            model_name = "openai/clip-vit-base-patch32"
            cache_dir = Path("./cache/clip").resolve()
            
            # é¦–å…ˆå°è¯•åŠ è½½ç¦»çº¿æ¨¡å‹
            logger.info(f"å°è¯•åŠ è½½ç¦»çº¿CLIPæ¨¡å‹: {model_name}")
            print(f"ğŸ” æ£€æŸ¥æœ¬åœ°CLIPæ¨¡å‹...")
            
            try:
                # å°è¯•ç¦»çº¿åŠ è½½
                self.clip_model = CLIPModel.from_pretrained(
                    model_name,
                    cache_dir=str(cache_dir),
                    local_files_only=True  # åªä½¿ç”¨æœ¬åœ°æ–‡ä»¶
                )
                self.clip_processor = CLIPProcessor.from_pretrained(
                    model_name,
                    cache_dir=str(cache_dir),
                    local_files_only=True
                )
                print("âœ… æˆåŠŸåŠ è½½æœ¬åœ°CLIPæ¨¡å‹")
                
            except Exception as offline_error:
                logger.warning(f"ç¦»çº¿æ¨¡å‹åŠ è½½å¤±è´¥: {offline_error}")
                print(f"âš ï¸ æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨ï¼Œå°è¯•åœ¨çº¿ä¸‹è½½...")
                
                # å¦‚æœç¦»çº¿åŠ è½½å¤±è´¥ï¼Œå°è¯•åœ¨çº¿ä¸‹è½½
                self.clip_model = CLIPModel.from_pretrained(
                    model_name,
                    cache_dir=str(cache_dir),
                    local_files_only=False
                )
                self.clip_processor = CLIPProcessor.from_pretrained(
                    model_name,
                    cache_dir=str(cache_dir),
                    local_files_only=False
                )
                print("âœ… åœ¨çº¿ä¸‹è½½æ¨¡å‹æˆåŠŸ")
            
            # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            self.clip_model.eval()
            
            # æ£€æŸ¥GPUå¯ç”¨æ€§
            if torch.cuda.is_available():
                self.clip_model = self.clip_model.to('cuda')
                logger.info("CLIPæ¨¡å‹å·²åŠ è½½åˆ°GPU")
                print("ğŸ® CLIPæ¨¡å‹å·²åŠ è½½åˆ°GPU")
            else:
                logger.info("CLIPæ¨¡å‹ä½¿ç”¨CPU")
                print("ğŸ’» CLIPæ¨¡å‹ä½¿ç”¨CPU")
                
            logger.info("CLIPæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.warning(f"CLIPæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            print(f"âš ï¸ CLIPæ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸºç¡€åˆ†ææ¨¡å¼")
            print(f"   å»ºè®®è¿è¡Œ: uv run python download_models.py")
            self.clip_model = None
            self.clip_processor = None
    
    def extract_video_frames(self, video_path: str, num_frames: int = 5) -> List[np.ndarray]:
        """
        ä»è§†é¢‘ä¸­æå–å…³é”®å¸§
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            num_frames: æå–å¸§æ•°
            
        Returns:
            å¸§å›¾åƒåˆ—è¡¨
        """
        frames = []
        
        try:
            cap = cv2.VideoCapture(video_path)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            if total_frames <= 0:
                logger.warning(f"æ— æ³•è¯»å–è§†é¢‘å¸§: {video_path}")
                return frames
            
            # å‡åŒ€é‡‡æ ·å¸§
            frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
            
            for frame_idx in frame_indices:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ret, frame = cap.read()
                
                if ret:
                    # è½¬æ¢é¢œè‰²ç©ºé—´ BGR -> RGB
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    frames.append(frame_rgb)
                else:
                    logger.warning(f"æ— æ³•è¯»å–ç¬¬{frame_idx}å¸§")
            
            cap.release()
            
        except Exception as e:
            logger.error(f"æå–è§†é¢‘å¸§å¤±è´¥ {video_path}: {e}")
        
        return frames
    
    def compute_clip_features(self, frames: List[np.ndarray]) -> Optional[np.ndarray]:
        """
        ä½¿ç”¨CLIPè®¡ç®—è§†é¢‘å¸§ç‰¹å¾
        
        Args:
            frames: è§†é¢‘å¸§åˆ—è¡¨
            
        Returns:
            ç‰¹å¾å‘é‡ æˆ– None
        """
        if not self.clip_model or not frames:
            # å¦‚æœCLIPä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€ç‰¹å¾
            return self._compute_basic_features(frames)
        
        try:
            # è½¬æ¢ä¸ºPILå›¾åƒ
            pil_images = [Image.fromarray(frame) for frame in frames]
            
            # é¢„å¤„ç†å›¾åƒ
            inputs = self.clip_processor(images=pil_images, return_tensors="pt", padding=True)
            
            # ç§»åŠ¨åˆ°GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if torch.cuda.is_available():
                inputs = {k: v.to('cuda') for k, v in inputs.items()}
            
            # è®¡ç®—å›¾åƒç‰¹å¾
            with torch.no_grad():
                image_features = self.clip_model.get_image_features(**inputs)
                
                # å–å¹³å‡å€¼ä½œä¸ºè§†é¢‘ç‰¹å¾
                video_features = torch.mean(image_features, dim=0)
                
                # å½’ä¸€åŒ–
                video_features = video_features / video_features.norm(dim=-1, keepdim=True)
                
                return video_features.cpu().numpy()
                
        except Exception as e:
            logger.error(f"CLIPç‰¹å¾è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€ç‰¹å¾: {e}")
            return self._compute_basic_features(frames)
    
    def _compute_basic_features(self, frames: List[np.ndarray]) -> Optional[np.ndarray]:
        """
        è®¡ç®—åŸºç¡€è§†è§‰ç‰¹å¾ï¼ˆä¸ä¾èµ–CLIPï¼‰
        
        Args:
            frames: è§†é¢‘å¸§åˆ—è¡¨
            
        Returns:
            åŸºç¡€ç‰¹å¾å‘é‡
        """
        if not frames:
            return None
        
        try:
            features = []
            
            for frame in frames:
                # è®¡ç®—é¢œè‰²ç›´æ–¹å›¾
                hist_b = cv2.calcHist([frame], [0], None, [32], [0, 256])
                hist_g = cv2.calcHist([frame], [1], None, [32], [0, 256])
                hist_r = cv2.calcHist([frame], [2], None, [32], [0, 256])
                
                # å½’ä¸€åŒ–ç›´æ–¹å›¾
                hist_b = hist_b.flatten() / np.sum(hist_b)
                hist_g = hist_g.flatten() / np.sum(hist_g)
                hist_r = hist_r.flatten() / np.sum(hist_r)
                
                # åˆå¹¶é¢œè‰²ç‰¹å¾
                color_features = np.concatenate([hist_r, hist_g, hist_b])
                
                # è®¡ç®—äº®åº¦å’Œå¯¹æ¯”åº¦ç‰¹å¾
                gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
                brightness = np.mean(gray)
                contrast = np.std(gray)
                
                # è®¡ç®—è¾¹ç¼˜ç‰¹å¾
                edges = cv2.Canny(gray, 50, 150)
                edge_density = np.sum(edges > 0) / edges.size
                
                # ç»„åˆæ‰€æœ‰ç‰¹å¾
                frame_features = np.concatenate([
                    color_features,
                    [brightness, contrast, edge_density]
                ])
                
                features.append(frame_features)
            
            # å–æ‰€æœ‰å¸§ç‰¹å¾çš„å¹³å‡å€¼
            video_features = np.mean(features, axis=0)
            
            # å½’ä¸€åŒ–
            video_features = video_features / np.linalg.norm(video_features)
            
            return video_features
            
        except Exception as e:
            logger.error(f"åŸºç¡€ç‰¹å¾è®¡ç®—å¤±è´¥: {e}")
            return None
    
    def compute_similarity(self, features1: np.ndarray, features2: np.ndarray) -> float:
        """è®¡ç®—è¯­ä¹‰ç›¸ä¼¼æ€§"""
        try:
            similarity = np.dot(features1, features2) / (
                np.linalg.norm(features1) * np.linalg.norm(features2)
            )
            return float((similarity + 1) / 2)  # å½’ä¸€åŒ–åˆ° [0, 1]
        except Exception as e:
            logger.error(f"ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def analyze_segments_similarity(self, segments: List[Dict[str, Any]], progress_callback: Optional[callable] = None) -> List[Dict[str, Any]]:
        """
        åˆ†æç‰‡æ®µé—´çš„è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œç¡®ä¿æ—¶é—´é¡ºåºçš„è¿è´¯æ€§
        
        Args:
            segments: è§†é¢‘ç‰‡æ®µåˆ—è¡¨
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            å¸¦æœ‰ç›¸ä¼¼æ€§ä¿¡æ¯çš„ç‰‡æ®µåˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´é¡ºåºæ’åº
        """
        logger.info(f"å¼€å§‹åˆ†æ {len(segments)} ä¸ªç‰‡æ®µçš„è¯­ä¹‰ç›¸ä¼¼æ€§")
        
        # ğŸš¨ å…³é”®ä¿®å¤ï¼šé¦–å…ˆæŒ‰æ—¶é—´é¡ºåºæ’åºæ‰€æœ‰ç‰‡æ®µ
        logger.info("ğŸ“Š æŒ‰æ—¶é—´é¡ºåºæ’åºç‰‡æ®µ...")
        sorted_segments = sorted(segments, key=lambda x: x.get('start_time', 0))
        
        # éªŒè¯æ—¶é—´é¡ºåºå’Œè¿è´¯æ€§
        logger.info("ğŸ” éªŒè¯æ—¶é—´è¿è´¯æ€§...")
        time_gaps = []
        for i in range(len(sorted_segments) - 1):
            current_end = sorted_segments[i].get('end_time', 0)
            next_start = sorted_segments[i + 1].get('start_time', 0)
            gap = next_start - current_end
            time_gaps.append(gap)
            if gap > 2.0:  # è¶…è¿‡2ç§’çš„æ—¶é—´é—´éš”
                logger.warning(f"âš ï¸  ç‰‡æ®µ {i+1} å’Œ {i+2} ä¹‹é—´æœ‰ {gap:.1f}s æ—¶é—´é—´éš”")
        
        avg_gap = sum(time_gaps) / len(time_gaps) if time_gaps else 0
        logger.info(f"å¹³å‡æ—¶é—´é—´éš”: {avg_gap:.2f}s")
        
        if progress_callback:
            progress_callback(20, f"åˆ†æ {len(sorted_segments)} ä¸ªç‰‡æ®µç‰¹å¾...")
        
        # ä¸ºæ¯ä¸ªç‰‡æ®µè®¡ç®—ç‰¹å¾
        for i, segment in enumerate(sorted_segments):
            if progress_callback and len(sorted_segments) > 1:
                progress = 20 + (i / len(sorted_segments)) * 20  # 20-40%
                progress_callback(progress, f"å¤„ç†ç‰‡æ®µ {i+1}/{len(sorted_segments)}")
            
            if not os.path.exists(segment.get('file_path', '')):
                logger.warning(f"ç‰‡æ®µæ–‡ä»¶ä¸å­˜åœ¨: {segment.get('file_path')}")
                segment['clip_features'] = None
                segment['has_features'] = False
                continue
            
            # æå–è§†é¢‘å¸§
            frames = self.extract_video_frames(segment['file_path'])
            
            if frames:
                # è®¡ç®—CLIPç‰¹å¾
                features = self.compute_clip_features(frames)
                segment['clip_features'] = features
                segment['has_features'] = features is not None
            else:
                segment['clip_features'] = None
                segment['has_features'] = False
            
            # è®°å½•æ—¶é—´é¡ºåºç´¢å¼•
            segment['time_order_index'] = i
            
            logger.debug(f"ç‰‡æ®µ {i+1}/{len(sorted_segments)} ç‰¹å¾è®¡ç®—å®Œæˆ")
        
        # ğŸ”‘ å…³é”®ï¼šåŸºäºæ—¶é—´é¡ºåºè®¡ç®—ç›¸é‚»ç‰‡æ®µçš„ç›¸ä¼¼åº¦
        logger.info("ğŸ§  è®¡ç®—æ—¶é—´ç›¸é‚»ç‰‡æ®µçš„è¯­ä¹‰ç›¸ä¼¼åº¦...")
        for i in range(len(sorted_segments) - 1):
            current_seg = sorted_segments[i]
            next_seg = sorted_segments[i + 1]
            
            # é¢å¤–éªŒè¯ï¼šç¡®ä¿è¿™ä¸¤ä¸ªç‰‡æ®µåœ¨æ—¶é—´ä¸Šæ˜¯çœŸæ­£ç›¸é‚»çš„
            current_end = current_seg.get('end_time', 0)
            next_start = next_seg.get('start_time', 0)
            time_gap = next_start - current_end
            
            if (current_seg.get('has_features') and 
                next_seg.get('has_features') and
                time_gap <= 2.0):  # åªæœ‰æ—¶é—´é—´éš”ä¸è¶…è¿‡2ç§’æ‰è®¡ç®—ç›¸ä¼¼åº¦
                
                similarity = self.compute_similarity(
                    current_seg['clip_features'],
                    next_seg['clip_features']
                )
                
                current_seg['similarity_to_next'] = similarity
                current_seg['time_gap_to_next'] = time_gap
                logger.debug(f"ç‰‡æ®µ {i}->{i+1} ç›¸ä¼¼åº¦: {similarity:.3f}, æ—¶é—´é—´éš”: {time_gap:.1f}s")
            else:
                current_seg['similarity_to_next'] = 0.0
                current_seg['time_gap_to_next'] = time_gap if time_gap <= 10.0 else 10.0
                if time_gap > 2.0:
                    logger.debug(f"ç‰‡æ®µ {i}->{i+1}: æ—¶é—´é—´éš”è¿‡å¤§({time_gap:.1f}s)ï¼Œä¸è®¡ç®—ç›¸ä¼¼åº¦")
        
        # æœ€åä¸€ä¸ªç‰‡æ®µæ²¡æœ‰ä¸‹ä¸€ä¸ª
        if sorted_segments:
            sorted_segments[-1]['similarity_to_next'] = 0.0
            sorted_segments[-1]['time_gap_to_next'] = 0.0
        
        logger.info(f"âœ… å®Œæˆè¯­ä¹‰ç›¸ä¼¼æ€§åˆ†æï¼Œå…± {len(sorted_segments)} ä¸ªç‰‡æ®µï¼ŒæŒ‰æ—¶é—´é¡ºåºæ’åˆ—")
        return sorted_segments
    
    def merge_similar_segments(self, 
                             segments: List[Dict[str, Any]], 
                             video_path: str,
                             output_dir: str) -> List[Dict[str, Any]]:
        """
        åˆå¹¶ç›¸ä¼¼çš„ç‰‡æ®µï¼Œç›´æ¥æ›¿æ¢åŸå§‹åˆ‡ç‰‡æ–‡ä»¶
        
        Args:
            segments: å·²åˆ†æçš„ç‰‡æ®µåˆ—è¡¨
            video_path: åŸå§‹è§†é¢‘è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•ï¼ˆslicesæ–‡ä»¶å¤¹ï¼‰
            
        Returns:
            åˆå¹¶åçš„ç‰‡æ®µåˆ—è¡¨
        """
        if not segments:
            return []
        
        logger.info(f"ğŸ”— å¼€å§‹ä¸¥æ ¼è¯­ä¹‰åˆå¹¶")
        logger.info(f"ğŸ“Š ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_threshold} (ä¸¥æ ¼æ¨¡å¼)")
        logger.info(f"â±ï¸  æœ€å¤§åˆå¹¶æ—¶é•¿: {self.max_merge_duration}ç§’")
        
        # å¤‡ä»½åŸå§‹æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        backup_dir = Path(output_dir) / "backup_before_merge"
        backup_dir.mkdir(exist_ok=True)
        
        final_segments = []
        current_group = []
        files_to_delete = []  # éœ€è¦åˆ é™¤çš„åŸå§‹æ–‡ä»¶
        
        # éå†æ‰€æœ‰ç‰‡æ®µè¿›è¡Œåˆå¹¶åˆ†ç»„
        for i, segment in enumerate(segments):
            if not current_group:
                current_group = [segment]
                continue
            
            current_segment = current_group[-1]
            
            # åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆå¹¶åˆ°å½“å‰ç»„
            should_merge = self._should_merge_segments_strict(current_group, segment, current_segment)
            
            if should_merge:
                current_group.append(segment)
                logger.debug(f"ğŸ“ ç‰‡æ®µ{segment.get('segment_index')} åŠ å…¥åˆå¹¶ç»„ (ç›¸ä¼¼åº¦: {current_segment.get('similarity_to_next', 0):.3f})")
            else:
                # å¤„ç†å½“å‰ç»„
                result_segment = self._process_segment_group(
                    current_group, video_path, output_dir, backup_dir, len(final_segments)
                )
                if result_segment:
                    final_segments.append(result_segment)
                    # å¦‚æœæ˜¯åˆå¹¶çš„ï¼Œè®°å½•éœ€è¦åˆ é™¤çš„åŸå§‹æ–‡ä»¶
                    if result_segment.get('is_merged', False):
                        for seg in current_group:
                            files_to_delete.append(seg.get('file_path'))
                
                current_group = [segment]
        
        # å¤„ç†æœ€åä¸€ç»„
        if current_group:
            result_segment = self._process_segment_group(
                current_group, video_path, output_dir, backup_dir, len(final_segments)
            )
            if result_segment:
                final_segments.append(result_segment)
                if result_segment.get('is_merged', False):
                    for seg in current_group:
                        files_to_delete.append(seg.get('file_path'))
        
        # åˆ é™¤è¢«åˆå¹¶çš„åŸå§‹æ–‡ä»¶
        deleted_count = 0
        for file_path in files_to_delete:
            if file_path and os.path.exists(file_path):
                try:
                    # å…ˆå¤‡ä»½åˆ°backupç›®å½•
                    backup_path = backup_dir / Path(file_path).name
                    shutil.copy2(file_path, backup_path)
                    # ç„¶ååˆ é™¤åŸæ–‡ä»¶
                    os.remove(file_path)
                    deleted_count += 1
                    logger.debug(f"ğŸ—‘ï¸  åˆ é™¤åŸå§‹æ–‡ä»¶: {Path(file_path).name}")
                except Exception as e:
                    logger.warning(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        logger.info(f"ğŸ¯ åˆå¹¶å®Œæˆ: {len(segments)} -> {len(final_segments)} ä¸ªç‰‡æ®µ")
        logger.info(f"ğŸ—‘ï¸  åˆ é™¤åŸå§‹æ–‡ä»¶: {deleted_count} ä¸ª")
        logger.info(f"ğŸ’¾ å¤‡ä»½æ–‡ä»¶ä¿å­˜åœ¨: {backup_dir}")
        
        return final_segments
    
    def _should_merge_segments(self, 
                              current_group: List[Dict[str, Any]], 
                              next_segment: Dict[str, Any],
                              current_segment: Dict[str, Any]) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆå¹¶ç‰‡æ®µ
        
        Args:
            current_group: å½“å‰åˆå¹¶ç»„
            next_segment: ä¸‹ä¸€ä¸ªç‰‡æ®µ
            current_segment: å½“å‰ç‰‡æ®µ
            
        Returns:
            æ˜¯å¦åº”è¯¥åˆå¹¶
        """
        # æ£€æŸ¥ç›¸ä¼¼åº¦é˜ˆå€¼
        similarity = current_segment.get('similarity_to_next', 0.0)
        if similarity < self.similarity_threshold:
            return False
        
        # æ£€æŸ¥åˆå¹¶åæ—¶é•¿
        group_duration = sum(seg.get('duration', 0) for seg in current_group)
        next_duration = next_segment.get('duration', 0)
        
        if group_duration + next_duration > self.max_merge_duration:
            return False
        
        # æ£€æŸ¥æ—¶é—´è¿ç»­æ€§ï¼ˆå®¹å¿å°çš„æ—¶é—´é—´éš”ï¼‰
        last_seg = current_group[-1]
        time_gap = abs(next_segment.get('start_time', 0) - last_seg.get('end_time', 0))
        
        if time_gap > 1.0:  # è¶…è¿‡1ç§’é—´éš”å°±ä¸åˆå¹¶
            return False
        
        return True
    
    def _should_merge_segments_strict(self, 
                                    current_group: List[Dict[str, Any]], 
                                    next_segment: Dict[str, Any],
                                    current_segment: Dict[str, Any]) -> bool:
        """
        ä¸¥æ ¼æ¨¡å¼ä¸‹åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆå¹¶ç‰‡æ®µ
        
        Args:
            current_group: å½“å‰åˆå¹¶ç»„
            next_segment: ä¸‹ä¸€ä¸ªç‰‡æ®µ
            current_segment: å½“å‰ç‰‡æ®µ
            
        Returns:
            æ˜¯å¦åº”è¯¥åˆå¹¶
        """
        # æ£€æŸ¥ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆæ›´ä¸¥æ ¼ï¼‰
        similarity = current_segment.get('similarity_to_next', 0.0)
        if similarity < self.similarity_threshold:
            return False
        
        # æ£€æŸ¥åˆå¹¶åæ—¶é•¿ï¼ˆæ›´ä¸¥æ ¼ï¼‰
        group_duration = sum(seg.get('duration', 0) for seg in current_group)
        next_duration = next_segment.get('duration', 0)
        
        if group_duration + next_duration > self.max_merge_duration:
            return False
        
        # æ£€æŸ¥æ—¶é—´è¿ç»­æ€§ï¼ˆæ›´ä¸¥æ ¼ï¼Œå®¹å¿æ›´å°çš„æ—¶é—´é—´éš”ï¼‰
        last_seg = current_group[-1]
        time_gap = abs(next_segment.get('start_time', 0) - last_seg.get('end_time', 0))
        
        if time_gap > 0.5:  # è¶…è¿‡0.5ç§’é—´éš”å°±ä¸åˆå¹¶
            return False
        
        # é¢å¤–æ£€æŸ¥ï¼šä¸å…è®¸åˆå¹¶è¶…è¿‡3ä¸ªç‰‡æ®µ
        if len(current_group) >= 3:
            return False
        
        return True
    
    def _process_segment_group(self, 
                             segment_group: List[Dict[str, Any]], 
                             video_path: str,
                             output_dir: str,
                             backup_dir: Path,
                             index: int) -> Optional[Dict[str, Any]]:
        """
        å¤„ç†ç‰‡æ®µç»„ï¼Œå¦‚æœéœ€è¦åˆå¹¶åˆ™åˆ›å»ºåˆå¹¶æ–‡ä»¶ï¼Œå¦åˆ™ä¿ç•™åŸæ–‡ä»¶
        
        Args:
            segment_group: è¦å¤„ç†çš„ç‰‡æ®µç»„
            video_path: åŸå§‹è§†é¢‘è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•ï¼ˆslicesæ–‡ä»¶å¤¹ï¼‰
            backup_dir: å¤‡ä»½ç›®å½•
            index: ç‰‡æ®µç´¢å¼•
            
        Returns:
            å¤„ç†åçš„ç‰‡æ®µä¿¡æ¯
        """
        if not segment_group:
            return None
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥è¿”å›ï¼Œä¸åšä»»ä½•ä¿®æ”¹
        if len(segment_group) == 1:
            segment = segment_group[0].copy()
            segment['is_merged'] = False
            segment['original_count'] = 1
            return segment
        
        try:
            # å¤šä¸ªç‰‡æ®µéœ€è¦åˆå¹¶
            start_time = min(seg.get('start_time', 0) for seg in segment_group)
            end_time = max(seg.get('end_time', 0) for seg in segment_group)
            duration = end_time - start_time
            
            # ç”Ÿæˆåˆå¹¶åçš„æ–‡ä»¶åï¼Œç›´æ¥ä¿å­˜åœ¨slicesç›®å½•ä¸‹
            video_name = Path(video_path).stem
            first_seg_index = segment_group[0].get('segment_index', 1)
            last_seg_index = segment_group[-1].get('segment_index', 1)
            
            merged_filename = f"{video_name}_merged_{first_seg_index:03d}-{last_seg_index:03d}.mp4"
            merged_path = Path(output_dir) / merged_filename
            
            # ä½¿ç”¨FFmpegåˆå¹¶ç‰‡æ®µ
            success = self._merge_video_segments(video_path, start_time, end_time, str(merged_path))
            
            if success:
                merged_segment = {
                    'file_path': str(merged_path),
                    'start_time': start_time,
                    'end_time': end_time,
                    'duration': duration,
                    'segment_index': first_seg_index,  # ä½¿ç”¨ç¬¬ä¸€ä¸ªç‰‡æ®µçš„ç´¢å¼•
                    'file_size': merged_path.stat().st_size if merged_path.exists() else 0,
                    'is_merged': True,
                    'original_count': len(segment_group),
                    'original_segments': [seg.get('segment_index') for seg in segment_group],
                    'merge_similarity': sum(seg.get('similarity_to_next', 0) for seg in segment_group[:-1]) / max(1, len(segment_group) - 1)
                }
                
                logger.info(f"âœ… åˆå¹¶ {len(segment_group)} ä¸ªç‰‡æ®µ -> {merged_filename}")
                return merged_segment
            else:
                logger.error(f"âŒ åˆå¹¶å¤±è´¥: {merged_filename}")
                return None
                
        except Exception as e:
            logger.error(f"å¤„ç†ç‰‡æ®µç»„å¤±è´¥: {e}")
            return None
    
    def _create_merged_segment(self, 
                              segment_group: List[Dict[str, Any]], 
                              video_path: str,
                              output_dir: str,
                              index: int,
                              merge_session_dir: str) -> Optional[Dict[str, Any]]:
        """
        åˆ›å»ºåˆå¹¶åçš„è§†é¢‘ç‰‡æ®µï¼Œä¿å­˜åˆ°æŒ‡å®šçš„åˆå¹¶ä¼šè¯ç›®å½•
        
        Args:
            segment_group: è¦åˆå¹¶çš„ç‰‡æ®µç»„
            video_path: åŸå§‹è§†é¢‘è·¯å¾„
            output_dir: åŸè¾“å‡ºç›®å½•
            index: åˆå¹¶ç‰‡æ®µç´¢å¼•
            merge_session_dir: æœ¬æ¬¡åˆå¹¶ä¼šè¯ç›®å½•
            
        Returns:
            åˆå¹¶åçš„ç‰‡æ®µä¿¡æ¯
        """
        if not segment_group:
            return None
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œåˆ›å»ºç¬¦å·é“¾æ¥æˆ–å¤åˆ¶å¼•ç”¨
        if len(segment_group) == 1:
            segment = segment_group[0].copy()
            segment['is_merged'] = False
            segment['original_count'] = 1
            segment['merge_session'] = Path(merge_session_dir).name
            return segment
        
        try:
            # è®¡ç®—åˆå¹¶æ—¶é—´èŒƒå›´
            start_time = min(seg.get('start_time', 0) for seg in segment_group)
            end_time = max(seg.get('end_time', 0) for seg in segment_group)
            duration = end_time - start_time
            
            # ç”Ÿæˆç»“æ„åŒ–çš„è¾“å‡ºæ–‡ä»¶å
            video_name = Path(video_path).stem
            timestamp = datetime.now().strftime("%H%M%S")
            merged_filename = f"{video_name}_merged_{index+1:03d}_from{len(segment_group)}clips_{timestamp}.mp4"
            merged_path = Path(merge_session_dir) / merged_filename
            
            # ä½¿ç”¨FFmpegåˆå¹¶ç‰‡æ®µ
            success = self._merge_video_segments(video_path, start_time, end_time, str(merged_path))
            
            if success:
                merged_segment = {
                    'file_path': str(merged_path),
                    'start_time': start_time,
                    'end_time': end_time,
                    'duration': duration,
                    'segment_index': index + 1,
                    'file_size': merged_path.stat().st_size if merged_path.exists() else 0,
                    'is_merged': True,
                    'original_count': len(segment_group),
                    'original_segments': [seg.get('segment_index') for seg in segment_group],
                    'merge_similarity': sum(seg.get('similarity_to_next', 0) for seg in segment_group[:-1]) / max(1, len(segment_group) - 1),
                    'merge_session': Path(merge_session_dir).name
                }
                
                logger.info(f"âœ… æˆåŠŸåˆå¹¶ {len(segment_group)} ä¸ªç‰‡æ®µ: {merged_filename}")
                return merged_segment
            else:
                logger.error(f"âŒ åˆå¹¶å¤±è´¥: {merged_filename}")
                return None
                
        except Exception as e:
            logger.error(f"åˆ›å»ºåˆå¹¶ç‰‡æ®µå¤±è´¥: {e}")
            return None
    
    def _merge_video_segments(self, video_path: str, start_time: float, end_time: float, output_path: str) -> bool:
        """
        ä½¿ç”¨FFmpegåˆå¹¶è§†é¢‘ç‰‡æ®µï¼ˆç²¾ç¡®æ—¶é—´å®šä½ç‰ˆæœ¬ï¼‰
        
        Args:
            video_path: åŸå§‹è§†é¢‘è·¯å¾„
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ ¼å¼åŒ–æ—¶é—´
            start_str = self._format_time_for_ffmpeg(start_time)
            duration = end_time - start_time
            duration_str = self._format_time_for_ffmpeg(duration)
            
            # FFmpegå‘½ä»¤ï¼ˆç²¾ç¡®æ—¶é—´å®šä½æ¨¡å¼ - è§£å†³é™æ­¢ç”»é¢é—®é¢˜ï¼‰
            cmd = [
                "ffmpeg", "-y",
                "-ss", start_str,                # âš ï¸ å…³é”®ï¼šè¾“å…¥å‰å®šä½ï¼Œæ›´ç²¾ç¡®
                "-i", video_path,
                "-t", duration_str,
                "-c:v", "libx264",               # âœ… é‡æ–°ç¼–ç è§†é¢‘æµï¼Œç¡®ä¿ç²¾ç¡®åˆ‡å‰²
                "-c:a", "aac",                   # âœ… é‡æ–°ç¼–ç éŸ³é¢‘æµ
                "-preset", "fast",               # å¿«é€Ÿç¼–ç é¢„è®¾
                "-crf", "23",                    # é«˜è´¨é‡ç¼–ç 
                "-avoid_negative_ts", "make_zero",
                "-fflags", "+genpts",
                "-reset_timestamps", "1",         # âœ… é‡ç½®æ—¶é—´æˆ³ä»0å¼€å§‹
                output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=False, timeout=120)
            
            if result.returncode == 0:
                logger.debug(f"âœ… ç²¾ç¡®è§†é¢‘åˆå¹¶æˆåŠŸ: {Path(output_path).name}")
                return True
            else:
                logger.error(f"FFmpegåˆå¹¶å¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"è§†é¢‘åˆå¹¶å¼‚å¸¸: {e}")
            return False
    
    def _format_time_for_ffmpeg(self, seconds: float) -> str:
        """å°†ç§’æ•°è½¬æ¢ä¸ºFFmpegæ—¶é—´æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = seconds % 60
        return f"{hours:02d}:{minutes:02d}:{secs:06.3f}"
    
    def process_segments(self, 
                        segments: List[Dict[str, Any]], 
                        video_path: str,
                        output_dir: str,
                        progress_callback: Optional[callable] = None) -> Dict[str, Any]:
        """
        å®Œæ•´çš„ç‰‡æ®µè¯­ä¹‰å¤„ç†æµç¨‹ï¼Œæ”¯æŒæ—¶é—´æˆ³å­æ–‡ä»¶å¤¹
        
        Args:
            segments: åŸå§‹ç‰‡æ®µåˆ—è¡¨
            video_path: åŸå§‹è§†é¢‘è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            progress_callback: è¿›åº¦å›è°ƒ
            
        Returns:
            å¤„ç†ç»“æœ
        """
        start_time = datetime.now()
        
        if progress_callback:
            progress_callback(10, "å¼€å§‹è¯­ä¹‰ç›¸ä¼¼æ€§åˆ†æ...")
        
        # 1. åˆ†æè¯­ä¹‰ç›¸ä¼¼æ€§
        analyzed_segments = self.analyze_segments_similarity(segments, progress_callback)
        
        if progress_callback:
            progress_callback(50, "å¼€å§‹åˆå¹¶ç›¸ä¼¼ç‰‡æ®µ...")
        
        # 2. åˆå¹¶ç›¸ä¼¼ç‰‡æ®µ (ç°åœ¨ä¼šè‡ªåŠ¨åˆ›å»ºæ—¶é—´æˆ³å­ç›®å½•)
        merged_segments = self.merge_similar_segments(analyzed_segments, video_path, output_dir)
        
        if progress_callback:
            progress_callback(90, "ç”Ÿæˆå¤„ç†æŠ¥å‘Š...")
        
        # 3. ç”ŸæˆæŠ¥å‘Š (ä¿å­˜åˆ°ä¸»ç›®å½•)
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        # æ¸…ç†ç‰‡æ®µæ•°æ®ä¸­çš„numpyæ•°ç»„ï¼Œå‡†å¤‡JSONåºåˆ—åŒ–
        cleaned_segments = []
        for segment in merged_segments:
            cleaned_segment = self._clean_for_json_serialization(segment)
            cleaned_segments.append(cleaned_segment)
        
        # æ‰¾åˆ°æœ€æ–°çš„åˆå¹¶ä¼šè¯ç›®å½•
        latest_session = None
        if merged_segments:
            latest_session = merged_segments[0].get('merge_session')
        
        report = {
            'timestamp': end_time.isoformat(),
            'processing_time': processing_time,
            'original_segments': len(segments),
            'merged_segments': len(merged_segments),
            'compression_ratio': len(segments) / max(1, len(merged_segments)),
            'similarity_threshold': self.similarity_threshold,
            'max_merge_duration': self.max_merge_duration,
            'merge_session': latest_session,
            'segments': cleaned_segments
        }
        
        # ä¿å­˜æ€»æŠ¥å‘Šåˆ°ä¸»ç›®å½•
        timestamp_str = start_time.strftime("%Y%m%d_%H%M%S")
        report_path = Path(output_dir) / f"semantic_merge_report_{timestamp_str}.json"
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            logger.info(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        except Exception as e:
            logger.warning(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥ï¼Œä½†å¤„ç†ç»§ç»­: {e}")
            # å³ä½¿ä¿å­˜æŠ¥å‘Šå¤±è´¥ï¼Œä¹Ÿä¸è¦å½±å“ä¸»æµç¨‹
        
        if progress_callback:
            progress_callback(100, f"è¯­ä¹‰åˆå¹¶å®Œæˆ! {len(segments)} -> {len(merged_segments)} ä¸ªç‰‡æ®µ")
        
        logger.info(f"ğŸ‰ è¯­ä¹‰ç‰‡æ®µåˆå¹¶å®Œæˆ!")
        logger.info(f"ğŸ“Š åŸå§‹ç‰‡æ®µ: {len(segments)}")
        logger.info(f"ğŸ“Š åˆå¹¶åç‰‡æ®µ: {len(merged_segments)}")
        logger.info(f"ğŸ“Š å‹ç¼©æ¯”: {report['compression_ratio']:.2f}x")
        logger.info(f"â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.1f}ç§’")
        logger.info(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        return report
    
    def merge_segments(self, 
                      segments: List[Dict[str, Any]], 
                      video_name: str,
                      output_dir: str,
                      progress_callback: Optional[callable] = None) -> Dict[str, Any]:
        """
        è¯­ä¹‰åˆå¹¶ç‰‡æ®µçš„ç®€åŒ–æ¥å£ï¼ˆç”¨äºCLIè°ƒç”¨ï¼‰
        
        Args:
            segments: åŸå§‹ç‰‡æ®µåˆ—è¡¨
            video_name: è§†é¢‘åç§°
            output_dir: è¾“å‡ºç›®å½•
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            åˆå¹¶ç»“æœ
        """
        try:
            if progress_callback:
                progress_callback(5, "åˆå§‹åŒ–è¯­ä¹‰åˆå¹¶...")
            
            # æ„é€ è§†é¢‘è·¯å¾„ï¼ˆä»ç¬¬ä¸€ä¸ªç‰‡æ®µæ¨æ–­ï¼‰
            if not segments:
                if progress_callback:
                    progress_callback(0, "é”™è¯¯: æ²¡æœ‰æä¾›ç‰‡æ®µ")
                return {"success": False, "error": "No segments provided"}
            
            if progress_callback:
                progress_callback(10, "æŸ¥æ‰¾åŸå§‹è§†é¢‘æ–‡ä»¶...")
            
            # ä»ç‰‡æ®µä¿¡æ¯æ¨æ–­åŸå§‹è§†é¢‘è·¯å¾„
            first_segment = segments[0]
            video_path = first_segment.get('video_path', '')
            
            if not video_path:
                # å°è¯•ä»file_pathæ¨æ–­
                file_path = first_segment.get('file_path', '')
                if file_path:
                    # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
                    possible_paths = [
                        f"../ğŸ­Origin/{video_name}.mp4",  # ç›¸å¯¹äºvideo_to_sliceç›®å½•
                        f"ğŸ­Origin/{video_name}.mp4",     # ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
                        f"data/input/{video_name}.mp4",   # ä¼ ç»Ÿè·¯å¾„
                        f"../ğŸ­Origin/{video_name}.mov",  # å…¶ä»–æ ¼å¼
                        f"ğŸ­Origin/{video_name}.mov",
                        f"../ğŸ­Origin/{video_name}.avi",
                        f"ğŸ­Origin/{video_name}.avi"
                    ]
                    
                    for test_path in possible_paths:
                            if os.path.exists(test_path):
                                video_path = test_path
                                break
            
            if not video_path or not os.path.exists(video_path):
                if progress_callback:
                    progress_callback(0, f"é”™è¯¯: æ‰¾ä¸åˆ°è§†é¢‘æ–‡ä»¶ {video_name}")
                logger.error(f"æ‰¾ä¸åˆ°åŸå§‹è§†é¢‘æ–‡ä»¶: {video_name}")
                return {
                    "success": False, 
                    "error": f"Cannot find original video file for {video_name}"
                }
            
            if progress_callback:
                progress_callback(15, f"æ‰¾åˆ°è§†é¢‘: {Path(video_path).name}")
            
            logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")
            logger.info(f"ç‰‡æ®µæ•°é‡: {len(segments)}")
            
            # æ‰§è¡Œå®Œæ•´çš„è¯­ä¹‰å¤„ç†
            result = self.process_segments(segments, video_path, output_dir, progress_callback)
            
            success = result.get('merged_segments', 0) > 0
            
            return {
                "success": success,
                "compression_ratio": result.get('compression_ratio', 1.0),
                "original_segments": result.get('original_segments', 0),
                "merged_segments": result.get('merged_segments', 0),
                "processing_time": result.get('processing_time', 0),
                "segments": result.get('segments', [])
            }
            
        except Exception as e:
            logger.error(f"è¯­ä¹‰åˆå¹¶å¤±è´¥: {e}")
            if progress_callback:
                progress_callback(0, f"é”™è¯¯: {str(e)[:30]}...")
            return {
                "success": False,
                "error": str(e)
            }

    def _clean_for_json_serialization(self, obj):
        """
        é€’å½’æ¸…ç†å¯¹è±¡ä»¥å‡†å¤‡JSONåºåˆ—åŒ–ï¼Œç§»é™¤æ‰€æœ‰numpyæ•°ç»„å’Œä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
        
        Args:
            obj: è¦æ¸…ç†çš„å¯¹è±¡
            
        Returns:
            æ¸…ç†åçš„å¯åºåˆ—åŒ–å¯¹è±¡
        """
        if isinstance(obj, np.ndarray):
            # numpyæ•°ç»„è½¬æ¢ä¸ºåˆ—è¡¨
            return obj.tolist()
        elif isinstance(obj, dict):
            # é€’å½’æ¸…ç†å­—å…¸
            cleaned_dict = {}
            for key, value in obj.items():
                # è·³è¿‡ç‰¹å®šçš„ä¸å¯åºåˆ—åŒ–å­—æ®µ
                if key in ['clip_features', 'features', 'model_output']:
                    continue
                try:
                    cleaned_dict[key] = self._clean_for_json_serialization(value)
                except (TypeError, ValueError):
                    # å¦‚æœå€¼ä¸èƒ½åºåˆ—åŒ–ï¼Œå°±è·³è¿‡
                    continue
            return cleaned_dict
        elif isinstance(obj, list):
            # é€’å½’æ¸…ç†åˆ—è¡¨
            return [self._clean_for_json_serialization(item) for item in obj]
        elif hasattr(obj, 'tolist') and callable(getattr(obj, 'tolist')):
            # æ”¯æŒtolistçš„numpyç±»å‹
            try:
                return obj.tolist()
            except:
                return str(obj)
        elif hasattr(obj, '__dict__'):
            # è‡ªå®šä¹‰å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸
            return self._clean_for_json_serialization(obj.__dict__)
        else:
            # åŸºæœ¬ç±»å‹ç›´æ¥è¿”å›
            return obj


if __name__ == "__main__":
    pass 