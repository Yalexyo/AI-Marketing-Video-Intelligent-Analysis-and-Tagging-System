#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœªåˆ†ææ–‡ä»¶æ£€æµ‹å’Œå¤„ç†è„šæœ¬
åŠŸèƒ½ï¼š
1. æ‰«æğŸ¬Sliceç›®å½•ä¸­çš„æ‰€æœ‰è§†é¢‘æ–‡ä»¶
2. æ£€æµ‹å“ªäº›æ–‡ä»¶æ²¡æœ‰æˆåŠŸåˆ†æï¼ˆæ²¡æœ‰æœ‰æ•ˆçš„analysis.jsonæ–‡ä»¶ï¼‰
3. å°†æœªåˆ†æçš„æ–‡ä»¶ç§»åŠ¨åˆ°"æœªåˆ†æ"æ–‡ä»¶å¤¹
4. ä¿®å¤å¤šåœºæ™¯æ–‡ä»¶åæ˜ å°„é—®é¢˜
"""

import os
import json
import shutil
import logging
from pathlib import Path
from typing import List, Dict, Any, Set, Optional
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class UnprocessedFileAnalyzer:
    """æœªåˆ†ææ–‡ä»¶åˆ†æå™¨"""
    
    def __init__(self, slice_dir: str = "ğŸ¬Slice"):
        self.slice_dir = Path(slice_dir)
        self.unprocessed_dir = Path("ğŸ¬Slice/æœªåˆ†æ")
        self.video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.m4v']
        
    def analyze_all_files(self) -> Dict[str, Any]:
        """åˆ†ææ‰€æœ‰æ–‡ä»¶çš„å¤„ç†çŠ¶æ€"""
        logger.info("ğŸ” å¼€å§‹åˆ†ææ–‡ä»¶å¤„ç†çŠ¶æ€...")
        
        results = {
            "total_videos": 0,
            "successfully_analyzed": 0,
            "failed_analysis": 0,
            "no_analysis": 0,
            "file_name_issues": 0,
            "unprocessed_files": [],
            "failed_files": [],
            "name_mapping_issues": [],
            "summary_by_video": {}
        }
        
        # æ‰«ææ‰€æœ‰è§†é¢‘ç›®å½•
        for video_dir in self.slice_dir.iterdir():
            if not video_dir.is_dir() or video_dir.name == "æœªåˆ†æ":
                continue
                
            video_name = video_dir.name
            logger.info(f"ğŸ“ åˆ†æè§†é¢‘ç›®å½•: {video_name}")
            
            video_stats = self._analyze_video_directory(video_dir)
            results["summary_by_video"][video_name] = video_stats
            
            # ç´¯ç§¯ç»Ÿè®¡
            results["total_videos"] += video_stats["total_files"]
            results["successfully_analyzed"] += video_stats["success_count"]
            results["failed_analysis"] += video_stats["failed_count"]
            results["no_analysis"] += video_stats["no_analysis_count"]
            results["file_name_issues"] += video_stats["name_issues_count"]
            
            # æ”¶é›†é—®é¢˜æ–‡ä»¶
            results["unprocessed_files"].extend(video_stats["unprocessed_files"])
            results["failed_files"].extend(video_stats["failed_files"])
            results["name_mapping_issues"].extend(video_stats["name_mapping_issues"])
        
        return results
    
    def _analyze_video_directory(self, video_dir: Path) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªè§†é¢‘ç›®å½•"""
        stats = {
            "total_files": 0,
            "success_count": 0,
            "failed_count": 0,
            "no_analysis_count": 0,
            "name_issues_count": 0,
            "unprocessed_files": [],
            "failed_files": [],
            "name_mapping_issues": []
        }
        
        # æ£€æŸ¥sliceså­ç›®å½•
        slices_dir = video_dir / "slices"
        if slices_dir.exists():
            self._analyze_slices_directory(slices_dir, video_dir.name, stats)
        else:
            # æ£€æŸ¥ç›´æ¥åœ¨è§†é¢‘ç›®å½•ä¸‹çš„æ–‡ä»¶
            self._analyze_direct_directory(video_dir, video_dir.name, stats)
        
        return stats
    
    def _analyze_slices_directory(self, slices_dir: Path, video_name: str, stats: Dict[str, Any]):
        """åˆ†æsliceså­ç›®å½•"""
        # æ”¶é›†æ‰€æœ‰è§†é¢‘æ–‡ä»¶
        video_files = []
        for file_path in slices_dir.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in self.video_extensions:
                video_files.append(file_path)
        
        stats["total_files"] = len(video_files)
        
        # åˆ†ææ¯ä¸ªè§†é¢‘æ–‡ä»¶
        for video_file in video_files:
            self._analyze_single_video_file(video_file, video_name, stats)
    
    def _analyze_direct_directory(self, video_dir: Path, video_name: str, stats: Dict[str, Any]):
        """åˆ†æç›´æ¥ç›®å½•ç»“æ„"""
        # æ”¶é›†æ‰€æœ‰è§†é¢‘æ–‡ä»¶
        video_files = []
        for file_path in video_dir.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in self.video_extensions:
                video_files.append(file_path)
        
        stats["total_files"] = len(video_files)
        
        # åˆ†ææ¯ä¸ªè§†é¢‘æ–‡ä»¶
        for video_file in video_files:
            self._analyze_single_video_file(video_file, video_name, stats)
    
    def _analyze_single_video_file(self, video_file: Path, video_name: str, stats: Dict[str, Any]):
        """åˆ†æå•ä¸ªè§†é¢‘æ–‡ä»¶"""
        file_stem = video_file.stem
        
        # æ¸…ç†æ–‡ä»¶åï¼ˆç§»é™¤â™»ï¸ç¬¦å·ç”¨äºJSONæ–‡ä»¶åŒ¹é…ï¼‰
        clean_stem = file_stem.replace("â™»ï¸", "")
        
        # å¯»æ‰¾å¯¹åº”çš„åˆ†ææ–‡ä»¶
        analysis_file = video_file.parent / f"{clean_stem}_analysis.json"
        failed_analysis_file = video_file.parent / f"âŒ{clean_stem}_analysis.json"
        
        if analysis_file.exists():
            # æ£€æŸ¥åˆ†ææ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
            if self._is_valid_analysis_file(analysis_file):
                stats["success_count"] += 1
            else:
                stats["failed_count"] += 1
                stats["failed_files"].append({
                    "video_file": str(video_file),
                    "analysis_file": str(analysis_file),
                    "video_name": video_name,
                    "issue": "åˆ†ææ–‡ä»¶æ— æ•ˆ"
                })
        elif failed_analysis_file.exists():
            # æœ‰å¤±è´¥æ ‡è®°çš„åˆ†ææ–‡ä»¶
            stats["failed_count"] += 1
            stats["failed_files"].append({
                "video_file": str(video_file),
                "analysis_file": str(failed_analysis_file),
                "video_name": video_name,
                "issue": "åˆ†æå¤±è´¥"
            })
        else:
            # å®Œå…¨æ²¡æœ‰åˆ†ææ–‡ä»¶
            stats["no_analysis_count"] += 1
            stats["unprocessed_files"].append({
                "video_file": str(video_file),
                "video_name": video_name,
                "issue": "æ— åˆ†ææ–‡ä»¶"
            })
        
        # æ£€æŸ¥æ–‡ä»¶åæ˜ å°„é—®é¢˜
        if file_stem.startswith("â™»ï¸"):
            # å¤šåœºæ™¯æ–‡ä»¶ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰åŸå§‹åç§°çš„JSONæ–‡ä»¶
            original_stem = file_stem[1:]  # ç§»é™¤â™»ï¸
            original_analysis = video_file.parent / f"{original_stem}_analysis.json"
            if original_analysis.exists():
                stats["name_issues_count"] += 1
                stats["name_mapping_issues"].append({
                    "video_file": str(video_file),
                    "expected_json": str(analysis_file),
                    "actual_json": str(original_analysis),
                    "video_name": video_name,
                    "issue": "å¤šåœºæ™¯æ–‡ä»¶åæ˜ å°„ä¸ä¸€è‡´"
                })
    
    def _is_valid_analysis_file(self, analysis_file: Path) -> bool:
        """æ£€æŸ¥åˆ†ææ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
        try:
            with open(analysis_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            if not data.get("success", False):
                return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ„ä¹‰çš„å†…å®¹
            object_val = data.get("object", "")
            if object_val in ["analysis failed", "æœªçŸ¥", "", "unknown"]:
                return False
            
            return True
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•è¯»å–åˆ†ææ–‡ä»¶ {analysis_file}: {e}")
            return False
    
    def move_unprocessed_files(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """ç§»åŠ¨æœªåˆ†æçš„æ–‡ä»¶åˆ°"æœªåˆ†æ"æ–‡ä»¶å¤¹"""
        logger.info("ğŸ“¦ å¼€å§‹ç§»åŠ¨æœªåˆ†æçš„æ–‡ä»¶...")
        
        # åˆ›å»ºæœªåˆ†æç›®å½•
        self.unprocessed_dir.mkdir(exist_ok=True)
        
        move_results = {
            "moved_files": 0,
            "failed_moves": 0,
            "moved_file_list": [],
            "move_errors": []
        }
        
        # ç§»åŠ¨å®Œå…¨æœªåˆ†æçš„æ–‡ä»¶
        for unprocessed in analysis_result["unprocessed_files"]:
            try:
                src_file = Path(unprocessed["video_file"])
                dst_file = self.unprocessed_dir / src_file.name
                
                # é¿å…æ–‡ä»¶åå†²çª
                counter = 1
                original_dst = dst_file
                while dst_file.exists():
                    dst_file = original_dst.parent / f"{original_dst.stem}_{counter}{original_dst.suffix}"
                    counter += 1
                
                shutil.move(str(src_file), str(dst_file))
                move_results["moved_files"] += 1
                move_results["moved_file_list"].append({
                    "original": str(src_file),
                    "destination": str(dst_file),
                    "video_name": unprocessed["video_name"]
                })
                logger.info(f"ğŸ“¦ å·²ç§»åŠ¨: {src_file.name} â†’ æœªåˆ†æ/")
                
            except Exception as e:
                move_results["failed_moves"] += 1
                move_results["move_errors"].append({
                    "file": unprocessed["video_file"],
                    "error": str(e)
                })
                logger.error(f"âŒ ç§»åŠ¨å¤±è´¥: {unprocessed['video_file']} - {e}")
        
        return move_results
    
    def fix_name_mapping_issues(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """ä¿®å¤æ–‡ä»¶åæ˜ å°„é—®é¢˜"""
        logger.info("ğŸ”§ å¼€å§‹ä¿®å¤æ–‡ä»¶åæ˜ å°„é—®é¢˜...")
        
        fix_results = {
            "fixed_count": 0,
            "failed_fixes": 0,
            "fixed_files": [],
            "fix_errors": []
        }
        
        for issue in analysis_result["name_mapping_issues"]:
            try:
                # é‡å‘½åJSONæ–‡ä»¶ä»¥åŒ¹é…è§†é¢‘æ–‡ä»¶å
                old_json = Path(issue["actual_json"])
                new_json = Path(issue["expected_json"])
                
                if old_json.exists() and not new_json.exists():
                    shutil.move(str(old_json), str(new_json))
                    fix_results["fixed_count"] += 1
                    fix_results["fixed_files"].append({
                        "old_json": str(old_json),
                        "new_json": str(new_json),
                        "video_file": issue["video_file"]
                    })
                    logger.info(f"ğŸ”§ å·²ä¿®å¤æ˜ å°„: {old_json.name} â†’ {new_json.name}")
                
            except Exception as e:
                fix_results["failed_fixes"] += 1
                fix_results["fix_errors"].append({
                    "issue": issue,
                    "error": str(e)
                })
                logger.error(f"âŒ ä¿®å¤å¤±è´¥: {issue['video_file']} - {e}")
        
        return fix_results
    
    def generate_report(self, analysis_result: Dict[str, Any], move_result: Optional[Dict[str, Any]] = None, fix_result: Optional[Dict[str, Any]] = None) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report_lines = [
            "=" * 80,
            "ğŸ” æœªåˆ†ææ–‡ä»¶æ£€æµ‹å’Œå¤„ç†æŠ¥å‘Š",
            f"â° ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "=" * 80,
            "",
            "ğŸ“Š æ€»ä½“ç»Ÿè®¡:",
            f"  æ€»è§†é¢‘æ–‡ä»¶æ•°: {analysis_result['total_videos']}",
            f"  æˆåŠŸåˆ†æ: {analysis_result['successfully_analyzed']} ({analysis_result['successfully_analyzed']/analysis_result['total_videos']*100:.1f}%)" if analysis_result['total_videos'] > 0 else "  æˆåŠŸåˆ†æ: 0 (0%)",
            f"  åˆ†æå¤±è´¥: {analysis_result['failed_analysis']}",
            f"  å®Œå…¨æœªåˆ†æ: {analysis_result['no_analysis']}",
            f"  æ–‡ä»¶åæ˜ å°„é—®é¢˜: {analysis_result['file_name_issues']}",
            "",
            "ğŸ“ æŒ‰è§†é¢‘ç›®å½•ç»Ÿè®¡:",
        ]
        
        for video_name, stats in analysis_result["summary_by_video"].items():
            if stats["total_files"] > 0:
                success_rate = stats["success_count"] / stats["total_files"] * 100
                report_lines.append(f"  ğŸ“¹ {video_name}:")
                report_lines.append(f"    æ€»æ–‡ä»¶: {stats['total_files']}, æˆåŠŸ: {stats['success_count']} ({success_rate:.1f}%)")
                report_lines.append(f"    å¤±è´¥: {stats['failed_count']}, æœªåˆ†æ: {stats['no_analysis_count']}, åç§°é—®é¢˜: {stats['name_issues_count']}")
        
        if move_result:
            report_lines.extend([
                "",
                "ğŸ“¦ æ–‡ä»¶ç§»åŠ¨ç»“æœ:",
                f"  æˆåŠŸç§»åŠ¨: {move_result['moved_files']} ä¸ªæ–‡ä»¶",
                f"  ç§»åŠ¨å¤±è´¥: {move_result['failed_moves']} ä¸ªæ–‡ä»¶",
            ])
        
        if fix_result:
            report_lines.extend([
                "",
                "ğŸ”§ æ˜ å°„ä¿®å¤ç»“æœ:",
                f"  æˆåŠŸä¿®å¤: {fix_result['fixed_count']} ä¸ªé—®é¢˜",
                f"  ä¿®å¤å¤±è´¥: {fix_result['failed_fixes']} ä¸ªé—®é¢˜",
            ])
        
        report_lines.extend([
            "",
            "=" * 80
        ])
        
        return "\n".join(report_lines)

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æœªåˆ†ææ–‡ä»¶æ£€æµ‹å’Œå¤„ç†å·¥å…·")
    parser.add_argument("--slice-dir", default="ğŸ¬Slice", help="åˆ‡ç‰‡ç›®å½•è·¯å¾„")
    parser.add_argument("--move", action="store_true", help="ç§»åŠ¨æœªåˆ†æçš„æ–‡ä»¶åˆ°'æœªåˆ†æ'æ–‡ä»¶å¤¹")
    parser.add_argument("--fix-mapping", action="store_true", help="ä¿®å¤æ–‡ä»¶åæ˜ å°„é—®é¢˜")
    parser.add_argument("--report-file", help="ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶")
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = UnprocessedFileAnalyzer(args.slice_dir)
    
    # åˆ†ææ‰€æœ‰æ–‡ä»¶
    logger.info("ğŸš€ å¼€å§‹æœªåˆ†ææ–‡ä»¶æ£€æµ‹...")
    analysis_result = analyzer.analyze_all_files()
    
    move_result = None
    fix_result = None
    
    # ä¿®å¤æ–‡ä»¶åæ˜ å°„é—®é¢˜
    if args.fix_mapping:
        fix_result = analyzer.fix_name_mapping_issues(analysis_result)
    
    # ç§»åŠ¨æœªåˆ†ææ–‡ä»¶
    if args.move:
        move_result = analyzer.move_unprocessed_files(analysis_result)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_report(analysis_result, move_result, fix_result)
    print(report)
    
    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    if args.report_file:
        with open(args.report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        logger.info(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.report_file}")
    
    # æ˜¾ç¤ºå»ºè®®
    if analysis_result["no_analysis"] > 0 or analysis_result["failed_analysis"] > 0:
        print("\nğŸ’¡ å»ºè®®æ“ä½œ:")
        if analysis_result["no_analysis"] > 0:
            print(f"  1. è¿è¡Œ python analyze_unprocessed_files.py --move å°† {analysis_result['no_analysis']} ä¸ªæœªåˆ†ææ–‡ä»¶ç§»åˆ°'æœªåˆ†æ'æ–‡ä»¶å¤¹")
        if analysis_result["file_name_issues"] > 0:
            print(f"  2. è¿è¡Œ python analyze_unprocessed_files.py --fix-mapping ä¿®å¤ {analysis_result['file_name_issues']} ä¸ªæ–‡ä»¶åæ˜ å°„é—®é¢˜")
        if analysis_result["failed_analysis"] > 0:
            print(f"  3. æ£€æŸ¥ {analysis_result['failed_analysis']} ä¸ªåˆ†æå¤±è´¥çš„æ–‡ä»¶ï¼Œè€ƒè™‘é‡æ–°å¤„ç†")

if __name__ == "__main__":
    main() 